# 数据密集型应用系统设计笔记


## 第一章 可靠、可扩展与可维护的应用系统

### 可靠性

指即使发生故障，系统也可以正常运行。

### 可扩展性

指负载增加时，有效保持系统性能的相关技术策略。

### 可维护性

意味着很多方面，本质是为了让工程和运营团队更为轻松。

## 第二章 数据模型与查询语言

读时模式：数据的结构时隐形的，只在读取时才解释。NoSQL。

写时模式：关系型数据库的一种传统方法，模式时显式的，并且数据库确保数据写入时都必须遵循。

读时模式类似动态类型检查，写时模式类似静态类型检查。

对文档进行更新时，通常会更新整个文档，而只有修改量不改变源文档大小时，原地覆盖更新才有效。因此，通常建议文档应该尽量小且避免写入时增加文档大小。

SQL 是一种声明式查询语言。CSS 也是声明式语言。

多对多关系是不同数据结构之间重要区别特征。如果数据大多是一对多关系或者记录之间没有关系，那么文档模型是合适的。

关系模型能够处理简单的多对多关系，但是随着数据之间的关联越来越复杂，将数据模型转换为图模型会更加自然

图由两种对象组成：顶点和边。

图强大的用途在于，提供了单个数据存储区保存完全不同类型对象的一致性方式。（顶点之间为不同类型，边之间为不同类型）

可以将图存储看作由两个关系表组成，一个用于定点，一个用于边。

Cypher 查询语言：一种用于属性图的声明式查询语言

如果把图数据放在关系结构中，也可以用 SQL 查询，只是存在一些困难。

三元存储模式几乎等同于属性图模型。  
在三元存储中，所有信息都是以非常简单的三部分形式存储（主体，谓语，客体）。主体相当于图中顶点，而客体是以下两种之一：

1. 原始数据类型中的值，如字符串或数字。这种情况下，谓语和客体相当于键和值。
2. 图中另一个顶点。此时，谓语是途中的边，主体是尾部顶点，客体是头部顶点。

SPARQL 查询语言：采用 RDF 数据模型的三元存储查询语言。它比 Cypher 更早，并且由于 Cypher 的模式匹配是借用 SPARQL 的，所以二者看起来很相似。

图数据库和网络模型的比较：

-   在 CODASYL 中，数据库有一个模式来指定哪种记录类型可以嵌套在其他记录类型中。在图数据库中则没有这种限制。
-   在 CODASYL 中，获取特定记录的唯一方法时遍历其中一条访问路径。在图数据库中，则可以通过顶点的唯一 ID 直接引用该顶点，也可以使用索引查找满足特定值的那些顶点。
-   在 CODASYL 中，记录的子记录是有序的，而图数据库中，顶点和边不是有序的。
-   在 CODASYL 中，所有的查询都是命令式的，图数据库可以用命令式，也可以用声明式，如 Cypher 和 SPARQL

### Datalog 基础

Datalog 是比 SPARQL 和 Cypher 更古老的语言。Datalog 的数据模型类似于三元存储模式，但更为通用一些。它采用`谓语（主体，客体）`

## 第三章 数据存储于检索

首先实现一个简单的文本键值对数据库。

许多数据库内部都使用日志，日志是一个仅支持追加更新的数据文件。

_日志通常指的是应用程序的运行输出日志，来记录发生了什么事。这里则是一个更为通用的含义，表示一个仅能追加的记录序列集合，它可能是人类不可读的，可能是二进制格式的而只能被其他程序来读取。_

如果日志保存了大量的记录，那个读性能会很慢。查找开销是 O(n)。

为了高效查找，引入了索引。但这会降低写的速度，所以需要权衡。

### 哈希索引

保存内存中的 hashmap，每当在文件中追加新的键值对时，还要更新 hashmap 来反映刚刚写入的数据的偏移。

只追加到一个文件，如何避免最终用尽磁盘空间？  
一个好的方法是将日志分解成一定大小的段，当文件达到一定大小时就关闭它，并将后续写入到新的段文件中。然后可以再这些段上执行压缩。压缩意味着丢弃重复的键，只保留最近的键。

可以再执行压缩的同时将多个段合并在一起。由于段在写入后不会再进行修改，合并的段会被写入到另一个文件。

在压缩和合并时，继续用旧的段文件读取和写入。合并完成后，删除旧的段文件。

每个段都有自己的哈希表。先检查最新段的 hashmap，如果不存在，检查第二新的，以此类推。

#### 文件格式

CSV 不是日志的最佳格式。更快更简单的方法时使用二进制格式。首先以字节为单位记录字符串的长度，之后跟上原始字符串（不需要转义）

#### 删除记录

在数据文件中追加一个特殊的删除记录（墓碑），之后在合并段阶段删除。

#### 崩溃恢复

将 hashmap 的快照存储在磁盘上

#### 部分写入的记录

文件包含校验值

#### 并发控制

只有一个写线程，多个读线程

---

#### 哈希表索引也有其局限

-   哈希表必须全部放入内存，如果有大量的 key，就没那么幸运了
-   区间查询效率不高

### SSTable 和 LSM-Tree

如果要求键值对的顺序按键排序，这种格式称为排序字符串表，即 SSTable。

相比于哈希表索引日志段，有以下优点：

1. 合并段更加简单高效。因为是有序的，可以用类似合并排序算法。当多个段包含相同的键时，保留最新段的值。
2. 不再需要在内存中保存所有键的索引。因为是有序的，可以对于段文件中的每几千字节，保存一个键就够了。稀疏的索引
3. 由于读请求往往需要扫描请求范围内的多个键值对，可以考虑将这些记录保存到一个块中并在写磁盘之前将其压缩。然后稀疏内存索引的一个条目指向压缩块的开头。

### 构建和维护 SSTable

存储引擎的基本工作流程如下：

-   当写入时，将其添加到内存中的平衡树数据结构中（如红黑树）。这个内存中的树有时被称为内存表。
-   当内存表大于某个阈值（通常为几兆字节）时，将其作为 SSTable 文件写入磁盘。写入的同时可以继续添加到一个新的内存表
-   为了处理读请求，首先尝试在内存表中查找键，然后是最新的磁盘段文件，然后是次新，直到找到目标
-   后台进程周期性的执行合并与压缩过程，以合并多个段文件，并丢弃那些已被覆盖或删除的值

基于合并和压缩排序文件原理的存储引擎通常都被称为 LSM 存储引擎。

### 性能优化

当查找数据库中某个不存在的键时，LSM-Tree 算法可能很慢。为优化这种访问，使用额外的布隆过滤器。布隆过滤器是内存高效的数据结构，用于近似计算集合的内容。如果数据库中不存在某个键，它能很快告诉你结果，从而节省不必要的磁盘读取。

有不同策略，会影响甚至决定 SSTable 压缩和合并时的具体顺序和时机，最常见的有两种：

-   大小分级：较新和较小的 SSTable 被连续合并到较旧和较大的 SSTable
-   分层压缩：键的范围分裂成多个更小的 SSTable，旧数据被移动到单独的“层级”，这样压缩可以逐步进行并节省磁盘空间

### B-trees

它是几乎所有关系型数据库中的标准索引实现，许多非关系型数据库也经常使用。

同 SSTable 一样，B-tree 保留按键排序的键值对。B-tree 将数据库分解成**固定大小的块或页**，传统上大小为 4KB（有时更大），页是内部读写最小单位。磁盘也是以固定大小的块排列。

么个页面都用地址或位置进行标识，可以让一个页面引用另一个页面，类似指针，不过指向是磁盘地址，而不是内存。

一个页包含的子叶数量称为分支因子，通常有几百个。

B-tree 底层的基本写操作时使用新数据覆盖磁盘页上的旧页。它假设覆盖不会改变页的磁盘存储位置，这与日志文件索引（如 LSM-Tree）仅追加更新文件形成鲜明对比

某些操作需要覆盖多个不同的页。例如，如果插入导致页溢出，因而需分裂页，那么需要写两个分裂的页，并且覆盖其父页以更新对两个子页的引用

为了能使数据库能从崩溃中恢复，常见的 B-tree 的实现需要支持磁盘上的额外的数据结构：预写日志（write-ahead log,WAL），也称重做日志。仅支持追加的文件，先更新 WAL 再修改树本身。

#### 优化 B-tree

-   一些数据库不使用覆盖页和维护 WAL 来进行崩溃恢复，而是使用写时复制方案。修改的页被写入不同的位置，树中父页的新版本被创建，并指向新的位置。

-   保存键的缩略信息。
-   相邻子页按顺序保存在磁盘上
-   添加额外的指针到树种。例如每个叶子页面可能会向左或向右引用其同级的兄弟页，这样可以顺序扫描键，而不用跳回到父页。

#### LSM-tree 优点

-   有较低的写放大，能承受更高的写入吞吐量
-   更好的压缩，因此通常磁盘上的文件比 B-tree 小很多

#### LSM-tree 缺点

-   压缩过程会干扰正在进行的读写操作，容易发生读写请求等待的情况。而 B-tree 的响应延时则更具确定性。
-   磁盘的有限写入带宽需要在初始写入和后台运行的压缩线程之间所共享，可能会发生压缩无法匹配写入速率的情况，这种情况下，磁盘上未合并段的数量不断增加，导致磁盘空间不足。

#### 在索引中存储值

索引中的键时查询搜索的对象，而值是以下两类之一：

1. 实际行（文档，顶点）
2. 对其他地方存储的行的引用。

第二种情况下，存储行的具体位置被称为堆文件，它不以特定的顺序存储数据。

聚集索引：将索引行直接存储在索引中。mysql 的 InnoDB 存储引擎中，表的主键始终是聚集索引，二级索引引用主键，而不是堆文件位置。

覆盖索引：支持只通过索引回答某些简单的查询，包含一部分列。

级联索引：将一列追加到另一列，将几个简单的字段组合成一个键，例如`lastname,firstname`组成和`lastname-firstname`，由于排列，索引可以用于找特定`lastname`的人，或特定`lastname-firstname`的人，而不能找特定`firstname`的人。级连索引是一种多列索引。

OLTP：在线事务处理。根据用户的输入插入或更新记录。
OLAP：在线分析处理。数据分析，需要扫描大量的行，每个记录只读取少数几列，并计算汇总统计信息。

数据仓库包含公司所有 OLTP 系统的只读副本。从 OLTP 数据库中提取数据，转换为分析友好的模式，执行必要的清理，然后加载到数据仓库中。过程称为提取-转换-加载。

### 星型与雪花型分析模式

与 OLTP 使用了多种不同数据模型不同，分析型业务的数据模型要少很多。许多数据仓库使用星型模型，也称为维度建模。

“星型模式”来源自当表关系可视化时，事实表位于中间，被一系列维度表包围；这些表的链接就像星星的光芒。

该模式的一个变体称为雪花模式，其中维度进一步细分为子空间。

### 列式存储

在大多数 OLTP 数据库中，存储以面向行的方式布局：来自表的一行的所有值彼此相邻存储。文档数据库也是类似。

面向列的存储的想法很简单：不需要讲一行中的所有值存储在一起，而是将每列中的所受值存储在一起。

#### 列压缩

用位图表示，位图也可以进行游程编码。

列存储的写操作时用 LSM-tree。

#### 物化视图

缓存查询最常用的一些计数或总和。

在 SQL 中，视图（标准视图、虚拟视图）是基于 SQL 语句的结果集的可视化的表。

视图包含行和列，就像一个真实的表。视图中的字段就是来自一个或多个数据库中的真实的表中的字段。我们可以向视图添加 SQL 函数、WHERE 以及 JOIN 语句，我们也可以提交数据，就像这些来自于某个单一的表。

视图总是显示最近的数据。每当用户查询视图时，数据库引擎通过使用 SQL 语句来重建数据。

不同的是，物化视图是查询结果的实际副本，并被写到磁盘，而虚拟视图只是用于编写查询的快捷方式。

在 OLTP 中不长使用物化视图，而对于大量读密集的数据仓库，物化事务则更有意义。

## 第四章 数据编码与演化

为了使系统继续顺利运行，需要保持双向的兼容性：

-   向后兼容
    较新的代码可以读取由旧代码编写的数据
-   向前兼容
    较旧的代码可以读取由较新代码编写的数据

使用语言内置的编码方案通常不是个好主意。

### JSON

-   对处理大数字有问题，可以用数字加字符串一起来表示
-   对 Unicode 支持很好，但不支持二进制字符串，所以通常用 Base64 将二进制数据编码为文本来解决。数据大小增加了 33%
-   由可选的模式支持。

### 二进制编码

#### Thrift 和 Protocol Buffers

Thrift 和 Protocol Buffers 是两种二进制编码库，相比于直接用 JSON 更省空间

每个字段由其标签号标识，并使用数据类型进行标识。

#### Avro

Apache Avro 是另一种二进制编码格式，也使用模式来指定编码的数据结构，它有两种模式语言：Avro IDL 用于人工编辑，另一种基于 JSON 更易于机器读取。

Avro 模式中没有标签编号，编码是最紧凑的。编码数据中没有任何内容告诉你它是什么类型。解析二进制数据时，按照他们出现在模式中的顺序便利这些字段，然后直接采用模式告诉你的每个字段的数据类型。这意味着读取数据的代码使用与写入数据的代码完全相同的模式才可以正确解析数据。

编码时，它使用所知道的模式的任何版本 来编码数据，这被称为写模式。

解码时，它期望数据符合某个模式，即读模式。

Avro 的关键思想是写模式和读模式不必是完全一样的，它们只需要保持兼容。

为了保持兼容性，只能添加或删除具有默认值的字段。更改字段名称是向后兼容的，但不能向前兼容。

Avro 对动态生成的模式更友好

### 数据流的几种模型

-   数据库
    写入数据库的进程对数据进行编码，读数据库的进程进行解码
-   RPC 和 REST API
    客户端对请求进行编码，服务器对请求进行解码并对响应进行编码，客户端最终对响应解码
-   异步消息传递（使用消息代理或 Actor）
    节点之间通过互相发送消息进行通信，信息由发送者编码并由接受者解码

## 第五章 数据复制

### 主从复制

只有主节点能写，读可以在主或从节点。主节点先写，然后将日志或更改发送给从节点，完成复制。

复制分为同步复制和异步复制

#### 配置新的从节点

1. 在某个时间点对主节点的数据副本产生一个一致性快照
2. 将此快照拷贝到新的从节点
3. 从节点连接到主节点并请求快照之后所发生的数据更改日志
4. 从节点应用这些日志，这个过程称为追赶

#### 复制日志的实现

##### 基于语句的复制

sql 语句，存在不确定因素，如时间

##### 基于预写日志（WAL）传输

所有对数据库的写入的字节序列都被记入日志，因此可以使用完全相同的日志在另一个节点上构建副本。主要缺点是日志描述的数据结果非常底层。对版本要求严格。

##### 基于行的逻辑日志

复制和存储引擎采用不同的日志格式，这样复制与存储逻辑剥离。这种复制日志称为逻辑日志。
这样可以保持向后兼容

#### 基于触发器的复制

更灵活，可以注册自己的应用层代码。

### 多主节点复制

系统存在多个主节点，每个都可以接受写请求，客户端将写请求发送到其中一个主节点上，由该主节点负责将数据更改事件同步到其他主节点和自己的从节点。

另一个多主复制比较合适的场景就是离线客户端操作。
还有一个场景是协作编辑。

### 处理写冲突

#### 避免冲突

应用层避免冲突。比如特定的用户请求总是路由到特定的数据中心。

#### 收敛于一致状态

-   给每个写入分配一个唯一 id,挑选最高的 id 获胜，其余丢弃。如果基于时间戳，称为最后写入者获胜。
-   为每个副本分配一个 id,并制定规则，如序号最高的优先序号低的。
-   以某种方式将这些值合在一起。
-   利用预定义好的格式来记录和保留冲突的所有信息，然后依靠应用层来提醒用户。

#### 自定义冲突解决逻辑：

-   在写入时执行
-   在读取时执行

### 无主节点复制

客户端将写请求发送到多个节点上，读取时从多个节点上并行读取，以此检测和纠正某些过期数据

### 一致性模型

-   写后读一致性
    保证用户总能看到自己提交的最新数据
-   单调读
    用户在某个时间点读到数据后，保证此后不会出现比该时间更早的数据
-   前缀一致读
    保证数据之间的因果关系，例如，总是以正确的顺序读取问题，然后看到回答

### 检测并发写

-   最后写入者获胜
-   确定前后关系
-   合并同时写入的值
-   版本矢量

## 第六章 数据分区

两种主要的分区方法：

-   基于关键字区间的分区。先对关键字进行排序，每个分区只负责一段包含最小到最大关键字范围的一段关键字。对关键字排序的优点是可以支持高效的区间查询，但是如果应用程序经常访问与排序一致的某段关键字，就会存在热点的风险。采用这种方法，当分区太大时，通常将其分裂为两个子区间，从而动态的再平衡分区
-   哈希分区。将哈希函数作用于每个关键字，每个分区负责一定范围的哈希值。这种方法打破了原关键字的顺序关系，它的区间查询效率比较低，但可以更均匀的分配负载。采用哈希分区时，通常事先创建好足够多（但固定数量）的分区，让每个节点承担多个分区，当添加或删除节点时将某些分区从一个节点迁移到另一个节点，也可以支持动态分区。

二级索引也需要分区，有两种方法：

-   基于文档来分区二级索引（本地索引）
-   基于词条来分区二级索引（全局索引）

### 请求路由

-   允许客户端连接任意的节点。如果节点恰好有所请求的分区，则直接处理，否则转发到下一个合适的节点，接受答复，并将答复返回给客户端。
-   将所有客户端的请求都发送到一个路由层，由后者将请求转发到对应的分区节点上。路由层充当一个分区感知的伏在均衡器。
-   客户端感知分区和节点的分配关系。

## 第七章 事务

### ACID

-   原子性：把多个写操作纳入一个原子事务，出现故障时，事物会终止，数据库丢弃或撤销局部完成的更改

-   一致性：对数据有特定的预期状态，任何数据更改必须满足这些状态约束。一致性更多是应用层的属性。

-   隔离行：并发执行的多个事物相互隔离，不能互相交叉，可串行化。

-   持久性：保证事物一旦提交成功，即使存在硬件故障或数据库崩溃，事物所写入的任何数据也不会消失。

### 脏读、幻读、不可重复读的概念

#### 脏读

所谓脏读是指一个事务中访问到了另外一个事务未提交的数据

#### 幻读

一个事务读取 2 次，得到的记录条数不一致。  
在一个事务中的写入改变了另一个事务查询结果的现象，称为幻读。

#### 不可重复读

一个事务读取同一条记录 2 次，得到的结果不一致

### 弱隔离级别

#### 读-提交

是最基本的事务隔离级别，只提供以下两个保证：

1. 读数据库时，只能看到已成功提交的数据（防止脏读）
2. 写数据库时，只能覆盖已成功提交的数据（防止脏写）

##### 读-提交实现

-   防止脏写：用行级锁。
-   防止脏读：对于每个待更新的对象，数据库都会维护其旧值和当前持锁事务将要设置的新值两个版本。在事务提交前，所有其他读操作都读取旧值仅当写事务提交后，才会切换到读取新值。

#### 快照级别隔离与可重复读

解决不可重复读。其总体想法是：每个事务都从数据库的一致性快照中读取，事务一开始看到的是最近提交的数据，即使数据随后可能被另一个事务更改，但保证每个事务都只能看到该特定时间点的旧数据。

##### 实现快照级别隔离

通常采用写锁来防止脏写。但是读取不需要加锁。读操作不会阻止写操作，反之亦然。

考虑到多个正在进行的事务可能会在不同的时间点查看数据库状态，所以数据库保留了对象多个不同的提交版本，这种技术因此也被称为多版本并发控制（MVCC）

如果只是为了提供读-提交级别隔离，则只保留对象的两个版本就足够了。支持快照隔离级别的存储引擎往往直接采用 MVCC 来实现读-提交隔离。典型做法是，在读-提交级别下，对每一个不同的查询单独创建一个快照；而快照级别隔离则是使用一个快照来运行整个事务。

##### 一致性快照的可见性规则

仅当以下两个条件都成立，则该数据对象对事务可见：

-   事务开始的时刻，创建该对象的事务已经完成了提交。
-   对象没有被标记删除；或者被标记的删除，但删除事务在当前事务开始时还没有完成提交。

### 防止更新丢失

#### 原子写操作

例如，以下指令在多数关系型数据库中都是并发安全的：

```sql
UPDATE counters SET valie = value + 1 WHERE key = 'foo';
```

原子操作通常采用对读取对象加独占锁的方式来实现，这样在更新被提交之前不会让对其他事务可以读它。

#### 显示加锁

```sql
SELECT * FROM figures WHERE name = 'robort' FOR UPDATE;
```

`FOR UPDATE`指令指示数据对返回的所有结果行要加锁

#### 自动检测更新丢失

原子操作和锁都是通过强制“读-修改-写回”操作序列串执行来防止丢失更新。另一种思路是先让他们并发执行，但如果事务管理器检测到了更新丢失风险，则终止当前事务，并强制回退到安全的“读-修改-写回”方式。

### 写倾斜和幻读

#### 定义写倾斜

如果两个事务读取相同的一组对象，然后更新其中的一部分：不同的事务更新不同的对象，则可能发生写倾斜；而不同的事务如果更新的是同一个对象，则可能发生脏写或更新丢失。

### 串行化

#### 两阶段加锁（2PL）

近三十年来，可以说数据库只有一种被广泛使用的串行化算法，那就是两阶段加锁。

多个事务可以同时读取同一个对象，但只要出现任何的写操作，则必须加以独占访问：

-   如果事务 A 已经读取了某个对象，此时事务 B 想要写入该对象，那么 B 必须等到 A 提交或终止才能继续。以确保 B 不会在事务 A 执行的过程中间去修改对象。
-   如果事务 A 已经修改了对象，此时事务 B 想要读取该对象，则 B 必须等到 A 提或终止之后才能继续，对于 2PL，不会出现读取到旧值得情况。

快照级别隔离的口号“读写互不干扰”非常准确的点名到了它和 2PL 的关键区别。

#### 2PL 实现

读取用共享锁，可以多个同时共享。写入要独占锁，此时不能有其他的独占锁和共享锁。就像 Rust 的可变引用和不可变引用的规则，

### 可串行化的快照隔离级别

它提供了完整的可串行化保证，而性能相比于快照隔离损失很小。

2PL 是一种悲观控制机制，可串行化的快照隔离级别是一种乐观并发控制。运行多个事务并发执行互不阻塞；仅当事务尝试提交时，才检查可能的冲突，如果发现违背了串行化，则某些事务会被中止。

## 第八章 分布式系统的挑战

## 第九章 一致性共识

分布式一致性模型与我们之前讨论过的多种事务隔离级别有相似之处，但总体讲他们有着显著的区别：事务隔离主要是为了处理并发执行事务时的各种临界条件，而分布式一致性则主要是针对延迟和故障等问题来协调副本之间的状态。

### 可线性化

数据库对上提供单个副本的假象，从而不必担心复制滞后。
这就是可线性化（也称原子一致性，强一致性）

-   可串行化
    可串行化是事务的隔离属性，其中每个事务可以读写多个对象。它用来确保事务执行的结果与串行执行（每次执行一个事务）的结果完全相同，即使顺序可能不同。
-   可线性化
    是读写寄存器（单个对象）的最新值保证。它并不要求将操作组合到事务中，因此无法避免写倾斜等问题，除非采取其他额外措施。

数据库可以同时支持可串行化与线性化，称为严格的可串行化或强的单副本可串行化。
基于两阶段加锁或实际以串行执行都是典型的可线性化。但是，可串行化的快照隔离不是线性的。

#### 实现可线性化系统

-   主从复制（部分支持可线性化）
-   共识算法（支持可线性化）
-   多主复制（不支持）
-   无主复制（不支持）

不要求线性化的应用更能容忍网络故障，这种思路通常被称为 CAP 定理。

CAP 有时也代表一致性，可用性，分区容错性，系统只能支持其中两个特性。网络分区是一种故障，不管喜不喜欢都存在。

